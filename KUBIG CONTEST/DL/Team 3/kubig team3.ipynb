{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "63f757a14885421b876bd99214c5636b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_746cd7e2ba15454790c2f58a7f7df0e3",
              "IPY_MODEL_8c034bd209af471d97eee7df94fb8f8d",
              "IPY_MODEL_b1aef8141295436387ece3b678967602"
            ],
            "layout": "IPY_MODEL_3db14c4ea3714aae9cb309c64897ceb9"
          }
        },
        "746cd7e2ba15454790c2f58a7f7df0e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59fb587367d54bc39fa98dcf0495cdd4",
            "placeholder": "​",
            "style": "IPY_MODEL_7aea5bd645444b41913183ce4c9f70de",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "8c034bd209af471d97eee7df94fb8f8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_731b4e8fd192453fa8f72599b8f5e94c",
            "max": 61,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_77948f51680c43cc8a8ce7db5a270c92",
            "value": 61
          }
        },
        "b1aef8141295436387ece3b678967602": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a8d6c56ff6b4ba49b16bee9c58ea63d",
            "placeholder": "​",
            "style": "IPY_MODEL_ccd1cacdb5ac43f69486a9d71878f6e2",
            "value": " 61.0/61.0 [00:00&lt;00:00, 4.77kB/s]"
          }
        },
        "3db14c4ea3714aae9cb309c64897ceb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59fb587367d54bc39fa98dcf0495cdd4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7aea5bd645444b41913183ce4c9f70de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "731b4e8fd192453fa8f72599b8f5e94c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77948f51680c43cc8a8ce7db5a270c92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9a8d6c56ff6b4ba49b16bee9c58ea63d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ccd1cacdb5ac43f69486a9d71878f6e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "34a261aba31948b2a48ecd52dd16ea33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_55ba41beab3b43e7b5952f79affb8956",
              "IPY_MODEL_6e91f30374fb43638a279e909bf65257",
              "IPY_MODEL_c36705ace08344d39b2a3b517c5393e3"
            ],
            "layout": "IPY_MODEL_352fb41bef8143ecb7e88bb38bc07922"
          }
        },
        "55ba41beab3b43e7b5952f79affb8956": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6365c2f6f50b4e0f97b4f314ad0b995f",
            "placeholder": "​",
            "style": "IPY_MODEL_75dd04735e6c461ebfa410a8393f156a",
            "value": "vocab.txt: 100%"
          }
        },
        "6e91f30374fb43638a279e909bf65257": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc8938d9648642bbbeebd45c339150bd",
            "max": 263326,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0b8fbdc61fd54e62aaacd56177675f90",
            "value": 263326
          }
        },
        "c36705ace08344d39b2a3b517c5393e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af1eaad40bf6443eb1a85bae134caf7f",
            "placeholder": "​",
            "style": "IPY_MODEL_241626cd290d472a8a95f7abb769287a",
            "value": " 263k/263k [00:00&lt;00:00, 3.47MB/s]"
          }
        },
        "352fb41bef8143ecb7e88bb38bc07922": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6365c2f6f50b4e0f97b4f314ad0b995f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75dd04735e6c461ebfa410a8393f156a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fc8938d9648642bbbeebd45c339150bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b8fbdc61fd54e62aaacd56177675f90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "af1eaad40bf6443eb1a85bae134caf7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "241626cd290d472a8a95f7abb769287a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f5ced24fd40845a997ddd80d83cac05b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_42ec28c98a5d4da8a0baed3a6e87e2f8",
              "IPY_MODEL_bb57831ce21d47049c6fe4b824524a68",
              "IPY_MODEL_e24a38c2d8ce4a84af744b0c33f5c63c"
            ],
            "layout": "IPY_MODEL_ca2bed2832de41f9a3f27278696fe6af"
          }
        },
        "42ec28c98a5d4da8a0baed3a6e87e2f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57beb33a1f6f4e319a595d203285b5d9",
            "placeholder": "​",
            "style": "IPY_MODEL_520dfc6be49141b98386bcea13ab2b73",
            "value": "config.json: 100%"
          }
        },
        "bb57831ce21d47049c6fe4b824524a68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d3ebeeb88d84aec962d481c6e1e5dd9",
            "max": 467,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7f79f53c6a024e5ca0980af3b76444b4",
            "value": 467
          }
        },
        "e24a38c2d8ce4a84af744b0c33f5c63c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af99549bc5844c89aae3b7130f5b67d2",
            "placeholder": "​",
            "style": "IPY_MODEL_ad8c62b4f37545048573db92d26c349a",
            "value": " 467/467 [00:00&lt;00:00, 27.4kB/s]"
          }
        },
        "ca2bed2832de41f9a3f27278696fe6af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57beb33a1f6f4e319a595d203285b5d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "520dfc6be49141b98386bcea13ab2b73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4d3ebeeb88d84aec962d481c6e1e5dd9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f79f53c6a024e5ca0980af3b76444b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "af99549bc5844c89aae3b7130f5b67d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad8c62b4f37545048573db92d26c349a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "451b1bb9ef194b82ada7b83b81b70903": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_56de0b78bbc64ee984757b641d7650e1",
              "IPY_MODEL_37a5f7c575b44d87a516669d11b06a34",
              "IPY_MODEL_8db6784fd3c446659fd7b8c0e16b57c3"
            ],
            "layout": "IPY_MODEL_697f6a367e2c42f0a5a6a079f21917dc"
          }
        },
        "56de0b78bbc64ee984757b641d7650e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a560d6156ed946149426b4e9a62adafc",
            "placeholder": "​",
            "style": "IPY_MODEL_5df64322742d4a09bcae99f4bd5f9bf1",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "37a5f7c575b44d87a516669d11b06a34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e9b4880d9e44d59b80d22c7051b7ec0",
            "max": 451741507,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ab30001f484d41c2ac3f862b47b1e654",
            "value": 451741507
          }
        },
        "8db6784fd3c446659fd7b8c0e16b57c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0efdcc5a111d49b8bc17646cb49be643",
            "placeholder": "​",
            "style": "IPY_MODEL_90c43553fab541d988cf17e67f2a9636",
            "value": " 452M/452M [00:02&lt;00:00, 241MB/s]"
          }
        },
        "697f6a367e2c42f0a5a6a079f21917dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a560d6156ed946149426b4e9a62adafc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5df64322742d4a09bcae99f4bd5f9bf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e9b4880d9e44d59b80d22c7051b7ec0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab30001f484d41c2ac3f862b47b1e654": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0efdcc5a111d49b8bc17646cb49be643": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90c43553fab541d988cf17e67f2a9636": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ce69dd4e51f4f7e86238a762c4c3584": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5a72a362d2834032b10af6a78cf70a43",
              "IPY_MODEL_be2c9b8406924a8d9f97d7d1a9d0f968",
              "IPY_MODEL_c430f4a321894252aa4bf804ba31ac07"
            ],
            "layout": "IPY_MODEL_72ce7d698c064dccb2f84cfe3ebb65ef"
          }
        },
        "5a72a362d2834032b10af6a78cf70a43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f957132881624743a91ad2a3d7fd0daf",
            "placeholder": "​",
            "style": "IPY_MODEL_e1fd59858d394f0988a71589f2d6fb45",
            "value": "model.safetensors: 100%"
          }
        },
        "be2c9b8406924a8d9f97d7d1a9d0f968": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22753606fe2b4b379ed0511bd8a1046d",
            "max": 451716860,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1f4a5412f6fc463cb321b5f851fe8589",
            "value": 451716860
          }
        },
        "c430f4a321894252aa4bf804ba31ac07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_afb12427fd9a493c950df6dce6436e28",
            "placeholder": "​",
            "style": "IPY_MODEL_8ca7096fd22f46bfaf23ea3b36013a44",
            "value": " 452M/452M [00:02&lt;00:00, 170MB/s]"
          }
        },
        "72ce7d698c064dccb2f84cfe3ebb65ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f957132881624743a91ad2a3d7fd0daf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1fd59858d394f0988a71589f2d6fb45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "22753606fe2b4b379ed0511bd8a1046d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f4a5412f6fc463cb321b5f851fe8589": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "afb12427fd9a493c950df6dce6436e28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ca7096fd22f46bfaf23ea3b36013a44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2eb64625b8ea40259aa3842d16b22613": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9709551ae20740e0b71b527756fc3475",
              "IPY_MODEL_3f9d9e28577644a4bc721c54a6628db2",
              "IPY_MODEL_4b2e6fa9cfbb49be9e12bf0b071fb5eb"
            ],
            "layout": "IPY_MODEL_7de25ac32d694bc3acfcb7f7525f8f9e"
          }
        },
        "9709551ae20740e0b71b527756fc3475": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7381dc1f6e3481da7dd22776175f4e2",
            "placeholder": "​",
            "style": "IPY_MODEL_699dceee7231421ebd0f8990643c3b2a",
            "value": "Loading checkpoint shards:   0%"
          }
        },
        "3f9d9e28577644a4bc721c54a6628db2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f39a5d7b16df48cc8cc9c15f10908946",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4d4b53e5709f40d8aea651288ebbb478",
            "value": 0
          }
        },
        "4b2e6fa9cfbb49be9e12bf0b071fb5eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed38f5b3f7f14baf8697da05179a390a",
            "placeholder": "​",
            "style": "IPY_MODEL_2d41565c793642b2b1d9e57cf0b6a103",
            "value": " 0/4 [00:00&lt;?, ?it/s]"
          }
        },
        "7de25ac32d694bc3acfcb7f7525f8f9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7381dc1f6e3481da7dd22776175f4e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "699dceee7231421ebd0f8990643c3b2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f39a5d7b16df48cc8cc9c15f10908946": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d4b53e5709f40d8aea651288ebbb478": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ed38f5b3f7f14baf8697da05179a390a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d41565c793642b2b1d9e57cf0b6a103": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9JXf8zejTrcn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed9ddddd-7815-47f9-99c7-c8a2f60fb195"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/KUBIG/DL/KUBIG_25-W STUDY/제출용/data\"\n",
        "#path = \"/content/drive/MyDrive/Colab Notebooks/NLP/KUBIG_25-W STUDY/제출용/data\""
      ],
      "metadata": {
        "id": "aN2arB-sT0PX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# data loading"
      ],
      "metadata": {
        "id": "HW_kMPiYT5Kv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 원본 데이터 : <br>\n",
        "TRAIN = pd.read_csv(path+\"/train.csv\")<br>\n",
        "TEST = pd.read_csv(path+\"/test.csv\")<br>\n",
        "\n",
        "- 원본 데이터 전처리 : <br>\n",
        "TRAIN_prep = pd.read_csv(path+\"/TRAIN_prep.csv\")<br>\n",
        "TEST_prep = pd.read_csv(path+\"/TEST_prep.csv\")<br>\n",
        "\n",
        "\n",
        "- train/valid split : <br>\n",
        "train_model = pd.read_csv(path+\"/train_model.csv\") <br>\n",
        "valid_model = pd.read_csv(path+\"/valid_model.csv\") <br>\n",
        "\n",
        "- train/valid split : <br>\n",
        "train_prep = pd.read_csv(path+\"/train_prep.csv\") <br>\n",
        "valid_prep = pd.read_csv(path+\"/valid_prep.csv\") <br>"
      ],
      "metadata": {
        "id": "fbkFjEX9bddC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "TRAIN = pd.read_csv(path+\"/train.csv\")\n",
        "TEST = pd.read_csv(path+\"/test.csv\")"
      ],
      "metadata": {
        "id": "Gvva3dCyT6ZD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing + Encoding"
      ],
      "metadata": {
        "id": "IEGxHBhhTxCz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import re\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "2NY_C7-2T8E8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessing(text):\n",
        "\n",
        "    start_code = 0xAC00 # 한글 시작 유니코드\n",
        "    end_code = 0xD7A3 # 한글 끝 유니코드\n",
        "\n",
        "    # 초성, 중성, 종성 리스트\n",
        "    cho = [chr(i) for i in range(0x1100, 0x1113)] # 초성 유니코드\n",
        "    jung = [chr(i) for i in range(0x1161, 0x1176)] # 중성 유니코드\n",
        "    jong = [chr(i) for i in range(0x11A8, 0x11C3)] # 종성 유니코드\n",
        "\n",
        "    chos = []\n",
        "    jungs = []\n",
        "    jongs = []\n",
        "    positions = []\n",
        "\n",
        "    cleaned_text = re.sub(r'[^\\uAC00-\\uD7A3\\s]', '', text)  # 한글과 공백만 남기기\n",
        "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text).strip()  # 중복 공백 제거\n",
        "\n",
        "\n",
        "    for char in cleaned_text:\n",
        "        if start_code <= ord(char) <= end_code:\n",
        "            char_code = ord(char) - start_code\n",
        "            cho_idx = char_code // (21 * 28)\n",
        "            jung_idx = (char_code % (21 * 28)) // 28\n",
        "            jong_idx = char_code % 28\n",
        "\n",
        "            # 초성, 중성\n",
        "            chos.append(cho[cho_idx])\n",
        "            jungs.append(jung[jung_idx])\n",
        "\n",
        "            # 종성 (없을 경우 'ㅉ'토큰; 받침에 올 수 없는 쌍자음)\n",
        "            jongs.append(jong[jong_idx - 1] if jong_idx > 0 else 'ㅉ')\n",
        "        else:\n",
        "            # 한글이 아닌 경우는 무시\n",
        "            continue\n",
        "\n",
        "    word_list = cleaned_text.split()  # 띄어쓰기 기준으로 단어 분리\n",
        "    for word in word_list:\n",
        "        for idx, _ in enumerate(word):\n",
        "            relative_pos = (idx + 1) / len(word)  # 현재 음절의 상대적 위치 계산\n",
        "            positions.append(round(relative_pos,2))\n",
        "\n",
        "    return chos, jungs, jongs, positions\n",
        "\n",
        "def extract_kr_char(text):\n",
        "    kr_chars = re.findall(r'[가-힣]', text)\n",
        "    return kr_chars\n",
        "\n",
        "\n",
        "def Encoder(data, jamo_to_index):\n",
        "  encoded_data = []\n",
        "  for jamos in data:\n",
        "    index_sequences = []\n",
        "    for jamo in jamos:\n",
        "      index_sequences.append(jamo_to_index[jamo])\n",
        "    encoded_data.append(index_sequences)\n",
        "  return encoded_data\n",
        "\n",
        "def preprocessing_encoding(df, train_flg = True):\n",
        "  df_prep = pd.DataFrame()\n",
        "  data = df.copy()\n",
        "\n",
        "  # 초성, 중성, 종성 유니코드 범위\n",
        "  cho = [chr(i) for i in range(0x1100, 0x1113)]  # 초성 (ㄱ~ㅎ)\n",
        "  jung = [chr(i) for i in range(0x1161, 0x1176)]  # 중성 (ㅏ~ㅣ)\n",
        "  jong = [chr(i) for i in range(0x11A8, 0x11C3)]  # 종성 (ㄱ~ㅄ)\n",
        "  jamo = cho + jung + jong + ['ㅉ']\n",
        "\n",
        "  jamo_to_index = {jamo[i]:i for i in range(len(jamo))}\n",
        "  index_to_jamo = {i:jamo[i] for i in range(len(jamo))}\n",
        "\n",
        "  for i in tqdm(range(len(data))):\n",
        "    chos, jungs, jongs, poss = preprocessing(data['input'][i])\n",
        "\n",
        "    chars = extract_kr_char(data['input'][i])\n",
        "\n",
        "    if train_flg:\n",
        "      orgs = extract_kr_char(data['output'][i])\n",
        "      chos_, jungs_, jongs_, _ = preprocessing(data['output'][i])\n",
        "\n",
        "      temp = pd.DataFrame({'index':i, '원본':orgs,'난독화':chars, '위치': poss,\n",
        "                        '초성':chos_, '중성': jungs_, '종성':jongs_,\n",
        "                        '난독화_초성':chos, '난독화_중성': jungs, '난독화_종성':jongs})\n",
        "    else:\n",
        "      temp = pd.DataFrame({'index':i,'난독화':chars, '위치': poss,\n",
        "                        '난독화_초성':chos, '난독화_중성': jungs, '난독화_종성':jongs})\n",
        "    df_prep = pd.concat([df_prep,temp])\n",
        "    df_prep.reset_index(drop=True, inplace=True)\n",
        "\n",
        "  if train_flg:\n",
        "    n = 4\n",
        "  else:\n",
        "    n = 3\n",
        "\n",
        "  data = df_prep.iloc[:,n:].values\n",
        "  encoded_data = Encoder(data, jamo_to_index)\n",
        "  encoded_data = np.array(encoded_data)\n",
        "\n",
        "  df_encoded = pd.DataFrame(encoded_data,\n",
        "                             columns=[f'{col}_ENC'for col in df_prep.columns[n:]])\n",
        "  df_prep = pd.concat([df_prep, df_encoded], axis=1)\n",
        "\n",
        "  return df_prep"
      ],
      "metadata": {
        "id": "3nhz59ogTwR7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_prep = preprocessing_encoding(TRAIN)\n",
        "TEST_prep = preprocessing_encoding(TEST, train_flg = False)"
      ],
      "metadata": {
        "id": "qkezWzigYS4z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "08ba1536-8609-475c-afe0-2698cac11737",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 1258/11263 [00:16<02:13, 74.93it/s]\n",
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-6-94c9b9d98122>\", line 1, in <cell line: 0>\n",
            "    TRAIN_prep = preprocessing_encoding(TRAIN)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-5-472dc66e051c>\", line 87, in preprocessing_encoding\n",
            "    df_prep = pd.concat([df_prep,temp])\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pandas/core/reshape/concat.py\", line 395, in concat\n",
            "    return op.get_result()\n",
            "           ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pandas/core/reshape/concat.py\", line 684, in get_result\n",
            "    new_data = concatenate_managers(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pandas/core/internals/concat.py\", line 177, in concatenate_managers\n",
            "    values = np.concatenate(vals, axis=1)  # type: ignore[arg-type]\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 1739, in getinnerframes\n",
            "    traceback_info = getframeinfo(tb, context)\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 1684, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "               ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 948, in getsourcefile\n",
            "    module = getmodule(object, filename)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 994, in getmodule\n",
            "    f = getabsfile(module)\n",
            "        ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 963, in getabsfile\n",
            "    _filename = getsourcefile(object) or getfile(object)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 932, in getsourcefile\n",
            "    def getsourcefile(object):\n",
            "    \n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "object of type 'NoneType' has no len()",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-94c9b9d98122>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mTRAIN_prep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessing_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mTEST_prep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessing_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTEST\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_flg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-472dc66e051c>\u001b[0m in \u001b[0;36mpreprocessing_encoding\u001b[0;34m(df, train_flg)\u001b[0m\n\u001b[1;32m     86\u001b[0m                         '난독화_초성':chos, '난독화_중성': jungs, '난독화_종성':jongs})\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0mdf_prep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_prep\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m     \u001b[0mdf_prep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 684\u001b[0;31m             new_data = concatenate_managers(\n\u001b[0m\u001b[1;32m    685\u001b[0m                 \u001b[0mmgrs_indexers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_axes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcat_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbm_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/internals/concat.py\u001b[0m in \u001b[0;36mconcatenate_managers\u001b[0;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[1;32m    176\u001b[0m                 \u001b[0;31m# _NestedSequence[_SupportsArray[dtype[Any]]]]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mis_1d_only_ea_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2098\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2099\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2099\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2101\u001b[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[1;32m   2102\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[1;32m   2103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_prep.to_csv(path+'/TRAIN_prep.csv', index=False)\n",
        "TEST_prep.to_csv(path+'/TEST_prep.csv', index=False)"
      ],
      "metadata": {
        "id": "SJ9CCcVIYhag",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "collapsed": true,
        "outputId": "a9095f44-f3cd-4dd5-aa45-0b450f733eae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'TRAIN_prep' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-7a2376afea3f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mTRAIN_prep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/TRAIN_prep.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mTEST_prep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/TEST_prep.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'TRAIN_prep' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 훈련을 위한 train, valid split"
      ],
      "metadata": {
        "id": "RAw5l5nNbmyM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN = pd.read_csv(path+\"/train.csv\")\n",
        "TEST = pd.read_csv(path+\"/test.csv\")"
      ],
      "metadata": {
        "id": "AAyueQJtg8Ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train = TRAIN.iloc[:,:-1], TRAIN.iloc[:,-1]\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "train_model = pd.concat([X_train, y_train], axis=1).reset_index(drop=True)\n",
        "valid_model = pd.concat([X_valid, y_valid], axis=1).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "ISPISj_Db5NU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model.to_csv(path+'/train_model.csv', index=False)\n",
        "valid_model.to_csv(path+'/valid_model.csv', index=False)"
      ],
      "metadata": {
        "id": "hsRZNCQMcA0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 전처리"
      ],
      "metadata": {
        "id": "iNH_mo78dQf2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_prep = preprocessing_encoding(train_model)\n",
        "valid_prep = preprocessing_encoding(valid_model)"
      ],
      "metadata": {
        "id": "VuNZQ4jYdQIS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8458d170-457b-42dd-ea3c-952bc7a542cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9010/9010 [06:41<00:00, 22.44it/s]\n",
            "100%|██████████| 2253/2253 [00:17<00:00, 129.95it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_prep.to_csv(path+'/train_prep.csv', index=False)\n",
        "valid_prep.to_csv(path+'/valid_prep.csv', index=False)"
      ],
      "metadata": {
        "id": "9CjLPfQQUiID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1차 해독 (MLP)"
      ],
      "metadata": {
        "id": "XwIJ3r_kYiqD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install -y fonts-nanum\n",
        "!sudo fc-cache -fv\n",
        "!rm ~/.cache/matplotlib -rf"
      ],
      "metadata": {
        "id": "3YfoQgiCYkdb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea4d012b-5428-45ce-a69f-baf0773d624b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  fonts-nanum\n",
            "0 upgraded, 1 newly installed, 0 to remove and 29 not upgraded.\n",
            "Need to get 10.3 MB of archives.\n",
            "After this operation, 34.1 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-nanum all 20200506-1 [10.3 MB]\n",
            "Fetched 10.3 MB in 2s (5,860 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package fonts-nanum.\n",
            "(Reading database ... 124947 files and directories currently installed.)\n",
            "Preparing to unpack .../fonts-nanum_20200506-1_all.deb ...\n",
            "Unpacking fonts-nanum (20200506-1) ...\n",
            "Setting up fonts-nanum (20200506-1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
            "/usr/share/fonts: caching, new cache contents: 0 fonts, 1 dirs\n",
            "/usr/share/fonts/truetype: caching, new cache contents: 0 fonts, 3 dirs\n",
            "/usr/share/fonts/truetype/humor-sans: caching, new cache contents: 1 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/liberation: caching, new cache contents: 16 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/nanum: caching, new cache contents: 12 fonts, 0 dirs\n",
            "/usr/local/share/fonts: caching, new cache contents: 0 fonts, 0 dirs\n",
            "/root/.local/share/fonts: skipping, no such directory\n",
            "/root/.fonts: skipping, no such directory\n",
            "/usr/share/fonts/truetype: skipping, looped directory detected\n",
            "/usr/share/fonts/truetype/humor-sans: skipping, looped directory detected\n",
            "/usr/share/fonts/truetype/liberation: skipping, looped directory detected\n",
            "/usr/share/fonts/truetype/nanum: skipping, looped directory detected\n",
            "/var/cache/fontconfig: cleaning cache directory\n",
            "/root/.cache/fontconfig: not cleaning non-existent cache directory\n",
            "/root/.fontconfig: not cleaning non-existent cache directory\n",
            "fc-cache: succeeded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import warnings\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import MultiStepLR\n",
        "import torch.optim as optim\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "plt.rc('font', family='NanumGothic')\n",
        "plt.rcParams['axes.unicode_minus'] = False"
      ],
      "metadata": {
        "id": "-P4XqU5hZY1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MLP training\n",
        "- AdamW + LR Scheduler"
      ],
      "metadata": {
        "id": "9Wwr9PuWcTqR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_prep = pd.read_csv(path+'/train_prep.csv')\n",
        "valid_prep = pd.read_csv(path+'/valid_prep.csv')"
      ],
      "metadata": {
        "id": "NW4eTU5LJJ7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train = train_prep.iloc[:,13:].values, train_prep.iloc[:,10:13].values\n",
        "X_valid, y_valid = valid_prep.iloc[:,13:].values, valid_prep.iloc[:,10:13].values\n",
        "\n",
        "X_train = torch.tensor(X_train, dtype=torch.long)\n",
        "y_train = torch.tensor(y_train, dtype=torch.long)\n",
        "X_valid = torch.tensor(X_valid, dtype=torch.long)\n",
        "y_valid = torch.tensor(y_valid, dtype=torch.long)"
      ],
      "metadata": {
        "id": "N41UnuiNcImK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X1_train = X_train\n",
        "X2_train = torch.tensor(train_prep.iloc[:,3].values, dtype = torch.float)\n",
        "X1_valid = X_valid\n",
        "X2_valid = torch.tensor(valid_prep.iloc[:,3].values, dtype = torch.float)"
      ],
      "metadata": {
        "id": "6x_Wfdz3d8aJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Embedding(nn.Module):\n",
        "    def __init__(self,embedding_dim, num_jamo=68):\n",
        "        super(Embedding, self).__init__()\n",
        "        self.jamo_embedding = nn.Embedding(num_jamo, embedding_dim//3)\n",
        "        self.pos_embedding = nn.Sequential(\n",
        "            nn.Linear(1, 8),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(8, embedding_dim%3)\n",
        "            )\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        x1 = self.jamo_embedding(x1)\n",
        "        x1 = x1.view(x1.size(0), -1)\n",
        "\n",
        "        x2 = x2.unsqueeze(-1)\n",
        "        x2 = self.pos_embedding(x2)\n",
        "\n",
        "        x = torch.cat([x2, x1], dim=-1)\n",
        "        return x\n",
        "\n",
        "class MLP(nn.Module):\n",
        "  def __init__(self, embedding_dim, hidden_dim):\n",
        "    super(MLP, self).__init__()\n",
        "    self.fc1 = nn.Linear(embedding_dim, hidden_dim)\n",
        "    self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
        "    self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "    self.bn2 = nn.BatchNorm1d(hidden_dim)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.fc1(x)\n",
        "    x = self.bn1(x)\n",
        "    x = torch.relu(x)\n",
        "    x = self.fc2(x) + x # skip connection\n",
        "    x = self.bn2(x)\n",
        "    x = torch.tanh(x)\n",
        "    return x\n",
        "class Decoder(nn.Module):\n",
        "  def __init__(self, hidden_dim = 128, embedding_dim = 64):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.embedding = Embedding(embedding_dim)\n",
        "    self.mlp = MLP(embedding_dim, hidden_dim)\n",
        "    self.fc = nn.Linear(hidden_dim, 68)\n",
        "\n",
        "  def forward(self, x1, x2):\n",
        "    x = self.embedding(x1,x2)\n",
        "    x = self.mlp(x)\n",
        "    x = self.fc(x)\n",
        "    return x\n",
        "\n",
        "def set_seed(seed: int = 42):\n",
        "    random.seed(seed)  # Python의 random 모듈 시드 고정\n",
        "    np.random.seed(seed)  # NumPy 시드 고정\n",
        "    torch.manual_seed(seed)  # PyTorch의 시드 고정\n",
        "    torch.cuda.manual_seed(seed)  # CUDA 시드 고정 (GPU 사용 시)\n",
        "    torch.cuda.manual_seed_all(seed)  # 다중 GPU 환경 시드 고정\n",
        "    torch.backends.cudnn.deterministic = True  # CUDNN 연산을 결정적으로 설정\n",
        "    torch.backends.cudnn.benchmark = False  # 연산 최적화 비활성화 (재현성 보장)\n",
        "\n",
        "set_seed(42)  # 원하는 시드 값 설정\n",
        "\n",
        "class CustomDataset(TensorDataset):\n",
        "    def __init__(self, jamo, position, labels):\n",
        "\n",
        "        self.jamo = jamo\n",
        "        self.position = position\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        jamo_sample = self.jamo[idx]\n",
        "        pos_sample = self.position[idx]\n",
        "        label = self.labels[idx]\n",
        "        return jamo_sample, pos_sample, label\n"
      ],
      "metadata": {
        "id": "5DAueOD-eBaE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 훈련 / 검증 데이터 분할 학습\n",
        "인사이트 도출용이므로 주석처리하고 넘어가도 됨"
      ],
      "metadata": {
        "id": "z-OmPbIWMRyg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4vT72KPDzGsb"
      },
      "outputs": [],
      "source": [
        "# from torch.optim import AdamW\n",
        "# from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# model = Decoder(hidden_dim = 256, embedding_dim = 128).to(device)\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# train_dataset = CustomDataset(X1_train, X2_train, y_train)\n",
        "# valid_dataset = CustomDataset(X1_valid, X2_valid, y_valid)\n",
        "\n",
        "# train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "# valid_loader = DataLoader(valid_dataset, batch_size=64, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ff7N1ApzGsb",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# import torch.optim as optim\n",
        "\n",
        "# optimizer = AdamW(model.parameters(), lr=0.001, weight_decay = 0.01)\n",
        "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=10)\n",
        "# # 10 epoch 동안 val_loss가 감소하지 않으면, 학습률 0.5 감소\n",
        "# model.train()\n",
        "\n",
        "# epochs = 200\n",
        "# loss_curve = np.zeros((2,epochs))\n",
        "# best_val_loss = float('inf')\n",
        "# save_path = path + \"/best_model.pth\"\n",
        "\n",
        "# for epoch in range(epochs):\n",
        "#     total_loss = 0\n",
        "#     # 학습\n",
        "#     for batch_idx, (jamo, pos, target) in enumerate(train_loader):\n",
        "#         optimizer.zero_grad()\n",
        "#         jamo, pos, target = jamo.to(device), pos.to(device), target.to(device)\n",
        "#         logits = model(jamo, pos)\n",
        "\n",
        "#         logit_cho = logits[:, :19]\n",
        "#         logit_jung = logits[:, 19:40]\n",
        "#         logit_jong = logits[:, 40:]\n",
        "\n",
        "#         loss1 = criterion(logit_cho, target[:, 0])\n",
        "#         loss2 = criterion(logit_jung, target[:, 1] - 19)\n",
        "#         loss3 = criterion(logit_jong, target[:, 2] - 40)\n",
        "#         loss = loss1 + loss2 + loss3\n",
        "\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "#         total_loss += loss.item()\n",
        "\n",
        "#         if batch_idx % 4500 == 0:\n",
        "#             print(f'Epoch: {epoch}, Batch: {batch_idx}, Loss: {loss.item()}')\n",
        "\n",
        "#     print(f'====> Epoch: {epoch}, Total Loss: {total_loss / (len(X_train) // 64):.4f}')\n",
        "#     loss_curve[0,epoch] = total_loss / (len(X_train) // 64)\n",
        "\n",
        "#     # 검증\n",
        "#     model.eval()\n",
        "#     val_loss = 0\n",
        "#     with torch.no_grad():\n",
        "#         for jamo, pos, target in valid_loader:\n",
        "#             jamo, pos, target = jamo.to(device), pos.to(device), target.to(device)\n",
        "#             logits = model(jamo, pos)\n",
        "\n",
        "#             logit_cho = logits[:, :19]\n",
        "#             logit_jung = logits[:, 19:40]\n",
        "#             logit_jong = logits[:, 40:]\n",
        "\n",
        "#             loss1 = criterion(logit_cho, target[:, 0])\n",
        "#             loss2 = criterion(logit_jung, target[:, 1] - 19)\n",
        "#             loss3 = criterion(logit_jong, target[:, 2] - 40)\n",
        "#             loss = loss1 + loss2 + loss3\n",
        "\n",
        "#             val_loss += loss.item()\n",
        "\n",
        "#     val_loss /= len(valid_loader)\n",
        "#     print(f'====> Validation Loss: {val_loss:.4f}')\n",
        "#     loss_curve[1,epoch] = val_loss\n",
        "#     scheduler.step(val_loss) # 스케줄러 업데이트\n",
        "\n",
        "#     if val_loss < best_val_loss:\n",
        "#         best_val_loss = val_loss\n",
        "#         torch.save({\n",
        "#             'epoch': epoch,\n",
        "#             'model_state_dict': model.state_dict(),\n",
        "#             'optimizer_state_dict': optimizer.state_dict(),\n",
        "#             'val_loss': best_val_loss,\n",
        "#         }, save_path)\n",
        "#         print(f\"Model Saved. (epoch: {epoch}, val_loss: {val_loss:.4f})\")\n",
        "#     model.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wWwCziIIzGsb",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# plt.plot(loss_curve[0], label='train')\n",
        "# plt.plot(loss_curve[1], label='valid')\n",
        "# plt.legend()\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 훈련 데이터 전체 학습"
      ],
      "metadata": {
        "id": "gYOgIMOuNQ3X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import AdamW\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = Decoder(hidden_dim = 256, embedding_dim = 128).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "X1_train = torch.vstack([X1_train, X1_valid])\n",
        "X2_train = torch.hstack([X2_train, X2_valid])\n",
        "y_train = torch.vstack([y_train, y_valid])\n",
        "\n",
        "train_dataset = CustomDataset(X1_train, X2_train, y_train)\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "zGcW3-_2fFU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = AdamW(model.parameters(), lr=0.001, weight_decay = 0.01)\n",
        "scheduler = MultiStepLR(optimizer, milestones = range(45,165,15), gamma=0.5)\n",
        "model.train()\n",
        "\n",
        "epochs = 200\n",
        "loss_curve = np.zeros((1,epochs))\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    total_loss = 0\n",
        "    # 학습\n",
        "    for batch_idx, (jamo, pos, target) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        jamo, pos, target = jamo.to(device), pos.to(device), target.to(device)\n",
        "        logits = model(jamo, pos)\n",
        "\n",
        "        logit_cho = logits[:, :19]\n",
        "        logit_jung = logits[:, 19:40]\n",
        "        logit_jong = logits[:, 40:]\n",
        "\n",
        "        loss1 = criterion(logit_cho, target[:, 0])\n",
        "        loss2 = criterion(logit_jung, target[:, 1] - 19)\n",
        "        loss3 = criterion(logit_jong, target[:, 2] - 40)\n",
        "        loss = loss1 + loss2 + loss3\n",
        "\n",
        "        lr = optimizer.param_groups[0]['lr']\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        if batch_idx % 4500 == 0:\n",
        "          lr = optimizer.param_groups[0]['lr']\n",
        "          print(f'Epoch: {epoch}, Batch: {batch_idx}, Loss: {loss.item()}, LR: {lr}')\n",
        "\n",
        "    print(f'====> Epoch: {epoch}, Total Loss: {total_loss / (len(X1_train) // 64):.4f}')\n",
        "    loss_curve[0,epoch] = total_loss / (len(X_train) // 64)\n",
        "    scheduler.step()\n",
        "\n",
        "    if epoch + 1 in range(50,201,10):\n",
        "      save_path = f\"{path}/full_model_{epoch+1}.pth\"\n",
        "      torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'scheduler_state_dict': scheduler.state_dict()\n",
        "        }, save_path)\n",
        "      print(f\"Model Saved. (epoch: {epoch+1})\")"
      ],
      "metadata": {
        "id": "ITUC_9qSfPlC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "1ad8dc8b-d9d2-4055-8696-3c83473ce220"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Batch: 0, Loss: 9.58500862121582, LR: 0.001\n",
            "Epoch: 0, Batch: 4500, Loss: 1.1189160346984863, LR: 0.001\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-ae8211494412>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(loss_curve[0], label='train')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CNloU2HLfj_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 해독"
      ],
      "metadata": {
        "id": "DHkxTpD4geFE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN = pd.read_csv(path+'/train.csv') #원본\n",
        "TRAIN_prep = pd.read_csv(path+'/TRAIN_prep.csv') #원본\n",
        "TEST = pd.read_csv(path+'/test.csv')\n",
        "TEST_prep = pd.read_csv(path+'/TEST_prep.csv')\n",
        "\n",
        "train = pd.read_csv(path+'/train_model.csv')\n",
        "train_prep = pd.read_csv(path+'/train_prep.csv')\n",
        "valid = pd.read_csv(path+'/valid_model.csv')\n",
        "valid_prep = pd.read_csv(path+'/valid_prep.csv')"
      ],
      "metadata": {
        "id": "5ksKzlS3ge5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cho = [chr(i) for i in range(0x1100, 0x1113)]  # 초성 (ㄱ~ㅎ)\n",
        "jung = [chr(i) for i in range(0x1161, 0x1176)]  # 중성 (ㅏ~ㅣ)\n",
        "jong = [chr(i) for i in range(0x11A8, 0x11C3)]  # 종성 (ㄱ~ㅄ)\n",
        "jamo = cho + jung + jong + ['ㅉ']\n",
        "\n",
        "jamo_to_index = {jamo[i]:i for i in range(len(jamo))}\n",
        "index_to_jamo = {i:jamo[i] for i in range(len(jamo))}"
      ],
      "metadata": {
        "id": "EU5jNlj5PlFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def combine_jamos(choseong_str, jungseong_str, jongseong_str='ㅉ'):\n",
        "\n",
        "    # 초성, 중성 인덱스 계산\n",
        "    choseong_index = cho.index(choseong_str)\n",
        "    jungseong_index = jung.index(jungseong_str)\n",
        "\n",
        "    # 종성 인덱스 계산 (받침 없는 경우 0으로 처리)\n",
        "    if jongseong_str == 'ㅉ':  # 받침이 없는 경우\n",
        "        jongseong_index = 0\n",
        "    else:\n",
        "        jongseong_index = jong.index(jongseong_str) + 1  # 종성은 1부터 시작\n",
        "\n",
        "    # 유니코드 한글 음절 계산\n",
        "    HANGUL_BASE = 0xAC00\n",
        "    syllable_code = (\n",
        "        HANGUL_BASE\n",
        "        + choseong_index * 21 * 28  # 초성\n",
        "        + jungseong_index * 28      # 중성\n",
        "        + jongseong_index           # 종성\n",
        "    )\n",
        "\n",
        "    return chr(syllable_code)\n"
      ],
      "metadata": {
        "id": "S8NWVZahQVm9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def inference(model, data, data_prep, index_to_jamo = index_to_jamo):\n",
        "\n",
        "  X1 = data_prep[['난독화_초성_ENC','난독화_중성_ENC','난독화_종성_ENC']].values\n",
        "  X2 = data_prep['위치'].values\n",
        "  X1, X2 = torch.tensor(X1, dtype = torch.long), torch.tensor(X2, dtype = torch.float)\n",
        "\n",
        "  model.eval()\n",
        "  model.to('cpu')\n",
        "\n",
        "  with torch.no_grad():\n",
        "    logits = model(X1, X2)\n",
        "    logit_cho = logits[:,:19]\n",
        "    logit_jung = logits[:,19:40]\n",
        "    logit_jong = logits[:,40:]\n",
        "\n",
        "  pred_cho = torch.argmax(logit_cho, dim=1)\n",
        "  pred_jung = torch.argmax(logit_jung, dim=1) + 19\n",
        "  pred_jong = torch.argmax(logit_jong, dim=1) + 40\n",
        "  pred_jamo = torch.stack([pred_cho, pred_jung, pred_jong], dim=1)\n",
        "\n",
        "  pred = pd.DataFrame(pred_jamo, columns=['초성', '중성', '종성'])\n",
        "  pred['결과'] = pred.apply(lambda x : combine_jamos(index_to_jamo[x['초성']],\n",
        "                                                   index_to_jamo[x['중성']],\n",
        "                                                   index_to_jamo[x['종성']]), axis =1)\n",
        "\n",
        "\n",
        "  chos = [chr(i) for i in range(0x1100, 0x1113)] # 초성 유니코드\n",
        "  jungs = [chr(i) for i in range(0x1161, 0x1176)] # 중성 유니코드\n",
        "  jongs = [chr(i) for i in range(0x11A8, 0x11C3)] # 종성 유니코드\n",
        "  jamo = chos + jungs + jongs + ['ㅉ']\n",
        "\n",
        "  jamo_to_index = {jamo[i]:i for i in range(len(jamo))}\n",
        "  index_to_jamo = {i:jamo[i] for i in range(len(jamo))}\n",
        "\n",
        "  decoded_sentences = []\n",
        "  i = 0\n",
        "\n",
        "  for _, sentence in data.iterrows():\n",
        "    decoded_sentence = ''\n",
        "    for char in sentence['input']:\n",
        "      if 0xAC00 <= ord(char) <= 0xD7A3:\n",
        "        decoded_sentence += pred.loc[i, '결과']\n",
        "        i += 1\n",
        "\n",
        "      else:\n",
        "        decoded_sentence += char\n",
        "    decoded_sentences.append(decoded_sentence)\n",
        "\n",
        "  return decoded_sentences, pred_jamo"
      ],
      "metadata": {
        "id": "tBmIvrnliNXr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_path = path+\"/full_model_140.pth\"\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "checkpoint = torch.load(save_path)\n",
        "model_ = Decoder(embedding_dim = 128, hidden_dim = 256).to(device)\n",
        "model_.load_state_dict(checkpoint['model_state_dict'])\n",
        "model_.to('cpu')\n",
        "\n",
        "def compute_accuracy(data, pred):\n",
        "  acc1 = (data.iloc[:,10:13].values == pred).all(axis=1).sum()/len(data)\n",
        "  acc2 = (data.iloc[:,10:13].values == pred).reshape(-1,).sum()/len(data)/3\n",
        "  return acc1, acc2"
      ],
      "metadata": {
        "id": "FaPFDCKUiWvr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def process_and_save_data(model, data, data_prep, dataset_type, path = path):\n",
        "    result, pred = inference(model, data, data_prep)\n",
        "    if dataset_type in ['train','TRAIN', 'valid']:\n",
        "      dec1_df = pd.DataFrame({\n",
        "        'input': data['input'],\n",
        "        'input_DEC1': result,\n",
        "        'output': data['output']\n",
        "        })\n",
        "    else:\n",
        "      dec1_df = pd.DataFrame({\n",
        "        'input': data['input'],\n",
        "        'input_DEC1': result\n",
        "        })\n",
        "\n",
        "    dec1_df.to_csv(path + f\"/{dataset_type}_dec1.csv\", index=False)\n",
        "    return dec1_df\n",
        "\n",
        "process_and_save_data(model_, TRAIN, TRAIN_prep, 'TRAIN')\n",
        "process_and_save_data(model_, train, train_prep, 'train')\n",
        "process_and_save_data(model_, valid, valid_prep, 'valid')\n",
        "process_and_save_data(model_, TEST, TEST_prep, 'TEST')"
      ],
      "metadata": {
        "id": "bguj4aHfjLJj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "48b6d76d-1a83-43ab-b79b-dc0c4633bdf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  input  \\\n",
              "0     녀뮨넒뭅 만죡숭러윤 효템뤼에오. 푸싸눼 옰면 콕 츄쩐학꼬 싶은 콧쉰웨오. 췌꾜윕뉘댜...   \n",
              "1     풀룐투갸 엎코, 좀식또 업읍머, 윌뱐 잎츔민든릿 샤있샤윔엡 위썬 호뗄첨렴 관뤽갉 찰...   \n",
              "2     쥔차 붉찐졀행욘. 삶먼섶 멂묽럿턴 혹텔 중웨 쬐약위였습뉜따. 칙어뉜쥐 샤쨩윈쥐 쩨끄...   \n",
              "3     붊 맛짚~~ 글련뎨 방움잃 뮈흙퍄녜용. 충칸 쏘움광 팔쿄닛갸 잊중짱임 야뉘럇셧 팜몌...   \n",
              "4     빻 샹택는 쥔쨔 폐헐 칙젓뉜테 쩐맣은 죠하욧. 뽀읾럭카 알쥬 찬쟌합꿰 똘앝썬 츄어서...   \n",
              "...                                                 ...   \n",
              "1684  윌뱐싫 5만언읽교, 쁘륌뮈얾 6만얹짧뤼눈 쓿딸윌려수, 앉먀긷됴 잊곪, PC툐 있찜많...   \n",
              "1685  윌탄 빵은 인풉곪, 패닯 음씩은 끎찌였섣 (외인쥔눈 윔뮨..) 륨셔삣술량 초쉭굻료 ...   \n",
              "1686  엔많함면 당쒸 앉 옭 옙졍윕닉댜. 겁율 욀뿡윕 있씁뉠단. 싫굘. 익견 머, 콴뤼할 ...   \n",
              "1687  돛짝 휴 쿠퀘 깊댓하찔 않앗는델 찌퀀뿐툴입 췬젊핫씩꼬 2빡 멎뭇눈 통얀 멘윌 캑실됴...   \n",
              "1688  찐꾸틂윌량 멸띱풂렉쑬륨멧써 툿쑥했는뎨 넒긷됴 넓교 궤읾핥 겯돎 많핫섭 좋얏섧오. 찐...   \n",
              "\n",
              "                                             input_DEC1  \n",
              "0     너문너무 만족스려운 호태리에요. 부사에 오면 꼭 추전하고 싶은 곳신에요. 최고입니다...  \n",
              "1     불론트가 없고, 조식도 없음며, 일반 이추인들이 사있사이에 이서 호텔점럼 관리가 잘...  \n",
              "2     진짜 불친절해요. 사면서 머물러던 호텔 중에 최아이었습니다. 직여니지 사장인지 체크...  \n",
              "3     블 맛집~~ 그런데 방음이 미흐파네요. 층간 소음과 발고니가 있중장이 아이라서 밤에...  \n",
              "4     방 상대는 진짜 페혀 직젔니데 전망은 조아요. 보일려가 아주 차자하게 돌았서 추여어...  \n",
              "...                                                 ...  \n",
              "1684  이반실 5만원이고, 프리미어 6만원짜리는 쓰다이러스, 않마기도 있고, PC도 있침만...  \n",
              "1685  일단 방은 인부고, 빼다 음식은 금치었서 (웨인지는 이문..) 룸서비스랑 조시구로 ...  \n",
              "1686  에많하면 다시 안 요 예정입니다. 거울 외풍이 있습니다. 실고. 이건 며, 관리할 ...  \n",
              "1687  도짝 후 크게 기대하지 않았는데 직원분들이 친절하시고 2박 멋무는 동안 메일 객실도...  \n",
              "1688  친크틀이랑 머디풀레스룸에서 투숙했는데 넓기도 넓고 게이할 것도 많아서 좋았어요. 친...  \n",
              "\n",
              "[1689 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-732b213e-b47e-4262-9d9c-c2f819e3a8c1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input</th>\n",
              "      <th>input_DEC1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>녀뮨넒뭅 만죡숭러윤 효템뤼에오. 푸싸눼 옰면 콕 츄쩐학꼬 싶은 콧쉰웨오. 췌꾜윕뉘댜...</td>\n",
              "      <td>너문너무 만족스려운 호태리에요. 부사에 오면 꼭 추전하고 싶은 곳신에요. 최고입니다...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>풀룐투갸 엎코, 좀식또 업읍머, 윌뱐 잎츔민든릿 샤있샤윔엡 위썬 호뗄첨렴 관뤽갉 찰...</td>\n",
              "      <td>불론트가 없고, 조식도 없음며, 일반 이추인들이 사있사이에 이서 호텔점럼 관리가 잘...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>쥔차 붉찐졀행욘. 삶먼섶 멂묽럿턴 혹텔 중웨 쬐약위였습뉜따. 칙어뉜쥐 샤쨩윈쥐 쩨끄...</td>\n",
              "      <td>진짜 불친절해요. 사면서 머물러던 호텔 중에 최아이었습니다. 직여니지 사장인지 체크...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>붊 맛짚~~ 글련뎨 방움잃 뮈흙퍄녜용. 충칸 쏘움광 팔쿄닛갸 잊중짱임 야뉘럇셧 팜몌...</td>\n",
              "      <td>블 맛집~~ 그런데 방음이 미흐파네요. 층간 소음과 발고니가 있중장이 아이라서 밤에...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>빻 샹택는 쥔쨔 폐헐 칙젓뉜테 쩐맣은 죠하욧. 뽀읾럭카 알쥬 찬쟌합꿰 똘앝썬 츄어서...</td>\n",
              "      <td>방 상대는 진짜 페혀 직젔니데 전망은 조아요. 보일려가 아주 차자하게 돌았서 추여어...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1684</th>\n",
              "      <td>윌뱐싫 5만언읽교, 쁘륌뮈얾 6만얹짧뤼눈 쓿딸윌려수, 앉먀긷됴 잊곪, PC툐 있찜많...</td>\n",
              "      <td>이반실 5만원이고, 프리미어 6만원짜리는 쓰다이러스, 않마기도 있고, PC도 있침만...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1685</th>\n",
              "      <td>윌탄 빵은 인풉곪, 패닯 음씩은 끎찌였섣 (외인쥔눈 윔뮨..) 륨셔삣술량 초쉭굻료 ...</td>\n",
              "      <td>일단 방은 인부고, 빼다 음식은 금치었서 (웨인지는 이문..) 룸서비스랑 조시구로 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1686</th>\n",
              "      <td>엔많함면 당쒸 앉 옭 옙졍윕닉댜. 겁율 욀뿡윕 있씁뉠단. 싫굘. 익견 머, 콴뤼할 ...</td>\n",
              "      <td>에많하면 다시 안 요 예정입니다. 거울 외풍이 있습니다. 실고. 이건 며, 관리할 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1687</th>\n",
              "      <td>돛짝 휴 쿠퀘 깊댓하찔 않앗는델 찌퀀뿐툴입 췬젊핫씩꼬 2빡 멎뭇눈 통얀 멘윌 캑실됴...</td>\n",
              "      <td>도짝 후 크게 기대하지 않았는데 직원분들이 친절하시고 2박 멋무는 동안 메일 객실도...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1688</th>\n",
              "      <td>찐꾸틂윌량 멸띱풂렉쑬륨멧써 툿쑥했는뎨 넒긷됴 넓교 궤읾핥 겯돎 많핫섭 좋얏섧오. 찐...</td>\n",
              "      <td>친크틀이랑 머디풀레스룸에서 투숙했는데 넓기도 넓고 게이할 것도 많아서 좋았어요. 친...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1689 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-732b213e-b47e-4262-9d9c-c2f819e3a8c1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-732b213e-b47e-4262-9d9c-c2f819e3a8c1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-732b213e-b47e-4262-9d9c-c2f819e3a8c1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-dced384a-7421-4180-b87f-3253f72baa0b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-dced384a-7421-4180-b87f-3253f72baa0b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-dced384a-7421-4180-b87f-3253f72baa0b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"process_and_save_data(model_, TEST, TEST_prep, 'TEST')\",\n  \"rows\": 1689,\n  \"fields\": [\n    {\n      \"column\": \"input\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1689,\n        \"samples\": [\n          \"\\ubc29\\uc6b0\\ubb88 \\uc580 \\ud1f4\\uadc4 \\ud578\\uc6a9. \\uc705\\uada4 \\ube75\\ub9cf\\ub2f7 \\ub5bc\\ub792\\uc4f0\\uae4c \\uc788\\uc372\\uc12d \\uc5ce\\ubc29 \\uc300\\ub78c\\ub730\\ub93c \\ud264\\ub77d\\uc218 \\ub09f\\uc654\\uc126 \\uba08\\ud590\\ub294 \\uc196\\ub9ad\\uae84 \\ub112\\ubba4 \\uc7d0 \\ub458\\ub9ad\\uad50, \\ub04a\\ud14c \\ubc29 \\uc9dc\\uccb8\\ub208 \\uce5c\\ucc3e \\ub112\\uce59\\ud590\\uad50 \\uc88b\\uc544\\uc694. \\uc778\\uc5ec\\ud460 \\ud0a5\\uacf5 \\ud6ac\\uc9f0 \\ub705\\uad76\\ucee4\\ub944 \\ud47c\\ucf00 \\ucb58\\uccd4.\",\n          \"\\uc881\\uc6a9\\ud788 \\uc26d\\ub531\\ucead\\uae3a \\uc88b\\uc6b4 \\uacf6 \\uac07\\ud0f8\\uc6a9.\",\n          \"\\uc379\\ube5b\\uc218\\ub208 \\ucdec\\uc808\\ud590\\uc528\\uaf2c, \\uc528\\uc15c\\uc6b4 \\uc87a \\uc694\\ub798\\ub664\\uc5bb\\uc501\\ub258\\ub2f3. \\ucc98\\ub208 \\ub9ce\\ucd09\\uae7b\\ub208\\ub5bc, \\ubbfc\\uce84\\ud55c \\ubd84\\ub208 \\uc601\\ub5aa\\ucc27 \\ubab2\\ub975\\ucf13\\uc5bb\\uc6a4.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"input_DEC1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1689,\n        \"samples\": [\n          \"\\ubc29\\uc73c\\uc774 \\uc548 \\ub418\\uae34 \\ud574\\uc694. \\uc774\\uac8c \\ubc29\\ub9c8\\ub2e4 \\ud0dc\\ub790\\uc2a4\\uac00 \\uc788\\uc124\\uc11c \\uc5c6\\ubc29 \\uc0ac\\ub78c\\ub4e4\\ub9ac \\ud14c\\ub77c\\uc2a4 \\ub098\\uc640\\uc11c \\ub9d0\\uc544\\ub294 \\uc18c\\ub9ac\\uac00 \\ub108\\ubb34 \\uc798 \\ub4e4\\ub9ac\\uace0, \\uadfc\\ub370 \\ubc29 \\uc790\\uc81c\\ub294 \\uc9c4\\ucc28 \\ub108\\uc9c1\\ud558\\uace0 \\uc88b\\uc57c\\uc694. \\uc778\\uc5b4\\ubcf8 \\uae30\\uace0 \\ud63c\\uc9dc \\ub6f0\\uadf8\\uac70\\ub9b4 \\ubd84\\uac8c \\uc8fc\\ucc9c.\",\n          \"\\uc881\\uc6a9\\ud788 \\uc2dc\\ud0c1\\ud558\\uae38 \\uc88b\\uc740 \\uace0 \\uac19\\uc544\\uc694.\",\n          \"\\uc11c\\ube44\\uc2a4\\ub294 \\uce5c\\uc808\\ud558\\uc2dc\\uace0, \\uc2dc\\uc124\\uc740 \\uc880 \\uc624\\ub798\\ub418\\uc5c8\\uc2b5\\ub2c8\\ub2e4. \\uc800\\ub294 \\ub9cc\\uc871\\ud588\\ub294\\ub370, \\ubbfc\\uac00\\ud55c \\ubdf0\\ub294 \\uc5ec\\ud130\\uc9c0 \\ubaa8\\ub974\\uaca0\\uc5b4\\uc694.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2차 해독 _electra"
      ],
      "metadata": {
        "id": "FFGvq2baj3cb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv(path+\"/TRAIN_dec1.csv\")\n",
        "test = pd.read_csv(path+\"/TEST_dec1.csv\")"
      ],
      "metadata": {
        "id": "FZUSuEZXj6_J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chunking"
      ],
      "metadata": {
        "id": "YXaY2mqWz-6N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "    # 1. 한국어(가-힣), 영어(a-zA-Z), 숫자(0-9), 공백(\\s) 외 특수문자 제거\n",
        "    text = re.sub(r'[^가-힣a-zA-Z0-9\\s(),.!?\\'\\\"\\[\\]\\{\\}:]', '', text)\n",
        "\n",
        "    # 2. ㅋㅋ, ㅜㅜ, ㅠㅠ, ㅎㅎ 등과 같은 불완전한 한글 제거\n",
        "    text = re.sub(r'[ㄱ-ㅎㅏ-ㅣ]', '', text)\n",
        "\n",
        "    return text\n",
        "\n",
        "def split_sentences(text):\n",
        "    # 온점, 느낌표, 물음표 뒤에 공백이 있으면 모두 분리\n",
        "    sentences = re.split(r'(?<=[.!?])\\s', text)\n",
        "    return [sentence for sentence in sentences if sentence]\n",
        "\n",
        "def clean_blank(text):\n",
        "    text = text.strip()  # 좌우 공백 제거\n",
        "    text = re.sub(r'\\s+', ' ', text)  # 연속된 공백을 하나로 변환\n",
        "    return text"
      ],
      "metadata": {
        "id": "WtbizK8Ty-j3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train['cleaned_input'] = train['input_DEC1'].apply(clean_text)\n",
        "test['cleaned_input'] = test['input_DEC1'].apply(clean_text)\n",
        "train['cleaned_output'] = train['output'].apply(clean_text)"
      ],
      "metadata": {
        "id": "sYtpP-lld8mO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train['chunked_input'] = train['cleaned_input'].apply(split_sentences)\n",
        "test['chunked_input'] = test['cleaned_input'].apply(split_sentences)\n",
        "train['chunked_output'] = train['cleaned_output'].apply(split_sentences)\n",
        "\n",
        "train_exploded = train.explode('chunked_input')[['chunked_input']].reset_index(drop=False)\n",
        "train_exploded_ = train.explode('chunked_output')[['chunked_output']].reset_index(drop=True)\n",
        "\n",
        "test_chunked = test.explode('chunked_input')[['chunked_input']].reset_index(drop=False)\n",
        "train_chunked = pd.concat([train_exploded, train_exploded_], axis=1)"
      ],
      "metadata": {
        "id": "Zm9DmgZg7uqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_chunked['chunked_input'].apply(len).sort_values(ascending=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "gAQ2j1UC8K1l",
        "outputId": "9a96f56b-2dfb-44fb-db31-cf8213ab8543"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2435     804\n",
              "33234    377\n",
              "14865    369\n",
              "14625    363\n",
              "26793    297\n",
              "        ... \n",
              "14335      1\n",
              "16318      1\n",
              "19027      1\n",
              "8303       1\n",
              "24692      1\n",
              "Name: chunked_input, Length: 34578, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>chunked_input</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2435</th>\n",
              "      <td>804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33234</th>\n",
              "      <td>377</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14865</th>\n",
              "      <td>369</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14625</th>\n",
              "      <td>363</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26793</th>\n",
              "      <td>297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14335</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16318</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19027</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8303</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24692</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>34578 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_chunked.loc[2435]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "GRPYbb5a8ZhL",
        "outputId": "43765685-7e1d-4199-8df9-2a76d23cca05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "index                                                           658\n",
              "chunked_input     [스때다트]  일지: 59층   전망: 시티 뷰   침대 타이: 더블, 트인   객...\n",
              "chunked_output    [스탠다드]  위치: 59층   전망: 시티 뷰   침대 타입: 더블, 트윈   객...\n",
              "Name: 2435, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>2435</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <td>658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>chunked_input</th>\n",
              "      <td>[스때다트]  일지: 59층   전망: 시티 뷰   침대 타이: 더블, 트인   객...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>chunked_output</th>\n",
              "      <td>[스탠다드]  위치: 59층   전망: 시티 뷰   침대 타입: 더블, 트윈   객...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_chunked[train_chunked['index'] == 658]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "wuI20zkC86KT",
        "outputId": "d3cbf942-7c6f-4ff9-aecf-a26d06aefe0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      index                                      chunked_input  \\\n",
              "2435    658  [스때다트]  일지: 59층   전망: 시티 뷰   침대 타이: 더블, 트인   객...   \n",
              "2436    658    이 기간 있후 치속 돈는 편경 식 (No Show 보함)    성수기 (4, 5...   \n",
              "\n",
              "                                         chunked_output  \n",
              "2435  [스탠다드]  위치: 59층   전망: 시티 뷰   침대 타입: 더블, 트윈   객...  \n",
              "2436    위 기간 이후 취소 또는 변경 시 (No Show 포함)    성수기 (4, 5...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ae66adb6-f480-4128-a4ed-834b24435963\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>chunked_input</th>\n",
              "      <th>chunked_output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2435</th>\n",
              "      <td>658</td>\n",
              "      <td>[스때다트]  일지: 59층   전망: 시티 뷰   침대 타이: 더블, 트인   객...</td>\n",
              "      <td>[스탠다드]  위치: 59층   전망: 시티 뷰   침대 타입: 더블, 트윈   객...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2436</th>\n",
              "      <td>658</td>\n",
              "      <td>이 기간 있후 치속 돈는 편경 식 (No Show 보함)    성수기 (4, 5...</td>\n",
              "      <td>위 기간 이후 취소 또는 변경 시 (No Show 포함)    성수기 (4, 5...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ae66adb6-f480-4128-a4ed-834b24435963')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ae66adb6-f480-4128-a4ed-834b24435963 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ae66adb6-f480-4128-a4ed-834b24435963');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e4db0ba4-b1a3-4974-9bf0-63ec4049c437\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e4db0ba4-b1a3-4974-9bf0-63ec4049c437')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e4db0ba4-b1a3-4974-9bf0-63ec4049c437 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"train_chunked[train_chunked['index'] == 658]\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"index\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 658,\n        \"max\": 658,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          658\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chunked_input\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"  \\uc774 \\uae30\\uac04 \\uc788\\ud6c4 \\uce58\\uc18d \\ub3c8\\ub294 \\ud3b8\\uacbd \\uc2dd (No Show \\ubcf4\\ud568)    \\uc131\\uc218\\uae30 (4, 5, 6, 10, 11\\uc6d4, 1224, 1231): \\ucd5c\\ucd08 1\\ubc15 \\uc62c\\uae08\\uc758 80 \\ubdf0\\uacfc    \\ud53c\\uc218\\uae30 (\\uc131\\uc218\\uae30 \\uc678 \\uae30\\uac04): \\ucd5c\\uc878 1\\ubc15 \\uc694\\uae08\\uc774 10 \\ud479\\uacfc\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chunked_output\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"  \\uc704 \\uae30\\uac04 \\uc774\\ud6c4 \\ucde8\\uc18c \\ub610\\ub294 \\ubcc0\\uacbd \\uc2dc (No Show \\ud3ec\\ud568)    \\uc131\\uc218\\uae30 (4, 5, 6, 10, 11\\uc6d4, 1224, 1231): \\ucd5c\\ucd08 1\\ubc15 \\uc694\\uae08\\uc758 80 \\ubd80\\uacfc    \\ube44\\uc218\\uae30 (\\uc131\\uc218\\uae30 \\uc678 \\uae30\\uac04): \\ucd5c\\ucd08 1\\ubc15 \\uc694\\uae08\\uc758 10 \\ubd80\\uacfc\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 청킹 후에도 긴 문장에 대해 수동 분할\n",
        "input1, input2 = train_chunked.iloc[2435][1][:423], train_chunked.iloc[2435][1][424:]\n",
        "input3 = train_chunked.iloc[2436][1]\n",
        "output1, output2 = train_chunked.iloc[2435][2][:423], train_chunked.iloc[2435][2][424:]\n",
        "output3 = train_chunked.iloc[2436][2]\n",
        "temp = pd.DataFrame({'index':[658,658,658], 'chunked_input':[input1,input2,input3],\n",
        "                     'chunked_output':[output1,output2,output3]})\n",
        "train_chunked.drop(index=[2435,2436], inplace=True)\n",
        "train_chunked = pd.concat([train_chunked, temp]).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "JC2CJMoA8sro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_chunked"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "_k9Y_BLlBeR9",
        "outputId": "08bd3e25-06f9-4b57-90a7-4b54e780552d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       index                                      chunked_input  \\\n",
              "0          0                                        별 한 개도 아깝다.   \n",
              "1          0  외 사람들이 별 1개를 준는지 걱거본 사람으로서 말로 설명하자니 대끔로는 너무 기고...   \n",
              "2          0                                아무은 두 번 다시 가길 실은 고.   \n",
              "3          0                     캠핑을 20어 년 다넉본 고 중 제일 기분 나파던 고.   \n",
              "4          1                                     잠만 작고 가 대 좋네요.   \n",
              "...      ...                                                ...   \n",
              "34574  11262                     품 그리고 룸서비스가 가겨기 저렴한 것에 비해 마이음.   \n",
              "34575  11262                      룸서비을 음시을 먹고 싶뻐어 도 가고 싶쁜 건 처음.   \n",
              "34576    658  [스때다트]  일지: 59층   전망: 시티 뷰   침대 타이: 더블, 트인   객...   \n",
              "34577    658  [체그인최크아웃 시간]   체금인: 오후 3시 이후   체크아웃: 정요    [주차...   \n",
              "34578    658    이 기간 있후 치속 돈는 편경 식 (No Show 보함)    성수기 (4, 5...   \n",
              "\n",
              "                                          chunked_output  \n",
              "0                                            별 한 개도 아깝다.  \n",
              "1      왜 사람들이 별 1개를 주는지 겪어본 사람으로서 말로 설명하자니 댓글로는 너무 길고...  \n",
              "2                                    아무튼 두 번 다시 가길 싫은 곳.  \n",
              "3                         캠핑을 20여 년 다녀본 곳 중 제일 기분 나빴던 곳.  \n",
              "4                                         잠만 자고 갈 때 좋네요.  \n",
              "...                                                  ...  \n",
              "34574                     뷰 그리고 룸서비스가 가격이 저렴한 것에 비해 맛있음.  \n",
              "34575                      룸서비스 음식을 먹고 싶어서 또 가고 싶은 건 처음.  \n",
              "34576  [스탠다드]  위치: 59층   전망: 시티 뷰   침대 타입: 더블, 트윈   객...  \n",
              "34577  [체크인체크아웃 시간]   체크인: 오후 3시 이후   체크아웃: 정오    [주차...  \n",
              "34578    위 기간 이후 취소 또는 변경 시 (No Show 포함)    성수기 (4, 5...  \n",
              "\n",
              "[34579 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c25a6db4-ce22-435c-a662-4aae10c65282\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>chunked_input</th>\n",
              "      <th>chunked_output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>별 한 개도 아깝다.</td>\n",
              "      <td>별 한 개도 아깝다.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>외 사람들이 별 1개를 준는지 걱거본 사람으로서 말로 설명하자니 대끔로는 너무 기고...</td>\n",
              "      <td>왜 사람들이 별 1개를 주는지 겪어본 사람으로서 말로 설명하자니 댓글로는 너무 길고...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>아무은 두 번 다시 가길 실은 고.</td>\n",
              "      <td>아무튼 두 번 다시 가길 싫은 곳.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>캠핑을 20어 년 다넉본 고 중 제일 기분 나파던 고.</td>\n",
              "      <td>캠핑을 20여 년 다녀본 곳 중 제일 기분 나빴던 곳.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>잠만 작고 가 대 좋네요.</td>\n",
              "      <td>잠만 자고 갈 때 좋네요.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34574</th>\n",
              "      <td>11262</td>\n",
              "      <td>품 그리고 룸서비스가 가겨기 저렴한 것에 비해 마이음.</td>\n",
              "      <td>뷰 그리고 룸서비스가 가격이 저렴한 것에 비해 맛있음.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34575</th>\n",
              "      <td>11262</td>\n",
              "      <td>룸서비을 음시을 먹고 싶뻐어 도 가고 싶쁜 건 처음.</td>\n",
              "      <td>룸서비스 음식을 먹고 싶어서 또 가고 싶은 건 처음.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34576</th>\n",
              "      <td>658</td>\n",
              "      <td>[스때다트]  일지: 59층   전망: 시티 뷰   침대 타이: 더블, 트인   객...</td>\n",
              "      <td>[스탠다드]  위치: 59층   전망: 시티 뷰   침대 타입: 더블, 트윈   객...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34577</th>\n",
              "      <td>658</td>\n",
              "      <td>[체그인최크아웃 시간]   체금인: 오후 3시 이후   체크아웃: 정요    [주차...</td>\n",
              "      <td>[체크인체크아웃 시간]   체크인: 오후 3시 이후   체크아웃: 정오    [주차...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34578</th>\n",
              "      <td>658</td>\n",
              "      <td>이 기간 있후 치속 돈는 편경 식 (No Show 보함)    성수기 (4, 5...</td>\n",
              "      <td>위 기간 이후 취소 또는 변경 시 (No Show 포함)    성수기 (4, 5...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>34579 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c25a6db4-ce22-435c-a662-4aae10c65282')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c25a6db4-ce22-435c-a662-4aae10c65282 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c25a6db4-ce22-435c-a662-4aae10c65282');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-40eaa3d6-2d98-4cc2-ac59-32921136900d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-40eaa3d6-2d98-4cc2-ac59-32921136900d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-40eaa3d6-2d98-4cc2-ac59-32921136900d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_f48b9ece-4ad6-4541-9c06-5e9316309e75\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('train_chunked')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_f48b9ece-4ad6-4541-9c06-5e9316309e75 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('train_chunked');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_chunked",
              "summary": "{\n  \"name\": \"train_chunked\",\n  \"rows\": 34579,\n  \"fields\": [\n    {\n      \"column\": \"index\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3308,\n        \"min\": 0,\n        \"max\": 11262,\n        \"num_unique_values\": 11263,\n        \"samples\": [\n          6928,\n          1670,\n          9500\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chunked_input\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 33663,\n        \"samples\": [\n          \"\\ucc38\\uace0\\ud589\\uc8fc\\uc138\\uc694.\",\n          \"\\ud589\\uc0ac\\uac00 \\uc774\\ud6c4 \\ub2f9\\uc77c \\uce58\\uc18c\",\n          \"\\uc9c1\\uc6d0\\ubd84\\ub4e4\\uc740 \\uc815\\ub9d0 \\uce5c\\uc808\\ud569\\ub2c8\\ub2e4!!\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chunked_output\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 33105,\n        \"samples\": [\n          \"\\ubc29\\uc74c \\uc548 \\ub428 (\\uc606 \\ubc29 \\ub300\\ud654 \\uc18c\\ub9ac)   2.\",\n          \"\\ub2e4\\ub9cc, \\uc870\\uc2dd\\uc744 \\uba39\\uc744 \\uc2e4\\ub0b4 \\uacf5\\uac04\\uc774 \\uc5c6\\uae34 \\ud55c\\ub370 \\uac74\\ub108\\ud3b8 \\ud22c\\uc378\\ud50c\\ub808\\uc774\\uc2a4\\uc5d0\\uc11c \\ud638\\ud154 \\ub77c\\uc6b4\\uc9c0 \\uac19\\uc740 \\ub290\\ub08c\\uc73c\\ub85c \\ube0c\\ub7f0\\uce58\\ub97c \\uba39\\uc744 \\uc218 \\uc788\\uc5b4\\uc694.\",\n          \"\\ub974\\uc0b4\\ub871 \\uae30\\ub300 \\uc774\\ud558, \\uc560\\ud504\\ud130\\ub208 \\ud2f0\\ub294 \\ud615\\ud3b8\\uc5c6\\uc74c(\\ud2b9\\ud788 \\ucee4\\ud53c \\ub108\\ubb34 \\ubcc4\\ub85c), \\ub531\\ud788 \\uc7ac\\ubc29\\ubb38\\ud560 \\ub9cc\\ud55c \\ub9e4\\ub825\\uc801\\uc778 \\uc694\\uc18c\\uac00 \\ud558\\ub098\\ub3c4 \\uc5c6\\uc74c\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_chunked['chunked_input'] = train_chunked.apply(lambda x: clean_blank(x['chunked_input']), axis = 1)\n",
        "train_chunked['chunked_output'] = train_chunked.apply(lambda x: clean_blank(x['chunked_output']), axis = 1)\n",
        "train_chunked['len'] = train_chunked['chunked_input'].apply(len)\n",
        "train_chunked.drop(train_chunked[train_chunked['len'] == 0].index, inplace=True)\n",
        "train_chunked.reset_index(drop=True, inplace=True)\n",
        "\n",
        "test_chunked['chunked_input'] = test_chunked.apply(lambda x: clean_blank(x['chunked_input']), axis = 1)\n",
        "test_chunked['len'] = test_chunked['chunked_input'].apply(len)\n",
        "test_chunked.drop(test_chunked[test_chunked['len'] == 0].index, inplace=True)\n",
        "test_chunked.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "IbgD7kCW0OdK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_chunked.drop(columns=['len'], inplace=True)\n",
        "test_chunked.drop(columns=['len'], inplace=True)"
      ],
      "metadata": {
        "id": "BHtcowES9tD5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_chunked.to_csv(path+\"/TRAIN_dec1_chunked.csv\", index=False)\n",
        "test_chunked.to_csv(path+\"/TEST_dec1_chunked.csv\", index=False)"
      ],
      "metadata": {
        "id": "dYxd4O470oX1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_chunked = pd.read_csv(path+\"/TRAIN_dec1_chunked.csv\")\n",
        "test_chunked = pd.read_csv(path+\"/TEST_dec1_chunked.csv\")"
      ],
      "metadata": {
        "id": "Eb8kLYbpVPS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utils"
      ],
      "metadata": {
        "id": "cLzKxkSI3KQ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "import json"
      ],
      "metadata": {
        "id": "JdI9b63Z4zJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def restore_original_text(original_text, decoded_text):\n",
        "\n",
        "    restored_text = \"\"\n",
        "    decoded_idx = 0\n",
        "    # 한글, 영어, 숫자, 공백, 문장부호만 허용하는 정규식\n",
        "    valid_char_pattern = re.compile(r'[가-힣a-zA-Z0-9(),.!?\\'\\\"\\[\\]\\{\\}:]')\n",
        "\n",
        "\n",
        "    for char in original_text:\n",
        "        if valid_char_pattern.match(char):\n",
        "            # 유효한 문자일 경우, 해독된 문자로 대체\n",
        "            if decoded_idx < len(decoded_text):\n",
        "                restored_text += decoded_text[decoded_idx]\n",
        "                decoded_idx += 1\n",
        "            else:\n",
        "                # 만약 해독된 텍스트가 끝났다면 원문 문자 그대로 추가\n",
        "                restored_text += char\n",
        "        else:\n",
        "            # 특수문자 및 불완전한 한글은 원문 그대로 유지\n",
        "            restored_text += char\n",
        "\n",
        "    return restored_text"
      ],
      "metadata": {
        "id": "WCFer7JG3OYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CSV 파일을 JSON 파일로 변환하는 함수\n",
        "def csv_to_json(csv_file_path, json_file_path):\n",
        "    with open(csv_file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        reader = csv.DictReader(f)\n",
        "        data = list(reader)\n",
        "\n",
        "    # JSON 파일 저장\n",
        "    with open(json_file_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(data, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "csv_file_path = path+\"/TRAIN_dec1_chunked.csv\"\n",
        "json_file_path = path+\"/TRAIN_dataset.json\"  # 변환할 JSON 파일 경로\n",
        "\n",
        "csv_to_json(csv_file_path, json_file_path)\n",
        "print(f\"변환 완료: {json_file_path}\")"
      ],
      "metadata": {
        "id": "cfIjTHjK3YPo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4fe30e9-c297-41c5-9408-fa4ba76b3b5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "변환 완료: /content/drive/MyDrive/KUBIG/DL/KUBIG_25-W STUDY/제출용/data/TRAIN_dataset.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sentencepiece as spm\n",
        "import os\n",
        "# SentencePiece 모델 학습 (음절 단위)\n",
        "os.chdir(path)\n",
        "spm.SentencePieceTrainer.Train(f'--input=TRAIN_dataset.json --model_prefix=syllable --vocab_size=12000 --character_coverage=1.0 --model_type=char')\n",
        "\n",
        "# SentencePiece 모델 로드\n",
        "sp = spm.SentencePieceProcessor()\n",
        "sp.Load(\"syllable.model\")"
      ],
      "metadata": {
        "id": "ImDeHJey3bdj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb31ae07-911d-424d-a6ce-f20c214f9ec5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "Gj4ZL6-t38dy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "train = pd.read_csv(path+\"/TRAIN_dec1.csv\")\n",
        "test = pd.read_csv(path+\"/TEST_dec1.csv\")\n",
        "\n",
        "train_chunked = pd.read_csv(path+\"/TRAIN_dec1_chunked.csv\")\n",
        "test_chunked = pd.read_csv(path+\"/TEST_dec1_chunked.csv\")"
      ],
      "metadata": {
        "id": "Q5tjaWis39oz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import ElectraTokenizer, ElectraForMaskedLM\n",
        "import sentencepiece as spm\n",
        "\n",
        "# 기존 KoELECTRA 모델의 토크나이저 로드\n",
        "base_tokenizer = ElectraTokenizer.from_pretrained(\"monologg/koelectra-base-v3-discriminator\")\n",
        "\n",
        "tokenizer_path = path+\"/syllable.model\"\n",
        "vocab_path = path+\"/syllable.vocab\"\n",
        "\n",
        "# SentencePiece를 이용한 커스텀 토크나이저 적용\n",
        "class CustomTokenizer(ElectraTokenizer):\n",
        "    def __init__(self, sp_model_path, *args, **kwargs):\n",
        "        super().__init__(vocab_file=vocab_path, *args, **kwargs)\n",
        "        self.sp_model = spm.SentencePieceProcessor()\n",
        "        self.sp_model.Load(sp_model_path)\n",
        "\n",
        "    def tokenize(self, text):\n",
        "        return self.sp_model.EncodeAsPieces(text)\n",
        "\n",
        "    def convert_tokens_to_ids(self, tokens):\n",
        "        return [self.sp_model.PieceToId(token) for token in tokens]\n",
        "\n",
        "    def convert_ids_to_tokens(self, ids):\n",
        "        return [self.sp_model.IdToPiece(id) for id in ids]\n",
        "\n",
        "# Custom Tokenizer 생성\n",
        "custom_tokenizer = CustomTokenizer(tokenizer_path)\n",
        "\n",
        "# KoELECTRA 모델 로드\n",
        "model = ElectraForMaskedLM.from_pretrained(\"monologg/koelectra-base-v3-discriminator\")"
      ],
      "metadata": {
        "id": "lnpMmBwa4c7q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200,
          "referenced_widgets": [
            "63f757a14885421b876bd99214c5636b",
            "746cd7e2ba15454790c2f58a7f7df0e3",
            "8c034bd209af471d97eee7df94fb8f8d",
            "b1aef8141295436387ece3b678967602",
            "3db14c4ea3714aae9cb309c64897ceb9",
            "59fb587367d54bc39fa98dcf0495cdd4",
            "7aea5bd645444b41913183ce4c9f70de",
            "731b4e8fd192453fa8f72599b8f5e94c",
            "77948f51680c43cc8a8ce7db5a270c92",
            "9a8d6c56ff6b4ba49b16bee9c58ea63d",
            "ccd1cacdb5ac43f69486a9d71878f6e2",
            "34a261aba31948b2a48ecd52dd16ea33",
            "55ba41beab3b43e7b5952f79affb8956",
            "6e91f30374fb43638a279e909bf65257",
            "c36705ace08344d39b2a3b517c5393e3",
            "352fb41bef8143ecb7e88bb38bc07922",
            "6365c2f6f50b4e0f97b4f314ad0b995f",
            "75dd04735e6c461ebfa410a8393f156a",
            "fc8938d9648642bbbeebd45c339150bd",
            "0b8fbdc61fd54e62aaacd56177675f90",
            "af1eaad40bf6443eb1a85bae134caf7f",
            "241626cd290d472a8a95f7abb769287a",
            "f5ced24fd40845a997ddd80d83cac05b",
            "42ec28c98a5d4da8a0baed3a6e87e2f8",
            "bb57831ce21d47049c6fe4b824524a68",
            "e24a38c2d8ce4a84af744b0c33f5c63c",
            "ca2bed2832de41f9a3f27278696fe6af",
            "57beb33a1f6f4e319a595d203285b5d9",
            "520dfc6be49141b98386bcea13ab2b73",
            "4d3ebeeb88d84aec962d481c6e1e5dd9",
            "7f79f53c6a024e5ca0980af3b76444b4",
            "af99549bc5844c89aae3b7130f5b67d2",
            "ad8c62b4f37545048573db92d26c349a",
            "451b1bb9ef194b82ada7b83b81b70903",
            "56de0b78bbc64ee984757b641d7650e1",
            "37a5f7c575b44d87a516669d11b06a34",
            "8db6784fd3c446659fd7b8c0e16b57c3",
            "697f6a367e2c42f0a5a6a079f21917dc",
            "a560d6156ed946149426b4e9a62adafc",
            "5df64322742d4a09bcae99f4bd5f9bf1",
            "9e9b4880d9e44d59b80d22c7051b7ec0",
            "ab30001f484d41c2ac3f862b47b1e654",
            "0efdcc5a111d49b8bc17646cb49be643",
            "90c43553fab541d988cf17e67f2a9636"
          ]
        },
        "outputId": "65fb2a85-1c31-47eb-e30c-48a4fe3798b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/61.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "63f757a14885421b876bd99214c5636b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/263k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "34a261aba31948b2a48ecd52dd16ea33"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/467 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f5ced24fd40845a997ddd80d83cac05b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/452M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "451b1bb9ef194b82ada7b83b81b70903"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of ElectraForMaskedLM were not initialized from the model checkpoint at monologg/koelectra-base-v3-discriminator and are newly initialized: ['generator_lm_head.bias', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias', 'generator_predictions.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def restore_original_text(original_text, decoded_text):\n",
        "\n",
        "    restored_text = \"\"\n",
        "    decoded_idx = 0  # 해독된 텍스트에서 현재 참조 중인 문자 위치\n",
        "\n",
        "    # 한글, 영어, 숫자, 공백, 문장부호만 허용하는 정규식\n",
        "    valid_char_pattern = re.compile(r'[가-힣a-zA-Z0-9(),.!?\\'\\\"\\[\\]\\{\\}:]')\n",
        "\n",
        "\n",
        "    for char in original_text:\n",
        "        if valid_char_pattern.match(char):\n",
        "            # 유효한 문자일 경우, 해독된 문자로 대체\n",
        "            if decoded_idx < len(decoded_text):\n",
        "                restored_text += decoded_text[decoded_idx]\n",
        "                decoded_idx += 1\n",
        "            else:\n",
        "                # 만약 해독된 텍스트가 끝났다면 원문 문자 그대로 추가\n",
        "                restored_text += char\n",
        "        else:\n",
        "            # 특수문자 및 불완전한 한글은 원문 그대로 유지\n",
        "            restored_text += char\n",
        "\n",
        "    return restored_text\n",
        "\n",
        "def clean_text(text):\n",
        "    # 1. 한국어(가-힣), 영어(a-zA-Z), 숫자(0-9), 공백(\\s) 외 특수문자 제거\n",
        "    text = re.sub(r'[^가-힣a-zA-Z0-9\\s(),.!?\\'\\\"\\[\\]\\{\\}:]', '', text)\n",
        "\n",
        "    # 2. ㅋㅋ, ㅜㅜ, ㅠㅠ, ㅎㅎ 등과 같은 불완전한 한글 제거\n",
        "    text = re.sub(r'[ㄱ-ㅎㅏ-ㅣ]', '', text)\n",
        "\n",
        "    return text\n",
        "\n",
        "def clean_blank(text):\n",
        "    text = text.strip()  # 좌우 공백 제거\n",
        "    text = re.sub(r'\\s+', ' ', text)  # 연속된 공백을 하나로 변환\n",
        "    return text"
      ],
      "metadata": {
        "id": "SBw_jOVW4esB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Dataloader"
      ],
      "metadata": {
        "id": "8fQWAyyY4qsI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import csv\n",
        "import json\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# 데이터셋 클래스 정의\n",
        "class ObfuscatedDataset(Dataset):\n",
        "    def __init__(self, data_path, tokenizer, max_length=512):\n",
        "        with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            self.data = json.load(f)\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length  # 최대 길이 지정\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.data[idx]\n",
        "        input_tokens = self.tokenizer.tokenize(item[\"chunked_input\"])\n",
        "        target_tokens = self.tokenizer.tokenize(item[\"chunked_output\"])\n",
        "\n",
        "        # 토큰을 ID로 변환\n",
        "        input_ids = self.tokenizer.convert_tokens_to_ids(input_tokens)\n",
        "        target_ids = self.tokenizer.convert_tokens_to_ids(target_tokens)\n",
        "\n",
        "        # **고정된 max_length로 패딩**\n",
        "        input_ids = input_ids[:self.max_length]\n",
        "        target_ids = target_ids[:self.max_length]\n",
        "\n",
        "        input_ids += [0] * (self.max_length - len(input_ids))  # 패딩 추가\n",
        "        target_ids += [0] * (self.max_length - len(target_ids))\n",
        "\n",
        "        # **어텐션 마스크 생성 (패딩된 부분: 0, 나머지: 1)**\n",
        "        attention_mask = [1 if token != 0 else 0 for token in target_ids]\n",
        "\n",
        "        return torch.tensor(input_ids, dtype=torch.long), torch.tensor(target_ids, dtype=torch.long), torch.tensor(attention_mask, dtype=torch.long)\n",
        "\n",
        "# 데이터셋 로드\n",
        "train_dataset = ObfuscatedDataset(path+\"/TRAIN_dataset.json\", custom_tokenizer, max_length=512)\n",
        "\n",
        "# DataLoader 설정\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n"
      ],
      "metadata": {
        "id": "MEUBI7sW4qJC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- loss & Optimizer"
      ],
      "metadata": {
        "id": "C_rjVLuk49KZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "num_epochs = 20\n",
        "total_steps = num_epochs * len(train_dataloader)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.01)\n",
        "\n",
        "warmup_steps = int(0.1 * total_steps)\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps, num_training_steps=total_steps)\n",
        "\n",
        "loss_curve = np.zeros((1,num_epochs))"
      ],
      "metadata": {
        "id": "XRqXy31e4-9x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "2ce69dd4e51f4f7e86238a762c4c3584",
            "5a72a362d2834032b10af6a78cf70a43",
            "be2c9b8406924a8d9f97d7d1a9d0f968",
            "c430f4a321894252aa4bf804ba31ac07",
            "72ce7d698c064dccb2f84cfe3ebb65ef",
            "f957132881624743a91ad2a3d7fd0daf",
            "e1fd59858d394f0988a71589f2d6fb45",
            "22753606fe2b4b379ed0511bd8a1046d",
            "1f4a5412f6fc463cb321b5f851fe8589",
            "afb12427fd9a493c950df6dce6436e28",
            "8ca7096fd22f46bfaf23ea3b36013a44"
          ]
        },
        "outputId": "40a93beb-a4d1-4a7d-83e3-8f666adb7f4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/452M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2ce69dd4e51f4f7e86238a762c4c3584"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Training"
      ],
      "metadata": {
        "id": "ISu_doI45A_-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "def set_seed(seed: int = 42):\n",
        "    random.seed(seed)  # Python의 random 모듈 시드 고정\n",
        "    np.random.seed(seed)  # NumPy 시드 고정\n",
        "    torch.manual_seed(seed)  # PyTorch의 시드 고정\n",
        "    torch.cuda.manual_seed(seed)  # CUDA 시드 고정 (GPU 사용 시)\n",
        "    torch.cuda.manual_seed_all(seed)  # 다중 GPU 환경 시드 고정\n",
        "    torch.backends.cudnn.deterministic = True  # CUDNN 연산을 결정적으로 설정\n",
        "    torch.backends.cudnn.benchmark = False  # 연산 최적화 비활성화 (재현성 보장)\n",
        "\n",
        "set_seed(42)  # 원하는 시드 값 설정"
      ],
      "metadata": {
        "id": "OBE8sZYd5CB9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "\n",
        "    model.train()\n",
        "    total_train_loss = 0\n",
        "    save_path = path+f\"/full_electra_epc{epoch+1}.pth\"\n",
        "\n",
        "    for batch_idx, (input_ids, target_ids, attention_mask) in enumerate(train_dataloader):\n",
        "        input_ids, target_ids, attention_mask = (\n",
        "            input_ids.to(device),\n",
        "            target_ids.to(device),\n",
        "            attention_mask.to(device),\n",
        "        )\n",
        "\n",
        "        outputs = model(input_ids, attention_mask=attention_mask).logits\n",
        "        loss = criterion(outputs.view(-1, outputs.size(-1)), target_ids.view(-1))\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # 100 배치마다 진행 상황 출력\n",
        "        if (batch_idx + 1) % 100 == 0:\n",
        "            avg_loss = total_train_loss / (batch_idx + 1)\n",
        "            print(f\"[Train] Epoch [{epoch+1}/{num_epochs}], Batch [{batch_idx+1}/{len(train_dataloader)}], Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
        "    loss_curve[0,epoch] = avg_train_loss\n",
        "    print(f\"[Train] Epoch {epoch+1}/{num_epochs}, Average Loss: {avg_train_loss:.4f}\")\n",
        "\n",
        "    if epoch >= 5:\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'scheduler_state_dict': scheduler.state_dict()\n",
        "        }, save_path)\n",
        "        print(f\"Model Saved. (epoch: {epoch+1})\")\n",
        "\n"
      ],
      "metadata": {
        "id": "pU45JGiz5KYb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "collapsed": true,
        "outputId": "319a389e-521b-40f0-8758-8b68465a69ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train] Epoch [1/20], Batch [100/4323], Loss: 11.1148\n",
            "[Train] Epoch [1/20], Batch [200/4323], Loss: 9.8087\n",
            "[Train] Epoch [1/20], Batch [300/4323], Loss: 8.7725\n",
            "[Train] Epoch [1/20], Batch [400/4323], Loss: 8.0156\n",
            "[Train] Epoch [1/20], Batch [500/4323], Loss: 7.3788\n",
            "[Train] Epoch [1/20], Batch [600/4323], Loss: 6.8105\n",
            "[Train] Epoch [1/20], Batch [700/4323], Loss: 6.2997\n",
            "[Train] Epoch [1/20], Batch [800/4323], Loss: 5.8322\n",
            "[Train] Epoch [1/20], Batch [900/4323], Loss: 5.3998\n",
            "[Train] Epoch [1/20], Batch [1000/4323], Loss: 5.0003\n",
            "[Train] Epoch [1/20], Batch [1100/4323], Loss: 4.6361\n",
            "[Train] Epoch [1/20], Batch [1200/4323], Loss: 4.3093\n",
            "[Train] Epoch [1/20], Batch [1300/4323], Loss: 4.0195\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-078fa5675a92>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mtotal_train_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# 100 배치마다 진행 상황 출력\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(loss_curve[0][1:], label='train')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lPvMp9sm5Lud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2차 해독"
      ],
      "metadata": {
        "id": "wcop_qZH5QA0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv(path+\"/TRAIN_dec1.csv\")\n",
        "test = pd.read_csv(path+\"/TEST_dec1.csv\")\n",
        "train_chunked = pd.read_csv(path+\"/TRAIN_dec1_chunked.csv\")\n",
        "test_chunked = pd.read_csv(path+\"/TEST_dec1_chunked.csv\")"
      ],
      "metadata": {
        "id": "nhTpFl9v5Ril"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import ElectraForMaskedLM\n",
        "from tqdm import tqdm\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = ElectraForMaskedLM.from_pretrained(\"monologg/koelectra-base-v3-discriminator\")\n",
        "checkpoint = torch.load(path+\"/full_electra_epc20.pth\", map_location=device)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "def denoise_text(input_text, tokenizer, max_length=512):\n",
        "\n",
        "    input_tokens = tokenizer.tokenize(input_text)\n",
        "    input_ids = tokenizer.convert_tokens_to_ids(input_tokens)\n",
        "\n",
        "    input_ids = input_ids[:max_length]\n",
        "    attention_mask = [1] * len(input_ids)\n",
        "    input_ids += [0] * (max_length - len(input_ids))  # 패딩\n",
        "    attention_mask += [0] * (max_length - len(attention_mask))\n",
        "\n",
        "    input_ids_tensor = torch.tensor([input_ids], dtype=torch.long).to(device)\n",
        "    attention_mask_tensor = torch.tensor([attention_mask], dtype=torch.long).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids_tensor, attention_mask=attention_mask_tensor).logits\n",
        "        predicted_ids = torch.argmax(outputs, dim=-1)[0].cpu().tolist()\n",
        "\n",
        "    final_ids = [\n",
        "        pred if a == 0 else (pred if pred != 0 else 59)\n",
        "        for orig, pred, a in zip(input_ids, predicted_ids, attention_mask)\n",
        "    ]\n",
        "\n",
        "    predicted_tokens = tokenizer.convert_ids_to_tokens(final_ids)\n",
        "    restored_text = \"\".join(predicted_tokens).replace(\"▁\", \" \")\n",
        "\n",
        "    return restored_text\n",
        "\n",
        "def check_double_blanks(text):\n",
        "    return bool(re.search(r' {2,}', text))\n",
        "\n",
        "def check_repeated_last_char(text):\n",
        "    return bool(re.search(r'([가-힣])\\1+$', text))\n",
        "\n",
        "\n",
        "def remove_trailing_unks(text):\n",
        "\n",
        "    cleaned_text = re.sub(r'(<unk>\\s*)+$', '', text)\n",
        "    return cleaned_text\n",
        "\n",
        "def post_processing(data, data_chunked, result, test_flg = True):\n",
        "  temp = data.copy()\n",
        "  temp_chunked = data_chunked.copy()\n",
        "\n",
        "  for i in range(len(result)):\n",
        "    result[i] = remove_trailing_unks(result[i])\n",
        "\n",
        "  temp_chunked['input_DEC2'] = result\n",
        "  data_recovered = temp_chunked.groupby(\"index\").agg(list).reset_index(drop=True)\n",
        "  if test_flg:\n",
        "    data_recovered.columns = ['input_DEC1','input_DEC2']\n",
        "    data_recovered['input_DEC2'] = data_recovered['input_DEC2'].apply(lambda x: ' '.join(x))\n",
        "  else:\n",
        "    data_recovered.columns = ['input_DEC1','output','input_DEC2']\n",
        "    data_recovered['input_DEC2'] = data_recovered['input_DEC2'].apply(lambda x: ' '.join(x))\n",
        "\n",
        "  temp['input_DEC1'] = temp.apply(lambda x: clean_blank(x['input_DEC1']), axis = 1)\n",
        "\n",
        "  temp['input_DEC2'] = data_recovered['input_DEC2']\n",
        "  temp['input_DEC2'] = temp.apply(lambda x: clean_blank(x['input_DEC2']), axis = 1)\n",
        "  temp['input_DEC2'] = temp.apply(lambda x: x['input_DEC2'].replace(\" \",\"\"), axis= 1)\n",
        "\n",
        "  temp['input_DEC2'] = temp.apply(lambda x: restore_original_text(x['input_DEC1'],x['input_DEC2']), axis = 1)\n",
        "\n",
        "  return temp"
      ],
      "metadata": {
        "id": "ipjU79EX5S9r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "188a9538-8f64-49b3-bcf6-5a45e69eed81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of ElectraForMaskedLM were not initialized from the model checkpoint at monologg/koelectra-base-v3-discriminator and are newly initialized: ['generator_lm_head.bias', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias', 'generator_predictions.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "test_sentences = test_chunked['chunked_input']\n",
        "\n",
        "decoded = []\n",
        "for sentence in tqdm(test_sentences):\n",
        "    restored = denoise_text(sentence, custom_tokenizer)\n",
        "    decoded.append(restored)\n",
        "\n",
        "test_result = post_processing(test, test_chunked, decoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fR4NF06wufDH",
        "outputId": "214fd5bc-92d7-4120-8d4e-f0384d382d26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7781/7781 [05:32<00:00, 23.41it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_result.to_csv(path+\"/TEST_dec2.csv\", index=False)"
      ],
      "metadata": {
        "id": "X19TzSKH766w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission = pd.read_csv(path+\"/sample_submission.csv\")\n",
        "submission['output'] = test_result['input_DEC2']\n",
        "submission.to_csv(path+\"/submission_electra.csv\", index=False)"
      ],
      "metadata": {
        "id": "fNaiNd92NG0j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2차 해독_후처리"
      ],
      "metadata": {
        "id": "e1lbWz1r8WDh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "# 잘 학습된 ELECTRA로 추론된 test dec2 셋\n",
        "test = pd.read_csv(path+\"/TEST_dec2.csv\")"
      ],
      "metadata": {
        "id": "80ty7gW38XLQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    # 1. 한국어(가-힣), 영어(a-zA-Z), 숫자(0-9), 공백(\\s) 외 특수문자 제거\n",
        "    text = re.sub(r'[^가-힣a-zA-Z0-9\\s(),.!?\\'\\\"\\[\\]\\{\\}:]', '', text)\n",
        "\n",
        "    # 2. ㅋㅋ, ㅜㅜ, ㅠㅠ, ㅎㅎ 등과 같은 불완전한 한글 제거\n",
        "    text = re.sub(r'[ㄱ-ㅎㅏ-ㅣ]', '', text)\n",
        "\n",
        "    return text\n",
        "\n",
        "def split_sentences(text):\n",
        "    # 기본적인 문장 분리\n",
        "    sentences = re.split(r'(?<=[.!?])\\s', text)\n",
        "    sentences = [sentence.strip() for sentence in sentences if sentence]  # 공백 제거 및 빈 요소 제거\n",
        "\n",
        "    merged_sentences = []\n",
        "    temp = \"\"\n",
        "    open_bracket_count = 0  # 열린 괄호 개수\n",
        "\n",
        "    for i, sentence in enumerate(sentences):\n",
        "        # 괄호 개수 체크\n",
        "        open_bracket_count += sentence.count(\"(\")\n",
        "        open_bracket_count -= sentence.count(\")\")\n",
        "\n",
        "        # 문장이 20자 이하이거나, 괄호가 닫히지 않았다면 다음 문장과 결합\n",
        "        if (len(sentence) <= 20 and i < len(sentences) - 1) or open_bracket_count > 0:\n",
        "            temp += sentence + \" \"\n",
        "        else:\n",
        "            temp += sentence\n",
        "            merged_sentences.append(temp)\n",
        "            temp = \"\"  # temp 초기화\n",
        "\n",
        "    if temp:  # 마지막 문장이 남아 있다면 추가\n",
        "        merged_sentences.append(temp.strip())\n",
        "\n",
        "    # 마지막 문장은 반드시 마지막에서 두 번째 문장과 결합\n",
        "    if len(merged_sentences) > 1:\n",
        "        merged_sentences[-2] += \" \" + merged_sentences[-1]\n",
        "        merged_sentences.pop()  # 마지막 문장 제거 (이미 합쳐졌으므로)\n",
        "\n",
        "    return merged_sentences\n",
        "\n",
        "def clean_blank(text):\n",
        "    text = text.strip()  # 좌우 공백 제거\n",
        "    text = re.sub(r'\\s+', ' ', text)  # 연속된 공백을 하나로 변환\n",
        "    return text"
      ],
      "metadata": {
        "id": "gFjiRPrO8aFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test['cleaned_input_DEC2'] = test['input_DEC2'].apply(clean_text)\n",
        "train_result['cleaned_input_DEC2'] = train_result['input_DEC2'].apply(clean_text)\n",
        "train_result['cleaned_output'] = train_result['output'].apply(clean_text)\n",
        "\n",
        "test_ = test.copy()\n",
        "test_['chunked_input'] = test['cleaned_input_DEC2'].apply(split_sentences)\n",
        "train_result['chunked_input'] = train_result['cleaned_input_DEC2'].apply(split_sentences)\n",
        "train_result['chunked_output'] = train_result['cleaned_output'].apply(split_sentences)\n",
        "test_chunked = test_.explode('chunked_input')[['chunked_input']].reset_index(drop=False)\n",
        "train_exploded1 = train_result.explode('chunked_input')[['chunked_input']].reset_index(drop=False)\n",
        "train_exploded2 = train_result.explode('chunked_output')[['chunked_output']].reset_index(drop=True)\n",
        "train_chunked = pd.concat([train_exploded1, train_exploded2], axis=1)\n",
        "\n",
        "test_chunked['chunked_input'] = test_chunked['chunked_input'].apply(clean_blank)\n",
        "train_chunked['chunked_input'] = train_chunked['chunked_input'].apply(clean_blank)\n",
        "train_chunked['chunked_output'] = train_chunked['chunked_output'].apply(clean_blank)\n",
        "\n",
        "\n",
        "test_chunked.drop(test_chunked[test_chunked['chunked_input'] == ''].index, inplace=True)\n",
        "test_chunked.reset_index(drop=True, inplace=True)\n",
        "test_chunked['len'] = test_chunked['chunked_input'].apply(lambda x: len(x))\n",
        "train_chunked['len'] = train_chunked['chunked_input'].apply(lambda x: len(x))\n",
        "# 수동으로 쪼개기\n",
        "input1, input2 = train_chunked.iloc[1339][1][:393], train_chunked.iloc[1339][1][394:]\n",
        "output1, output2 = train_chunked.iloc[1339][2][:393], train_chunked.iloc[1339][2][394:]\n",
        "temp = pd.DataFrame({'index':[658,658], 'chunked_input':[input1,input2],\n",
        "                     'chunked_output':[output1,output2]})\n",
        "train_chunked.drop(index=[1339], inplace=True)\n",
        "train_chunked = pd.concat([train_chunked, temp]).reset_index(drop=True)\n",
        "train_chunked['len1'] = train_chunked['chunked_input'].apply(len)\n",
        "train_chunked['len2'] = train_chunked['chunked_output'].apply(len)\n",
        "train_chunked['diff'] = train_chunked['len1'] - train_chunked['len2']\n",
        "train_chunked.at[5412,'chunked_input'] = \"딱 트윈 광안리 오션뷰와 힐링 베기지로 이용한 했음 온천 찜치과 사우나까지, 줄거운 추억이 가득 담았네요.\"\n",
        "train_chunked.at[5413,'chunked_input'] = \"리뷰 평일 좋지 않아 내심 걱정했지만 실제로 와보시면 멋진 오션뷰 그 자체만으로 잊지 못할 여행이 될 거예요! 꼭 한 번 방문해 보세요\""
      ],
      "metadata": {
        "id": "RKrRIzac8fKJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_chunked['len1'] = train_chunked['chunked_input'].apply(len)\n",
        "train_chunked['len2'] = train_chunked['chunked_output'].apply(len)\n",
        "train_chunked['diff'] = train_chunked['len1'] - train_chunked['len2']\n",
        "train_chunked[train_chunked['diff'] != 0]\n",
        "train_chunked.drop(['len','len1','len2','diff'],axis=1, inplace = True)\n",
        "train_chunked.head()"
      ],
      "metadata": {
        "id": "KAexLhXg847a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_chunked.to_csv(path+\"/TRAIN_dec2_chunked.csv\", index=False)"
      ],
      "metadata": {
        "id": "aNRB5o-587aD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_result['cleaned_input_DEC2'] = train_result.apply(lambda x: x['cleaned_input_DEC2'].replace(\" \",\"\"), axis= 1)\n",
        "train_result['restored_input_DEC2'] = train_result.apply(lambda x: restore_original_text(x['input_DEC2'],x['cleaned_input_DEC2']), axis = 1)\n",
        "result_train = train.apply(lambda x: restore_original_text(x['input_DEC1'],x['recovered_input']), axis = 1)\n",
        "result_train_ = train.apply(lambda x: restore_original_text(x['output'],x['recovered_output']), axis = 1)\n",
        "train_result.drop(train_result.columns[4:],axis=1)\n",
        "test['cleaned_input_DEC2'] = test.apply(lambda x: x['cleaned_input_DEC2'].replace(\" \",\"\"), axis= 1)\n",
        "test['restored_input_DEC2'] = test.apply(lambda x: restore_original_text(x['input_DEC2'],x['cleaned_input_DEC2']), axis = 1)\n",
        "test.drop(test.columns[3:],axis=1)\n",
        "test_chunked.drop(['len'],axis = 1, inplace=True)"
      ],
      "metadata": {
        "id": "0VCHL2aE9CBo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_chunked.to_csv(path+\"/TEST_dec2_chunked.csv\", index=False)"
      ],
      "metadata": {
        "id": "_snbXyMX9Lfd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# koGemma-7b finetuning을 위한 전처리"
      ],
      "metadata": {
        "id": "qKgLWMvaXLax"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "def clean_text(text):\n",
        "    text = str(text)\n",
        "    text = re.sub(r'[^가-힣a-zA-Z0-9\\s(),.!?\\'\\\"\\[\\]\\{\\}:]', '', text)\n",
        "    text = re.sub(r'[ㄱ-ㅎㅏ-ㅣ]', '', text)\n",
        "    return text\n",
        "\n",
        "def split_sentences(text):\n",
        "    text = str(text)\n",
        "    sentences = re.split(r'(?<=[.!?])\\s', text)\n",
        "    sentences = [s.strip() for s in sentences if s]\n",
        "\n",
        "    merged = []\n",
        "    temp = \"\"\n",
        "    open_bracket_count = 0\n",
        "    for i, sentence in enumerate(sentences):\n",
        "        open_bracket_count += sentence.count(\"(\")\n",
        "        open_bracket_count -= sentence.count(\")\")\n",
        "        if (len(sentence) <= 20 and i < len(sentences) - 1) or open_bracket_count > 0:\n",
        "            temp += sentence + \" \"\n",
        "        else:\n",
        "            temp += sentence\n",
        "            merged.append(temp.strip())\n",
        "            temp = \"\"\n",
        "    if temp:\n",
        "        merged.append(temp.strip())\n",
        "    if len(merged) > 1:\n",
        "        merged[-2] = merged[-2] + \" \" + merged[-1]\n",
        "        merged.pop()\n",
        "    return merged\n",
        "\n",
        "def clean_blank(text):\n",
        "    return re.sub(r'\\s+', ' ', str(text).strip())\n",
        "\n",
        "def get_char_type(char):\n",
        "    if char.isspace():\n",
        "        return \"space\"\n",
        "    elif '가' <= char <= '힣':\n",
        "        return \"hangul\"\n",
        "    elif char.isdigit():\n",
        "        return \"num\"\n",
        "    elif ('A' <= char <= 'Z') or ('a' <= char <= 'z'):\n",
        "        return \"eng\"\n",
        "    else:\n",
        "        return \"symbol\"\n",
        "\n",
        "def chunk_dataframe(df, input_cleaned_col, output_cleaned_col=None):\n",
        "    df = df.copy()\n",
        "    df['chunked_input'] = df[input_cleaned_col].apply(split_sentences)\n",
        "    if output_cleaned_col:\n",
        "        df['chunked_output'] = df[output_cleaned_col].apply(split_sentences)\n",
        "\n",
        "    df_input = df.explode('chunked_input').reset_index(drop=False)\n",
        "    df_input['chunked_input'] = df_input['chunked_input'].apply(clean_blank)\n",
        "\n",
        "    if output_cleaned_col:\n",
        "        df_output = df.explode('chunked_output').reset_index(drop=False)\n",
        "        df_output['chunked_output'] = df_output['chunked_output'].apply(clean_blank)\n",
        "        if not df_input['index'].equals(df_output['index']):\n",
        "            raise ValueError(\"입력과 출력의 explode 결과 인덱스가 일치하지 않습니다.\")\n",
        "        df_input['chunked_output'] = df_output['chunked_output']\n",
        "\n",
        "    df_input = df_input[df_input['chunked_input'] != ''].reset_index(drop=True)\n",
        "    df_input['len'] = df_input['chunked_input'].apply(len)\n",
        "    return df_input\n",
        "\n",
        "def process_files(train_file, test_file, input_col, output_col=None,\n",
        "                  valid_file=None,\n",
        "                  cleaned_input_col=\"cleaned_input\", cleaned_output_col=\"cleaned_output\",\n",
        "                  train_out_csv=\"data/train_chunked.csv\", test_out_csv=\"data/test_chunked.csv\"):\n",
        "\n",
        "    train_df = pd.read_csv(train_file)\n",
        "    if valid_file:\n",
        "        valid_df = pd.read_csv(valid_file)\n",
        "        train_df = pd.concat([train_df, valid_df]).reset_index(drop=True)\n",
        "    test_df = pd.read_csv(test_file)\n",
        "\n",
        "    train_df[cleaned_input_col] = train_df[input_col].apply(clean_text)\n",
        "    test_df[cleaned_input_col] = test_df[input_col].apply(clean_text)\n",
        "    if output_col:\n",
        "        train_df[cleaned_output_col] = train_df[output_col].apply(clean_text)\n",
        "\n",
        "    train_chunked = chunk_dataframe(train_df, cleaned_input_col, cleaned_output_col if output_col else None)\n",
        "    test_chunked = chunk_dataframe(test_df, cleaned_input_col)\n",
        "\n",
        "    train_chunked.to_csv(train_out_csv, index=False)\n",
        "    test_chunked.to_csv(test_out_csv, index=False)\n",
        "\n",
        "def process_standard():\n",
        "    process_files(\n",
        "        train_file=\"train.csv\",\n",
        "        test_file=\"test.csv\",\n",
        "        input_col=\"input\",\n",
        "        output_col=\"output\",\n",
        "        cleaned_input_col=\"cleaned_input\",\n",
        "        cleaned_output_col=\"cleaned_output\",\n",
        "        train_out_csv=\"data/train_chunked.csv\",\n",
        "        test_out_csv=\"data/test_chunked.csv\"\n",
        "    )\n",
        "\n",
        "def process_dec1():\n",
        "    process_files(\n",
        "        train_file=\"train_dec1.csv\",\n",
        "        test_file=\"test_dec1.csv\",\n",
        "        input_col=\"input_DEC1\",\n",
        "        output_col=\"output\",\n",
        "        valid_file=\"valid_dec1.csv\",\n",
        "        cleaned_input_col=\"cleaned_input_DEC1\",\n",
        "        cleaned_output_col=\"cleaned_output\",\n",
        "        train_out_csv=\"data/train_chunked_dec1.csv\",\n",
        "        test_out_csv=\"data/test_chunked_dec1.csv\"\n",
        "    )\n",
        "\n",
        "def filter_sentence(sentence, allowed_labels={\"hangul\", \"eng\", \"space\", \"num\"}):\n",
        "    sentence = str(sentence)\n",
        "    return \"\".join(char for char in sentence if get_char_type(char) in allowed_labels)\n",
        "\n",
        "def filter_df(df, input_col, output_col=None, new_input_col=\"input\", new_output_col=\"output\"):\n",
        "    df = df.copy()\n",
        "    df[new_input_col] = df[input_col].apply(filter_sentence)\n",
        "    if output_col:\n",
        "        df[new_output_col] = df[output_col].apply(filter_sentence)\n",
        "        return df[[new_input_col, new_output_col]]\n",
        "    return df[[new_input_col]]\n",
        "\n",
        "def process_finetuning(in_train_csv, in_test_csv, out_train_csv, out_test_csv):\n",
        "    train = pd.read_csv(in_train_csv).drop(columns=\"index\", errors='ignore')\n",
        "    test = pd.read_csv(in_test_csv).drop(columns=\"index\", errors='ignore')\n",
        "\n",
        "    train_filtered = filter_df(train, \"chunked_input\", \"chunked_output\", new_input_col=\"input\", new_output_col=\"output\")\n",
        "    test_filtered = filter_df(test, \"chunked_input\", output_col=None, new_input_col=\"input\")\n",
        "\n",
        "    train_filtered.to_csv(out_train_csv, index=False)\n",
        "    test_filtered.to_csv(out_test_csv, index=False)\n",
        "\n",
        "def process_finetuning_original():\n",
        "    process_finetuning(\"data/train_chunked.csv\", \"data/test_chunked.csv\",\n",
        "                         \"data/finetuning_train_orginal.csv\", \"data/finetuning_test_original.csv\")\n",
        "\n",
        "def process_finetuning_mlp():\n",
        "    process_finetuning(\"data/train_chunked_dec1.csv\", \"data/test_chunked_dec1.csv\",\n",
        "                         \"data/finetuning_train_mlp.csv\", \"data/finetuning_test_mlp.csv\")\n",
        "\n",
        "def finetuning_dataset_maker():\n",
        "    process_standard()\n",
        "    process_dec1()\n",
        "    process_finetuning_original()\n",
        "    process_finetuning_mlp()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    finetuning_dataset_maker()"
      ],
      "metadata": {
        "id": "2QbqBs-GVFwC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqAB7Y3cfkk5"
      },
      "source": [
        "# Seqmatcher에서 사용할 데이터 전처리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVQmk5YAfklA"
      },
      "source": [
        "- electra 결과 문장부호 제거"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MqEAF3qDfklN"
      },
      "outputs": [],
      "source": [
        "dec2 = pd.read_csv(path+\"/TEST_dec2_chunked.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zYTW5-SYfklN"
      },
      "outputs": [],
      "source": [
        "dec2_dict = {}\n",
        "\n",
        "for idx, text in dec2[\"chunked_input\"].items():\n",
        "    char_list = [(char, get_char_type(char)) for char in text]\n",
        "    dec2_dict[idx] = pd.DataFrame(char_list, columns=[\"Character\", \"Label\"])\n",
        "\n",
        "# 허용할 라벨 리스트\n",
        "allowed_labels = {\"hangul\", \"eng\", \"space\", \"num\"}\n",
        "\n",
        "# 각 row별로 문자 필터링 후 합친 문장을 저장\n",
        "\n",
        "cleaned_dec2 = pd.DataFrame({\n",
        "    \"chunked_input\": [\n",
        "        \"\".join(dec2_dict[idx].loc[dec2_dict[idx][\"Label\"].isin(allowed_labels), \"Character\"])\n",
        "        for idx in dec2_dict\n",
        "    ]\n",
        "})\n",
        "\n",
        "# cc: chunked & cleaned\n",
        "# index는 지움\n",
        "dec2_cc = cleaned_dec2.rename(columns={\"chunked_input\": \"input\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FP19E9PXfklO"
      },
      "outputs": [],
      "source": [
        "# chunking시 선공백처리, 후공백처리 (clean_blank)에 따라 문장 분리가 안일어나는 문장 하나가 있음...\n",
        "# 장점 접근성이 나쁘지 않습니다 / 부산역에서 버스 15분 로비가 3층이라 호텔 출입 시 프라이빗 보장이 됩니다\n",
        "# 분리시켜서 최종적으로 4808행을 4809행으로 늘림\n",
        "\n",
        "# 기존 데이터 가져오기\n",
        "data = dec2_cc.copy()\n",
        "\n",
        "# 104번째 행의 값 가져오기\n",
        "original_text = data.iloc[104, 0]\n",
        "\n",
        "# \"장점 접근성이 나쁘지 않습니다\"를 기준으로 분리\n",
        "split_point = \"장점 접근성이 나쁘지 않습니다\"\n",
        "if split_point in original_text:\n",
        "    first_part = split_point\n",
        "    second_part = original_text.replace(split_point, \"\").strip()  # 나머지 부분 가져오기\n",
        "\n",
        "    # 104번째 행 업데이트\n",
        "    data.iloc[104, 0] = first_part\n",
        "\n",
        "    # 이후 행들을 한 칸씩 밀기\n",
        "    new_rows = pd.DataFrame({0: [second_part]})  # 새로운 행 생성\n",
        "    data = pd.concat([data.iloc[:105], new_rows, data.iloc[105:]]).reset_index(drop=True)\n",
        "\n",
        "data.iloc[105, 0] = data.iloc[105, 1]\n",
        "dec2_cc = data.drop(columns=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lkomB3vtfklO"
      },
      "outputs": [],
      "source": [
        "dec2_cc.to_csv(path+\"/seqmatcher_ELECTRA.csv\", index=False) # seqmatcher에서 사용할 dec2 청크 문장부호 제거입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrqLFXoifklO"
      },
      "source": [
        "- 원본 데이터 청크와 문장부호 제거"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Mj1V9i5fklP"
      },
      "outputs": [],
      "source": [
        "original = pd.read_csv(path+\"/test.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sh_XPkpdfklQ"
      },
      "outputs": [],
      "source": [
        "original[\"cleaned_input\"] = original[\"input\"].apply(clean_text)\n",
        "original_ = original.copy()\n",
        "original_['chunked_input'] = original['cleaned_input'].apply(split_sentences)\n",
        "original_chunked_ = original_.explode('chunked_input')[['chunked_input']].reset_index(drop=False)\n",
        "original_chunked_['chunked_input'] = original_chunked_['chunked_input'].apply(clean_blank)\n",
        "\n",
        "original_chunked_.drop(original_chunked_[original_chunked_['chunked_input'] == ''].index, inplace=True)\n",
        "original_chunked_.reset_index(drop=True, inplace=True)\n",
        "original_chunked_['len'] = original_chunked_['chunked_input'].apply(lambda x: len(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dTHW9-_sfklS"
      },
      "outputs": [],
      "source": [
        "original_dict = {}\n",
        "\n",
        "for idx, text in original_chunked_[\"chunked_input\"].items():\n",
        "    char_list = [(char, get_char_type(char)) for char in text]\n",
        "    original_dict[idx] = pd.DataFrame(char_list, columns=[\"Character\", \"Label\"])\n",
        "\n",
        "allowed_labels = {\"hangul\", \"eng\", \"space\", \"num\"}\n",
        "\n",
        "# 각 row별로 문자 필터링 후 합친 문장을 저장\n",
        "\n",
        "cleaned_original = pd.DataFrame({\n",
        "    \"chunked_input\": [\n",
        "        \"\".join(original_dict[idx].loc[original_dict[idx][\"Label\"].isin(allowed_labels), \"Character\"])\n",
        "        for idx in original_dict\n",
        "    ]\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aN1-A91afklT"
      },
      "outputs": [],
      "source": [
        "original_cc = cleaned_original.rename(columns={\"chunked_input\": \"input\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jW1jro16fklU"
      },
      "outputs": [],
      "source": [
        "original_cc.to_csv(path+\"/seqmatcher_ORIGINAL.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2차 해독_finetuning"
      ],
      "metadata": {
        "id": "8ocJIQcGr1WL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "import torch\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    BitsAndBytesConfig,\n",
        "    pipeline,\n",
        "    TrainingArguments\n",
        ")\n",
        "\n",
        "from datasets import Dataset\n",
        "from peft import LoraConfig, get_peft_model, PeftModel\n",
        "from trl import SFTTrainer"
      ],
      "metadata": {
        "id": "p1URYPqJr17y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "67ed5ca1-d8d8-4355-9340-e7ef46275376"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'datasets'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-bdc168fe48fd>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpeft\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLoraConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_peft_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPeftModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtrl\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSFTTrainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'datasets'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 42\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "# cuDNN 관련 설정\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "os.environ['CUBLAS_WORKSPACE_CONFIG'] = \":4096:8\"  # (PyTorch 1.8 이상에서 추천)\n",
        "torch.use_deterministic_algorithms(True)\n",
        "\n",
        "os.environ[\"HF_HOME\"] = path+\"/workspace/huggingface\"\n",
        "os.environ[\"TRANSFORMERS_CACHE\"] = path+\"/workspace/huggingface\""
      ],
      "metadata": {
        "id": "gDWpNXB0xCpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 통합 파이프라인 함수\n",
        "def full_training_pipeline(train_df, test_df, output_dir, base_model_path, adapter_model_path, epoch):\n",
        "    # 8-bit BitsAndBytes config (8-bit uses bfloat16)\n",
        "    bnb_config = BitsAndBytesConfig(\n",
        "        load_in_8bit=True\n",
        "    )\n",
        "\n",
        "    model_id = 'beomi/gemma-ko-7b'\n",
        "\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_id,\n",
        "        quantization_config=bnb_config,\n",
        "        device_map={\"\": 0},\n",
        "        cache_dir=path+\"/workspace/huggingface\"    # <--- volume 지정\n",
        "    )\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\n",
        "        model_id,\n",
        "        cache_dir=path+\"/workspace/huggingface\"    # <--- volume 지정\n",
        "    )\n",
        "\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "    tokenizer.padding_side = 'right'\n",
        "\n",
        "    train = Dataset.from_pandas(train_df)\n",
        "    test = Dataset.from_pandas(test_df)\n",
        "\n",
        "    def prompting(input, output):\n",
        "        prompt = (\n",
        "            \"<start_of_turn> Your task is to transform the given obfuscated Korean review into a clear, correct, and natural-sounding Korean review that reflects its original meaning. The number of words and letters per word must be observed.\\n\"\n",
        "            f\"Input: {input}\\n\"\n",
        "            \"<end_of_turn>\\n\"\n",
        "            \"<start_of_turn>Assistant:\\n\"\n",
        "            f\"Output: {output}\"\n",
        "        )\n",
        "        return prompt\n",
        "\n",
        "    def chat_format(row):\n",
        "        prompt = prompting(row[\"input\"], row[\"output\"])\n",
        "        tokens = tokenizer.encode(prompt, truncation=True, max_length=512)\n",
        "        row[\"input_ids\"] = tokens\n",
        "        return row\n",
        "\n",
        "    train = train.map(chat_format, batched=False, num_proc=4)\n",
        "\n",
        "    # LoRA 설정\n",
        "    lora_config = LoraConfig(\n",
        "        r=8,\n",
        "        lora_alpha=32,\n",
        "        target_modules=[\n",
        "            \"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\",\n",
        "            \"gate_proj\", \"down_proj\", \"up_proj\"\n",
        "        ],\n",
        "        lora_dropout=0.1,\n",
        "        bias='none',\n",
        "        task_type='CAUSAL_LM'\n",
        "    )\n",
        "\n",
        "    model = get_peft_model(model, lora_config)\n",
        "    model.train()\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    training_args = TrainingArguments(\n",
        "        seed=42,\n",
        "        output_dir=output_dir,\n",
        "        num_train_epochs=epoch,\n",
        "        per_device_train_batch_size=4,\n",
        "        per_device_eval_batch_size=4,\n",
        "        gradient_accumulation_steps=8,\n",
        "        optim=\"paged_adamw_32bit\",\n",
        "        eval_strategy=\"no\",\n",
        "        logging_dir=\"./logs\",\n",
        "        logging_steps=50,\n",
        "        warmup_steps=20,\n",
        "        logging_strategy=\"steps\",\n",
        "        learning_rate=2e-4,\n",
        "        group_by_length=True,\n",
        "        save_strategy=\"epoch\",\n",
        "        fp16=True\n",
        "    )\n",
        "\n",
        "    trainer = SFTTrainer(\n",
        "        model=model,\n",
        "        train_dataset=train,\n",
        "        args=training_args,\n",
        "        peft_config=lora_config,\n",
        "        formatting_func=lambda x: x['input_ids']\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "\n",
        "    # 모델 저장 및 로드\n",
        "    trainer.model.save_pretrained(adapter_model_path)\n",
        "\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "    base_model,\n",
        "    device_map='auto',\n",
        "    torch_dtype=torch.float16,\n",
        "    cache_dir=path+\"/workspace/huggingface\")\n",
        "\n",
        "    model = PeftModel.from_pretrained(\n",
        "        model,\n",
        "        adapter_model_path,\n",
        "        device_map='auto',\n",
        "        torch_dtype=torch.float16\n",
        "    )\n",
        "    return model\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    #2차 해독_finetuning_ver1(input:MLP)\n",
        "    train0 = pd.read_csv(path+'/finetuning_train_mlp.csv')\n",
        "    test0 = pd.read_csv(path+'/finetuning_test_mlp.csv')\n",
        "    output_dir0=path+\"/results0221\"\n",
        "    base_model_path0 = \"beomi/gemma-ko-7b\"\n",
        "    adapter_model_path0 = path+\"/workspace/results0221/lora-adapter-epoch3\"\n",
        "\n",
        "    model0 = full_training_pipeline(train0, test0, base_model_path0, adapter_model_path0, 3)\n",
        "    model0.save_pretrained(\"/workspace/results0221/gemma-finetuning-epoch3\")\n",
        "    print(\"2차 해독_finetuning_ver1(input:MLP) 완료\")\n",
        "\n",
        "    #2차 해독_finetuning_ver1(input:원본)\n",
        "    train1 = pd.read_csv(path+'/finetuning_train_originalcsv')\n",
        "    test1 = pd.read_csv(path+'/finetuning_test_original.csv')\n",
        "    output_dir1=path+\"/results0225\"\n",
        "    base_model_path1 = \"beomi/gemma-ko-7b\"\n",
        "    adapter_model_path1 = \"/workspace/results0225/lora-adapter-epoch5\"\n",
        "\n",
        "    model1 = full_training_pipeline(train0, test0, base_model_path0, adapter_model_path0, 5)\n",
        "    model1.save_pretrained(\"/workspace/results0225/gemma-finetuning-epoch5\")\n",
        "    print(\"2차 해독_finetuning_ver1(input:원본) 완료\")\n"
      ],
      "metadata": {
        "id": "jo584jBXvWvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def restore_reviews(FINETUNE_MODEL, BASE_MODEL, test):\n",
        "    # 모델과 토크나이저 로드\n",
        "    finetune_model = AutoModelForCausalLM.from_pretrained(\n",
        "        FINETUNE_MODEL, cache_dir=path+\"/workspace/huggingface\", device_map={\"\": 0}\n",
        "    )\n",
        "    tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL, cache_dir=path+\"/workspace/huggingface\")\n",
        "\n",
        "    # 텍스트 생성 파이프라인 초기화\n",
        "    text_gen_pipeline = pipeline(\n",
        "        \"text-generation\",\n",
        "        model=finetune_model,\n",
        "        tokenizer=tokenizer,\n",
        "    )\n",
        "\n",
        "    restored_reviews = []\n",
        "    total_reviews = len(test)\n",
        "\n",
        "    for index, row in test.iterrows():\n",
        "        query = row['input']\n",
        "        prompt = (\n",
        "            \"<start_of_turn> Your task is to transform the given obfuscated Korean review \"\n",
        "            \"into a clear, correct, and natural-sounding Korean review that reflects its \"\n",
        "            \"original meaning. The number of words and letters per word must be observed.\\n\"\n",
        "            f\"Input: {query}\\n\"\n",
        "            \"<end_of_turn>\\n\"\n",
        "            \"<start_of_turn>Assistant:\\n\"\n",
        "            \"Output:\"\n",
        "        )\n",
        "\n",
        "        # 텍스트 생성\n",
        "        generated = text_gen_pipeline(\n",
        "            prompt,\n",
        "            num_return_sequences=1,\n",
        "            temperature=0.2,\n",
        "            top_p=0.9,\n",
        "            max_new_tokens=len(query),\n",
        "            do_sample=True,\n",
        "            eos_token_id=tokenizer.eos_token_id\n",
        "        )\n",
        "\n",
        "        # 생성된 텍스트에서 출력 부분 추출\n",
        "        generated_text = generated[0]['generated_text']\n",
        "        output_start = generated_text.find(\"Output:\")\n",
        "\n",
        "        if output_start != -1:\n",
        "            restored_reviews.append(generated_text[output_start + len(\"Output:\"):].strip())\n",
        "        else:\n",
        "            restored_reviews.append(generated_text.strip())\n",
        "\n",
        "        # 진행 상황 출력\n",
        "        print(f\"{index + 1}/{total_reviews} 완료\", end='\\r')\n",
        "\n",
        "    return restored_reviews\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "  FINETUNE_MODEL0 = path+\"/workspace/results0221/gemma-finetuning-epoch3\"\n",
        "  BASE_MODEL0 = \"beomi/gemma-ko-7b\"\n",
        "  test0 = pd.read_csv(path+'/finetuning_test.csv')\n",
        "  restored_reviews0 = restore_reviews(FINETUNE_MODEL0, BASE_MODEL0, test0)\n",
        "\n",
        "  FINETUNE_MODEL1 = path+\"/workspace/results0225/2gemma-finetuning-epoch5\"\n",
        "  BASE_MODEL1 = \"beomi/gemma-ko-7b\"\n",
        "  test1 = pd.read_csv(path+'/finetuning2_test.csv')\n",
        "  restored_reviews1 = restore_reviews(FINETUNE_MODEL1, BASE_MODEL1, test1)"
      ],
      "metadata": {
        "id": "Jjo4JiSE4IjY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "703d89e0-bdb1-42ff-932e-5be1d9d263a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/KUBIG/DL/KUBIG_25-W STUDY/제출용/data/finetuning_test.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-7d62297f49d9>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m   \u001b[0mFINETUNE_MODEL0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/workspace/results0221/gemma-finetuning-epoch3\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m   \u001b[0mBASE_MODEL0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"beomi/gemma-ko-7b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m   \u001b[0mtest0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/finetuning_test.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0mrestored_reviews0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrestore_reviews\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFINETUNE_MODEL0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBASE_MODEL0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/KUBIG/DL/KUBIG_25-W STUDY/제출용/data/finetuning_test.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submission = pd.read_csv(path+\"/sample_submission.csv\")\n",
        "submission = pd.DataFrame()\n",
        "submission['output'] = restored_reviews0\n",
        "submission['output'] = submission['output'].apply(lambda x: x.split(\"<end_of_turn>\")[0])\n",
        "submission.to_csv(path+'/kogemma_0222_raw.csv', index = False, encoding = 'utf-8-sig')"
      ],
      "metadata": {
        "id": "yADhegeD5UXr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission = pd.read_csv(path+\"/sample_submission.csv\")\n",
        "submission = pd.DataFrame()\n",
        "submission['output'] = restored_reviews1\n",
        "submission['output'] = submission['output'].apply(lambda x: x.split(\"<end_of_turn>\")[0])\n",
        "submission.to_csv(path+'/kogemma_0226_raw.csv', index = False, encoding = 'utf-8-sig')"
      ],
      "metadata": {
        "id": "LXPgY5dj5y1y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sequence Matcher"
      ],
      "metadata": {
        "id": "FOam3kYJDUVU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import difflib\n",
        "from jamo import h2j\n",
        "from rapidfuzz import fuzz\n",
        "import re"
      ],
      "metadata": {
        "id": "J6aJW2_rDV9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## koGemma 후처리 함수"
      ],
      "metadata": {
        "id": "DckOWjcYDlCA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fuzzy_equal(a: str, b: str, threshold: float) -> bool:\n",
        "    if len(a) != len(b):\n",
        "        return False\n",
        "    return fuzz.ratio(h2j(a), h2j(b)) >= threshold\n",
        "\n",
        "def refine_replace_block(tokens_a, tokens_b, threshold: float):\n",
        "    n, m = len(tokens_a), len(tokens_b)\n",
        "    dp = [[0]*(m+1) for _ in range(n+1)]\n",
        "    for i in range(n):\n",
        "        for j in range(m):\n",
        "            if fuzzy_equal(tokens_a[i], tokens_b[j], threshold):\n",
        "                dp[i+1][j+1] = dp[i][j] + 1\n",
        "            else:\n",
        "                dp[i+1][j+1] = max(dp[i+1][j], dp[i][j+1])\n",
        "    i, j = n, m\n",
        "    matched = []\n",
        "    while i > 0 and j > 0:\n",
        "        if fuzzy_equal(tokens_a[i-1], tokens_b[j-1], threshold):\n",
        "            matched.append((i-1, j-1))\n",
        "            i -= 1\n",
        "            j -= 1\n",
        "        else:\n",
        "            if dp[i-1][j] >= dp[i][j-1]:\n",
        "                i -= 1\n",
        "            else:\n",
        "                j -= 1\n",
        "    matched.reverse()\n",
        "\n",
        "    opcodes = []\n",
        "    a_start, b_start = 0, 0\n",
        "    for a_idx, b_idx in matched:\n",
        "        if a_start < a_idx:\n",
        "            opcodes.append(('delete', a_start, a_idx, b_start, b_start))\n",
        "        opcodes.append(('equal', a_idx, a_idx+1, b_idx, b_idx+1))\n",
        "        a_start = a_idx + 1\n",
        "        b_start = b_idx + 1\n",
        "    if a_start < n:\n",
        "        opcodes.append(('delete', a_start, n, b_start, b_start))\n",
        "    return opcodes\n",
        "\n",
        "def process_pairwise_block(block_org, block_a, block_b, similarity_threshold):\n",
        "    \"\"\"\n",
        "    동일 길이의 토큰 블록에 대해, 원본(block_org)과의 유사도를 비교하여\n",
        "    더 유사한 토큰을 선택합니다.\n",
        "    \"\"\"\n",
        "    result = []\n",
        "    for org_tok, a_tok, b_tok in zip(block_org, block_a, block_b):\n",
        "        if len(a_tok) == len(b_tok):\n",
        "            score_a = fuzz.ratio(h2j(org_tok), h2j(a_tok))\n",
        "            score_b = fuzz.ratio(h2j(org_tok), h2j(b_tok))\n",
        "            result.append(a_tok if score_a > score_b else b_tok)\n",
        "        else:\n",
        "            result.append(a_tok)\n",
        "    return result\n",
        "\n",
        "def process_replace_block(block_org, block_a, block_b, similarity_threshold):\n",
        "    \"\"\"\n",
        "    replace 구간 처리:\n",
        "      - 토큰 수가 같으면 pairwise 비교,\n",
        "      - 다르면 LCS 기반으로 재세분화(refine_replace_block)를 수행하여 세부 opcodes에 따라 처리.\n",
        "    \"\"\"\n",
        "    if len(block_a) == len(block_b):\n",
        "        return process_pairwise_block(block_org, block_a, block_b, similarity_threshold)\n",
        "    else:\n",
        "        refined_opcodes = refine_replace_block(block_a, block_b, similarity_threshold)\n",
        "        result = []\n",
        "        for tag, i1, i2, j1, j2 in refined_opcodes:\n",
        "            if tag == 'equal':\n",
        "                sub_org = block_org[i1:i2]\n",
        "                sub_a = block_a[i1:i2]\n",
        "                sub_b = block_b[j1:j2]\n",
        "                if len(sub_a) == len(sub_b):\n",
        "                    result.extend(process_pairwise_block(sub_org, sub_a, sub_b, similarity_threshold))\n",
        "                else:\n",
        "                    result.extend(sub_b)\n",
        "            elif tag == 'delete':\n",
        "                result.extend(block_a[i1:i2])\n",
        "            elif tag == 'replace':\n",
        "                result.extend(block_b[j1:j2])\n",
        "        return result\n",
        "\n",
        "def transform_sentence(original: str, sent_a: str, sent_b: str, similarity_threshold=50) -> str:\n",
        "    tokens_org = original.split()\n",
        "    tokens_a = sent_a.split()\n",
        "    tokens_b = sent_b.split()\n",
        "\n",
        "    matcher = difflib.SequenceMatcher(None, tokens_a, tokens_b)\n",
        "    opcodes = matcher.get_opcodes()\n",
        "\n",
        "    result_tokens = []\n",
        "    for tag, i1, i2, j1, j2 in opcodes:\n",
        "        if tag == 'equal':\n",
        "            result_tokens.extend(tokens_b[j1:j2])\n",
        "        elif tag == 'delete':\n",
        "            result_tokens.extend(tokens_a[i1:i2])\n",
        "        elif tag == 'insert':\n",
        "            continue  # insert 구간은 무시\n",
        "        elif tag == 'replace':\n",
        "            block_org = tokens_org[i1:i2]\n",
        "            block_a = tokens_a[i1:i2]\n",
        "            block_b = tokens_b[j1:j2]\n",
        "            result_tokens.extend(process_replace_block(block_org, block_a, block_b, similarity_threshold))\n",
        "\n",
        "    len_diff = len(tokens_a) - len(result_tokens)\n",
        "    if len_diff > 0:\n",
        "        result_tokens.extend(tokens_a[-len_diff:])\n",
        "    elif len_diff < 0:\n",
        "        result_tokens = result_tokens[:len(tokens_a)]\n",
        "\n",
        "    return \" \".join(result_tokens)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    original = (\"특힌 캑쉴 1012횬눈 쌈뮷쉴 뒷펀 예열켠 싫욉귀갸 샴얼 죵때료 토엷한 샥먁한 푸갸 쉬야위 절뱌늚 쨔찌합뉘답\")\n",
        "    sent_a = (\"특히 객실 1012호는 사무실 뒤편 에어컨 실외기가 샤워 초대로 도염한 싼막한 뷰가 시양이 절반을 차취합니다\")\n",
        "    sent_b = (\"특히 객실 1012호는 사무실 뒤편 에어컨 실외기가 샤워 창틀 쪽으로 돌출한 삭막한 뷰가 시야를 차지합니다\")\n",
        "\n",
        "    # original = (\"3밗 옌아켓탁갸 1빡 학꼲 딴 뗄룟 옳걷닸\")\n",
        "    # sent_a = (\"3박 예약했다가 1박 하고 딴 데로 옮겼다\")\n",
        "    # sent_b = (\"3박 예약했다가 1박 하고 다 데로 돌려 받았다\")\n",
        "\n",
        "    original =  (\"쮜겡군 끄 와츙웨 왠 네 물켱는 쥐엊치꽃 냐걋눈 견짐 앍코 본뉘 뀔를 팡 앉에 놓꼬 낚왓단는 쮜껙긔 만뤠 샵창이 먁슴떠끼룰 줆엊터락굡욤\")\n",
        "    sent_a =    (\"치객은 그 와중에 왜 내 물거는 찢어지고 나가는 건지 않고 보니 키를 방 안에 놓고 나왔다는 취객의 만에 사장이 막스더기를 주셨더라고요\")\n",
        "    sent_b =    (\"치킨은 그 와중에 왜 내 물컵은 치워지고 나갔는 건지 알고 보니 키를 방 안에 놓고 나왔다는 치킨의 말에 사장이 마스터키를 주었다고요\")\n",
        "\n",
        "    merged = transform_sentence(original, sent_a, sent_b, similarity_threshold=50)\n",
        "    print(\"[최종 결과]\\n\", merged)\n",
        "    print(\"[문장 A 토큰 수] \", len(sent_a.split()))\n",
        "    print(\"[최종 결과 토큰 수]\", len(merged.split()))\n"
      ],
      "metadata": {
        "id": "uKxYVnQGDo6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uf7ILMYWw0r"
      },
      "source": [
        "## electra 잘못된 문장부호 추론 대체"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IRuBvvMVWw0s",
        "outputId": "137387c7-fefe-4fd8-ff78-d3b4c1a43452"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "''"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "TEST_0328\n",
        "kogemma raw\n",
        "베개에 고무의처럼 얼룩이 있어서 그린 줄 알았는데 커버를 살짝 벗겨보니 누가 침을 흘렸던 베개인지 오염돼서 생긴 얼룩에 커버를 씌운 거였습니다\n",
        "electra\n",
        "베개에 교문의처럼 얼룩이 있어서 그림일 줄 알았는데, 거버를 살짝 벗겨보니 누가 짐을 흐렸던 베개인지 옵염돼서 생긴 얼룩게 커버를 !은 것이었습니다.\n",
        "후처리\n",
        "베개에 고무의처럼 얼룩이 있어서 그림일 줄 알았는데 커버를 살짝 벗겨보니 누가 침을 흘렸던 베개인지 오염돼서 생긴 얼룩에 커버를 은 것이었습니다\n",
        "원본\n",
        "볘캐웨 꽃뮨늬철렴 얽륙익 잊엿셔 끓림민 출 앍얏눈뒈, 켜벌를 삵짝 벋겊봉뉘 눌갉 찜울 흙렸뎐 뻬게윈쥐 옮엄퉤써 쌩낀 열류궤 컵뻘를 씔운 겸씩얻숩뉜타.\n",
        "\n",
        "electra의 경우 한글 글자를 문장기호로 추론하는 경우가 있음.\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hVqIoZchWw0s"
      },
      "outputs": [],
      "source": [
        "electra = pd.read_csv(path+\"/seqmatcher_ELECTRA.csv\")\n",
        "test = pd.read_csv(path+\"/finetuning_TEST_mlp.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W5EN3YAGWw0t"
      },
      "outputs": [],
      "source": [
        "# 공백 기준으로 어절을 나누는 함수\n",
        "def split_sentence(sentence):\n",
        "    return sentence.split()\n",
        "\n",
        "# 어절 길이 비교 후 대체하는 함수\n",
        "def correct_sentence(electra_sentence, test_sentence):\n",
        "    electra_words = split_sentence(electra_sentence)\n",
        "    test_words = split_sentence(test_sentence)\n",
        "\n",
        "    # 최소한의 길이로 맞춰 비교\n",
        "    min_len = min(len(electra_words), len(test_words))\n",
        "\n",
        "    # 어절 길이가 다르면 test의 어절로 교체\n",
        "    corrected_words = [\n",
        "        test_words[i] if len(electra_words[i]) != len(test_words[i]) else electra_words[i]\n",
        "        for i in range(min_len)\n",
        "    ]\n",
        "\n",
        "    # 만약 electra 문장이 짧으면 test 문장 어절 추가\n",
        "    if len(electra_words) < len(test_words):\n",
        "        corrected_words.extend(test_words[min_len:])\n",
        "\n",
        "    return \" \".join(corrected_words)\n",
        "\n",
        "# Electra 문장 수정 적용\n",
        "electra[\"no_more_nueggimpyo\"] = [\n",
        "    correct_sentence(e_sent, t_sent) for e_sent, t_sent in zip(electra[\"input\"], test[\"input\"])\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oemtViDoWw0u"
      },
      "outputs": [],
      "source": [
        "electra[\"no_more_nueggimpyo\"].to_csv(path+\"/seqmatcher2_ELECTRA.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFR4YvmiWw0u"
      },
      "source": [
        "## kogemma 추론의 ZWS 공백문자 제거"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9m296CdLWw0u"
      },
      "source": [
        "### kogemma v1 (mlp)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "HfdAmVr-h9mn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-jta--P5Ww0u",
        "outputId": "5c35ca63-beec-439c-fd5d-6e8fce75cbcc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-f736ce236e2e>:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  zws_mask = zws.applymap(lambda x: \"\\u200b\" in str(x) if pd.notna(x) else False)\n"
          ]
        }
      ],
      "source": [
        "# 파일 경로\n",
        "file_path = path+\"/kogemma_0222_raw.csv\"\n",
        "\n",
        "# CSV 파일 로드 (모든 열을 문자열로 로드)\n",
        "zws = pd.read_csv(file_path, dtype=str)\n",
        "\n",
        "# Zero-Width Space (ZWS, U+200B) 포함 여부 확인\n",
        "zws_mask = zws.applymap(lambda x: \"\\u200b\" in str(x) if pd.notna(x) else False)\n",
        "\n",
        "# ZWS가 포함된 셀들의 위치 찾기\n",
        "zws_cells = [(row, col) for row, col in zip(*zws_mask.to_numpy().nonzero())]\n",
        "zws_count = len(zws_cells)  # ZWS 포함된 셀 개수\n",
        "print(zws_count)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_xOtGqRZWw0v",
        "outputId": "ac20ec15-a36d-439f-aa73-ed79f7d96cbb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-ec0b5c68c8f9>:2: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  zws[\"ZWS_positions\"] = zws.applymap(lambda x: [i for i, char in enumerate(str(x)) if char == \"\\u200b\"] if pd.notna(x) else [])\n",
            "<ipython-input-10-ec0b5c68c8f9>:11: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  zws_cleaned = zws.drop(columns=[\"ZWS_positions\"]).applymap(remove_zws)\n"
          ]
        }
      ],
      "source": [
        "# 각 셀에서 ZWS 위치를 저장할 새로운 컬럼 추가\n",
        "zws[\"ZWS_positions\"] = zws.applymap(lambda x: [i for i, char in enumerate(str(x)) if char == \"\\u200b\"] if pd.notna(x) else [])\n",
        "\n",
        "# ZWS 제거 함수 정의\n",
        "def remove_zws(cell):\n",
        "    if isinstance(cell, str):  # 문자열인 경우에만 처리\n",
        "        return cell.replace(\"\\u200b\", \"\")\n",
        "    return cell  # 그 외는 그대로 반환\n",
        "\n",
        "# ZWS 제거 적용\n",
        "zws_cleaned = zws.drop(columns=[\"ZWS_positions\"]).applymap(remove_zws)\n",
        "\n",
        "# 새로운 파일로 저장\n",
        "cleaned_file_path = path+\"/kogemma_0222_zws.csv\"\n",
        "zws_cleaned.to_csv(cleaned_file_path, index=False, encoding=\"utf-8-sig\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhSruFGxWw0v"
      },
      "source": [
        "### kogemma v2 (원본)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n-2FNFkvWw0v",
        "outputId": "a8157155-0c77-4a12-f07a-09b85ada22f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3988\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-19db13ac8e73>:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  zws_mask = zws.applymap(lambda x: \"\\u200b\" in str(x) if pd.notna(x) else False)\n"
          ]
        }
      ],
      "source": [
        "# 파일 경로\n",
        "file_path = path+\"/kogemma_0226_raw.csv\n",
        "\n",
        "# CSV 파일 로드 (모든 열을 문자열로 로드)\n",
        "zws = pd.read_csv(file_path, dtype=str)\n",
        "\n",
        "# Zero-Width Space (ZWS, U+200B) 포함 여부 확인\n",
        "zws_mask = zws.applymap(lambda x: \"\\u200b\" in str(x) if pd.notna(x) else False)\n",
        "\n",
        "# ZWS가 포함된 셀들의 위치 찾기\n",
        "zws_cells = [(row, col) for row, col in zip(*zws_mask.to_numpy().nonzero())]\n",
        "zws_count = len(zws_cells)  # ZWS 포함된 셀 개수\n",
        "print(zws_count)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tHrgF-5RWw0v",
        "outputId": "982d0ae5-ad6a-4234-84b8-83d92d3de99a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-4c195205dc91>:2: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  zws[\"ZWS_positions\"] = zws.applymap(lambda x: [i for i, char in enumerate(str(x)) if char == \"\\u200b\"] if pd.notna(x) else [])\n",
            "<ipython-input-12-4c195205dc91>:11: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  zws_cleaned = zws.drop(columns=[\"ZWS_positions\"]).applymap(remove_zws)\n"
          ]
        }
      ],
      "source": [
        "# 각 셀에서 ZWS 위치를 저장할 새로운 컬럼 추가\n",
        "zws[\"ZWS_positions\"] = zws.applymap(lambda x: [i for i, char in enumerate(str(x)) if char == \"\\u200b\"] if pd.notna(x) else [])\n",
        "\n",
        "# ZWS 제거 함수 정의\n",
        "def remove_zws(cell):\n",
        "    if isinstance(cell, str):  # 문자열인 경우에만 처리\n",
        "        return cell.replace(\"\\u200b\", \"\")\n",
        "    return cell  # 그 외는 그대로 반환\n",
        "\n",
        "# ZWS 제거 적용\n",
        "zws_cleaned = zws.drop(columns=[\"ZWS_positions\"]).applymap(remove_zws)\n",
        "\n",
        "# 새로운 파일로 저장\n",
        "cleaned_file_path = path+\"/kogemma_0226_zws.csv\"\n",
        "zws_cleaned.to_csv(cleaned_file_path, index=False, encoding=\"utf-8-sig\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbkeS64bWw0v"
      },
      "source": [
        "# 데이터 프레임 가공"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpKDUYUmWw0w"
      },
      "source": [
        "### kogemma v1 (mlp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mksc6yMHWw0w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "dfb6f92b-1694-4ce3-8c6f-d9aa31e17073"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/KUBIG/DL/KUBIG_25-W STUDY/제출용/data/seqmatcher_ORIGINAL.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-843921933a56>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 데이터 로드\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moriginal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/seqmatcher_ORIGINAL.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0melectra\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/seqmatcher2_ELECTRA.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0melectra\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melectra\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"no_more_nueggimpyo\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"input\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mkogemma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/kogemma_0222_zws.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"output\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"input\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/KUBIG/DL/KUBIG_25-W STUDY/제출용/data/seqmatcher_ORIGINAL.csv'"
          ]
        }
      ],
      "source": [
        "# 데이터 로드\n",
        "original = pd.read_csv(path+\"/seqmatcher_ORIGINAL.csv\")\n",
        "electra = pd.read_csv(path+\"/seqmatcher2_ELECTRA.csv\")\n",
        "electra = electra.rename(columns={\"no_more_nueggimpyo\": \"input\"})\n",
        "kogemma = pd.read_csv(path+\"/kogemma_0222_zws.csv\").rename(columns={\"output\": \"input\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k6kem546Ww0w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "ba634447-4d01-420b-9442-9690502e68d5"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'electra' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-26202b324faf>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 새로운 데이터프레임 생성\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0melectra\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0msent_original_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moriginal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msent_a_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melectra\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'electra' is not defined"
          ]
        }
      ],
      "source": [
        "# 새로운 데이터프레임 생성\n",
        "df = pd.DataFrame()\n",
        "for column in electra.columns:\n",
        "    sent_original_list = original[column].astype(str).tolist()\n",
        "    sent_a_list = electra[column].astype(str).tolist()\n",
        "    sent_b_list = kogemma[column].astype(str).tolist()\n",
        "    df[f\"{column}_electra\"] = sent_a_list\n",
        "    df[f\"{column}_kogemma\"] = [transform_sentence(o ,a, b, 50) for o, a, b in zip(sent_original_list, sent_a_list, sent_b_list)]\n",
        "\n",
        "# 결과 저장\n",
        "df.to_csv(path+\"/0227_electra_vs_kogemmaV1.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index_data = pd.read_csv(path+\"/test_chunked_dec1.csv\")\n",
        "df = pd.read_csv(path+\"/0227_electra_vs_kogemmaV1.csv\")\n",
        "df[\"index\"] = index_data[\"index\"]\n",
        "df_unchunk = df.groupby(\"index\")[\"input_kogemma\"].apply(lambda x: \" \".join(x)).reset_index()\n",
        "df_unchunk = df_unchunk.drop(columns=\"index\")\n",
        "df_unchunk.to_csv(path+\"/0227_unchunk_electra_vs_kogemmaV1.csv\", index=False)"
      ],
      "metadata": {
        "id": "TABV7TtTIZq0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "405f7ae2-0d49-4dc3-e3bd-24e6f721c525"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/KUBIG/DL/KUBIG_25-W STUDY/제출용/data/test_chunked_dec1.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-509144c90e4c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mindex_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/test_chunked_dec1.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/0227_electra_vs_kogemmaV1.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"index\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"index\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf_unchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_kogemma\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf_unchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_unchunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/KUBIG/DL/KUBIG_25-W STUDY/제출용/data/test_chunked_dec1.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouKtnpQ1Ww0w"
      },
      "source": [
        "### kogemma v2 (원본)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fl46BxsyWw0w"
      },
      "outputs": [],
      "source": [
        "# 데이터 로드\n",
        "original = pd.read_csv(path+\"/seqmatcher_ORIGINAL.csv\")\n",
        "electra = pd.read_csv(path+\"/seqmatcher2_ELECTRA.csv\")\n",
        "electra = electra.rename(columns={\"no_more_nueggimpyo\": \"input\"})\n",
        "#kogemma = pd.read_csv(\"data/seqmatcher_kogemma.csv\")\n",
        "kogemma = pd.read_csv(path+\"/kogemma_0226_zws.csv\").rename(columns={\"output\": \"input\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kYFU4VSjWw0w"
      },
      "outputs": [],
      "source": [
        "# 새로운 데이터프레임 생성\n",
        "df = pd.DataFrame()\n",
        "for column in electra.columns:\n",
        "    sent_original_list = original[column].astype(str).tolist()\n",
        "    sent_a_list = electra[column].astype(str).tolist()\n",
        "    sent_b_list = kogemma[column].astype(str).tolist()\n",
        "    df[f\"{column}_electra\"] = sent_a_list\n",
        "    df[f\"{column}_kogemma\"] = [transform_sentence(o ,a, b, 50) for o, a, b in zip(sent_original_list, sent_a_list, sent_b_list)]\n",
        "\n",
        "# 결과 저장\n",
        "df.to_csv(path+\"/0227_electra_vs_kogemmaV2.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k492HoeGWw0y"
      },
      "outputs": [],
      "source": [
        "index_data = pd.read_csv(path+\"/test_chunked_dec1.csv\")\n",
        "df = pd.read_csv(path+\"/0227_electra_vs_kogemmaV2.csv\")\n",
        "df[\"index\"] = index_data[\"index\"]\n",
        "df_unchunk = df.groupby(\"index\")[\"input_kogemma\"].apply(lambda x: \" \".join(x)).reset_index()\n",
        "df_unchunk = df_unchunk.drop(columns=\"index\")\n",
        "df_unchunk.to_csv(path+\"/0227_unchunk_electra_vs_kogemmaV2.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryH9dbNDWw03"
      },
      "source": [
        "# 문장 부호 붙이기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wtHvXd-wWw03"
      },
      "outputs": [],
      "source": [
        "def replace_with_kogemma(test_text, kogemma_text):\n",
        "    \"\"\"\n",
        "    test_text에서 (가-힣, a-z, A-Z, 0-9)만 순회하며\n",
        "    kogemma_text(공백 제거) 글자들을 순서대로 치환.\n",
        "    만약 글자 수가 다르면 알림 메시지를 리턴.\n",
        "    \"\"\"\n",
        "    # 1) kogemma_text에서 공백 제거 -> 각 글자 리스트\n",
        "    kogemma_chars = list(kogemma_text.replace(\" \", \"\"))\n",
        "\n",
        "    # 2) test_text 내 치환 대상 글자 수 세기\n",
        "    test_valid_chars = re.findall(r'[가-힣a-zA-Z0-9]', test_text)\n",
        "    test_valid_count = len(test_valid_chars)\n",
        "    kogemma_count = len(kogemma_chars)\n",
        "\n",
        "    # 3) 글자 수가 다르면 알림만 리턴\n",
        "    #if test_valid_count != kogemma_count:\n",
        "    #   return f\"[글자 수 불일치] test:{test_valid_count}, unchunked:{kogemma_count} - 내용: {test_text}\"\n",
        "\n",
        "    # 4) 한 글자씩 교체 진행\n",
        "    result_chars = []\n",
        "    idx = 0  # kogemma_chars 인덱스\n",
        "    for ch in test_text:\n",
        "        # (가-힣, a-zA-Z, 0-9)이면 교체\n",
        "        if re.match(r'[가-힣a-zA-Z0-9]', ch):\n",
        "            result_chars.append(kogemma_chars[idx])\n",
        "            idx += 1\n",
        "        else:\n",
        "            # 그 외 (공백, 문장부호, 이모티콘 등)은 그대로 둠\n",
        "            result_chars.append(ch)\n",
        "\n",
        "    return \"\".join(result_chars)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUB_uOIoWw04"
      },
      "source": [
        "### kogemma v1 (mlp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PzMZ1HoZWw04"
      },
      "outputs": [],
      "source": [
        "test_df = pd.read_csv(path+\"/test.csv\")\n",
        "kogemma_unchunked_df = pd.read_csv(path+\"/0227_unchunk_electra_vs_kogemmaV1.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xtOxH6uCWw04"
      },
      "outputs": [],
      "source": [
        "# DF를 순회하면서 치환 결과를 새로운 컬럼으로 넣음\n",
        "df_result = pd.DataFrame(columns=['input', 'input_kogemma', 'output'])\n",
        "\n",
        "for i in range(len(test_df)):\n",
        "    t = test_df.loc[i, 'input']\n",
        "    k = kogemma_unchunked_df.loc[i, 'input_kogemma']\n",
        "    replaced_text = replace_with_kogemma(t, k)\n",
        "\n",
        "    df_result.loc[i] = [t, k, replaced_text]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OtGNrtz4Ww04"
      },
      "outputs": [],
      "source": [
        "sample = pd.read_csv(path+\"/sample_submission.csv\")\n",
        "sample[\"output\"] = df_result[\"output\"]\n",
        "sample.to_csv(path+\"/0227_koGemma_v1.csv\", index=False)\n",
        "temp = pd.read_csv(path+\"/test.csv\")\n",
        "sum(len(temp[\"input\"].iloc[i]) != len(sample[\"output\"].iloc[i]) for i in range(len(temp))) # 길이 검증, 0 나와야함"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dw1FsOIrWw04"
      },
      "source": [
        "### kogemma v2 (원본)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SMdQXZL9Ww04"
      },
      "outputs": [],
      "source": [
        "test_df = pd.read_csv(path+\"/test.csv\")\n",
        "kogemma_unchunked_df = pd.read_csv(\"data/0227_unchunk_electra_vs_kogemmaV2.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r5MXbArqWw04"
      },
      "outputs": [],
      "source": [
        "# DF를 순회하면서 치환 결과를 새로운 컬럼으로 넣음\n",
        "df_result = pd.DataFrame(columns=['input', 'input_kogemma', 'output'])\n",
        "\n",
        "for i in range(len(test_df)):\n",
        "    t = test_df.loc[i, 'input']\n",
        "    k = kogemma_unchunked_df.loc[i, 'input_kogemma']\n",
        "    replaced_text = replace_with_kogemma(t, k)\n",
        "\n",
        "    df_result.loc[i] = [t, k, replaced_text]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hU_wWTDzWw04"
      },
      "outputs": [],
      "source": [
        "sample = pd.read_csv(path+\"/sample_submission.csv\")\n",
        "sample[\"output\"] = df_result[\"output\"]\n",
        "sample.to_csv(path+\"/0227_koGemma_v2.csv\", index=False)\n",
        "temp = pd.read_csv(\"test.csv\")\n",
        "sum(len(temp[\"input\"].iloc[i]) != len(sample[\"output\"].iloc[i]) for i in range(len(temp))) # 길이 검증, 0 나와야함"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sentence Selection with perplexity computed by Bllossom 8B"
      ],
      "metadata": {
        "id": "lKck7X1QxFoq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "def calculate_perplexity(sentence: str, model, tokenizer, device: str) -> float:\n",
        "    encodings = tokenizer(sentence, return_tensors=\"pt\")\n",
        "    input_ids = encodings.input_ids.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, labels=input_ids)\n",
        "        loss = outputs.loss\n",
        "\n",
        "    # perplexity\n",
        "    perplexity = torch.exp(loss)\n",
        "    return perplexity.item()"
      ],
      "metadata": {
        "id": "OzwulKI1uUkm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"MLP-KTLim/llama-3-Korean-Bllossom-8B\"\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153,
          "referenced_widgets": [
            "2eb64625b8ea40259aa3842d16b22613",
            "9709551ae20740e0b71b527756fc3475",
            "3f9d9e28577644a4bc721c54a6628db2",
            "4b2e6fa9cfbb49be9e12bf0b071fb5eb",
            "7de25ac32d694bc3acfcb7f7525f8f9e",
            "f7381dc1f6e3481da7dd22776175f4e2",
            "699dceee7231421ebd0f8990643c3b2a",
            "f39a5d7b16df48cc8cc9c15f10908946",
            "4d4b53e5709f40d8aea651288ebbb478",
            "ed38f5b3f7f14baf8697da05179a390a",
            "2d41565c793642b2b1d9e57cf0b6a103"
          ]
        },
        "id": "dpo2Kd3ju-bZ",
        "outputId": "83ee1d10-9ca6-469f-d8ec-7a822366f999",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2eb64625b8ea40259aa3842d16b22613"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ym1_gGfE0O4f"
      },
      "outputs": [],
      "source": [
        "data1 = pd.read_csv(path+\"/0227_koGemma_v1.csv\")\n",
        "data2 = pd.read_csv(path+\"/submission_electra.csv\")\n",
        "data3 = pd.read_csv(path+\"/0227_koGemma_v2.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xolVWK180S2V"
      },
      "source": [
        "## Cleaning Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bVnA7f5nJ4Ej"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'[^가-힣a-zA-Z0-9\\s(),.!?\\'\\\"\\[\\]\\{\\}:]', '', text)\n",
        "    text = re.sub(r'[ㄱ-ㅎㅏ-ㅣ]', '', text)\n",
        "    text = text.strip()\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    return text\n",
        "\n",
        "def split_sentences(text):\n",
        "    sentences = re.split(r'(?<=[.!?])\\s', text)\n",
        "    sentences = [sentence.strip() for sentence in sentences if sentence]\n",
        "    merged_sentences = []\n",
        "    temp = \"\"\n",
        "    open_bracket_count = 0\n",
        "\n",
        "    for i, sentence in enumerate(sentences):\n",
        "        open_bracket_count += sentence.count(\"(\")\n",
        "        open_bracket_count -= sentence.count(\")\")\n",
        "        if (len(sentence) <= 15 and i < len(sentences) - 1) or open_bracket_count > 0:\n",
        "            temp += sentence + \" \"\n",
        "        else:\n",
        "            temp += sentence\n",
        "            merged_sentences.append(temp)\n",
        "            temp = \"\"\n",
        "\n",
        "    if temp:\n",
        "        merged_sentences.append(temp.strip())\n",
        "\n",
        "    if len(merged_sentences) > 1:\n",
        "        merged_sentences[-2] += \" \" + merged_sentences[-1]\n",
        "        merged_sentences.pop()\n",
        "    return merged_sentences\n",
        "\n",
        "\n",
        "def clean_and_chunk_data(data):\n",
        "    data['cleaned_output'] = data['output'].apply(clean_text)\n",
        "    data['length'] = data['cleaned_output'].apply(len)\n",
        "    max_length = data['length'].max()\n",
        "    data['chunked_output'] = data['cleaned_output'].apply(split_sentences)\n",
        "    data_chunked = data.explode('chunked_output')[['chunked_output']].reset_index(drop=False)\n",
        "    data_chunked['len'] = data_chunked['chunked_output'].apply(len)\n",
        "    data_chunked.drop(columns=['len'], inplace=True, errors='ignore')\n",
        "\n",
        "    return data_chunked, max_length\n",
        "\n",
        "data1_chunked, max_length1 = clean_and_chunk_data(data1)\n",
        "data2_chunked, max_length2 = clean_and_chunk_data(data2)\n",
        "data3_chunked, max_length3 = clean_and_chunk_data(data3)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_length1, max_length2, max_length3"
      ],
      "metadata": {
        "id": "0RCvNWtyJkdL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eOEGDpjLVp1B"
      },
      "outputs": [],
      "source": [
        "data = pd.concat([data1_chunked, data2_chunked[['chunked_output']], data3_chunked[['chunked_output']]], axis =1)\n",
        "data.columns = ['index','kogemma','electra', 'kogemma_v2']\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.to_csv(path+\"/data_chunked.csv\", index=False)"
      ],
      "metadata": {
        "id": "75uqW1LLJwIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Kogemma vs Electra"
      ],
      "metadata": {
        "id": "SQ6QBkUpzWQX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Candidates"
      ],
      "metadata": {
        "id": "jpOHEROOsW9L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(path+\"/data_chunked.csv\")"
      ],
      "metadata": {
        "id": "xyVC3xbdsqC4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "2167ad3f-7465-44d3-bfe4-84782f972c10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'pd' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-a4d00bb8d071>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/data_chunked.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import product\n",
        "\n",
        "def generate_candidate_sentences(sentence1: str, sentence2: str) -> list:\n",
        "\n",
        "    tokens1 = sentence1.split()\n",
        "    tokens2 = sentence2.split()\n",
        "\n",
        "    if len(tokens1) != len(tokens2):\n",
        "        raise ValueError(\"두 문장의 어절 수가 동일해야 합니다.\")\n",
        "\n",
        "    candidate_tokens = []\n",
        "    for t1, t2 in zip(tokens1, tokens2):\n",
        "        # 어절이 동일하면 한 가지 선택지만, 다르면 두 가지 선택지를 사용합니다.\n",
        "        candidate_tokens.append([t1] if t1 == t2 else [t1, t2])\n",
        "\n",
        "    # Cartesian product를 사용해 모든 조합의 문장을 생성합니다.\n",
        "    candidates = [\" \".join(tokens) for tokens in product(*candidate_tokens)]\n",
        "    return candidates\n",
        "\n",
        "data['candidate'] = data.apply(lambda row: generate_candidate_sentences(row['kogemma'], row['electra']), axis=1)\n",
        "data['len'] = data.apply(lambda x: len(x['candidate']) if len(x['candidate']) > 1 else 0, axis = 1)\n",
        "data['sent_len'] = data.apply(lambda x: len(x['kogemma'].split()), axis = 1)"
      ],
      "metadata": {
        "id": "KQ0KbSb_sY_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['len'].value_counts()"
      ],
      "metadata": {
        "id": "s3TjpgMcKVZ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## perplexity"
      ],
      "metadata": {
        "id": "3lCabxu120c8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "tqdm.pandas()"
      ],
      "metadata": {
        "id": "KcZbDqu2bEqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_blank(text):\n",
        "    text = text.strip()  # 좌우 공백 제거\n",
        "    text = re.sub(r'\\s+', ' ', text)  # 연속된 공백을 하나로 변환\n",
        "    return text\n",
        "\n",
        "def restore_original_text(original_text, decoded_text):\n",
        "\n",
        "    restored_text = \"\"\n",
        "    decoded_idx = 0  # 해독된 텍스트에서 현재 참조 중인 문자 위치\n",
        "\n",
        "    # 한글, 영어, 숫자, 공백, 문장부호만 허용하는 정규식\n",
        "    valid_char_pattern = re.compile(r'[가-힣a-zA-Z0-9(),.!?\\'\\\"\\[\\]\\{\\}:]')\n",
        "\n",
        "\n",
        "    for char in original_text:\n",
        "        if valid_char_pattern.match(char):\n",
        "            # 유효한 문자일 경우, 해독된 문자로 대체\n",
        "            if decoded_idx < len(decoded_text):\n",
        "                restored_text += decoded_text[decoded_idx]\n",
        "                decoded_idx += 1\n",
        "            else:\n",
        "                # 만약 해독된 텍스트가 끝났다면 원문 문자 그대로 추가\n",
        "                restored_text += char\n",
        "        else:\n",
        "            # 특수문자 및 불완전한 한글은 원문 그대로 유지\n",
        "            restored_text += char\n",
        "\n",
        "    return restored_text\n",
        "\n",
        "def check_double_blanks(text):\n",
        "    return bool(re.search(r' {2,}', text))\n",
        "\n",
        "def check_repeated_last_char(text):\n",
        "    return bool(re.search(r'([가-힣])\\1+$', text))\n",
        "\n",
        "def remove_trailing_unks(text):\n",
        "\n",
        "    cleaned_text = re.sub(r'(<unk>\\s*)+$', '', text)\n",
        "    return cleaned_text\n",
        "\n",
        "def post_processing(data, data_chunked, result, test_flg = True):\n",
        "  temp = data.copy()\n",
        "  temp_chunked = data_chunked.copy()\n",
        "\n",
        "  temp_chunked['result'] = result\n",
        "  data_recovered = temp_chunked.groupby(\"index\").agg(list).reset_index(drop=True)\n",
        "  if test_flg:\n",
        "    data_recovered.columns = ['kogemma','electra', 'result']\n",
        "    data_recovered['result'] = data_recovered['result'].apply(lambda x: ' '.join(x))\n",
        "  else:\n",
        "    data_recovered.columns = ['input_DEC1','output','input_DEC2']\n",
        "    data_recovered['input_DEC2'] = data_recovered['input_DEC2'].apply(lambda x: ' '.join(x))\n",
        "\n",
        "  temp['input'] = temp.apply(lambda x: clean_blank(x['input']), axis = 1)\n",
        "\n",
        "  temp['result'] = data_recovered['result']\n",
        "  temp['result'] = temp.apply(lambda x: clean_blank(x['result']), axis = 1)\n",
        "  temp['result'] = temp.apply(lambda x: x['result'].replace(\" \",\"\"), axis= 1)\n",
        "\n",
        "  temp['result'] = temp.apply(lambda x: restore_original_text(x['input'],x['result']), axis = 1)\n",
        "\n",
        "  return temp"
      ],
      "metadata": {
        "id": "lPVTH4RfE7-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## comparison"
      ],
      "metadata": {
        "id": "U51tVtiPbdqn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def select_best_candidate(candidates: list, model, tokenizer, device: str, sentence1: str, sentence2: str) -> str:\n",
        "    \"\"\"\n",
        "    후보 문장 리스트에서, 후보 수에 따라 다음과 같이 선택.\n",
        "      - 후보가 1개이면: 바로 그 문장을 선택 (펄플렉시티 계산 없이)\n",
        "      - 후보가 200개 이상이면: 두 원본 문장(sentence1, sentence2)만 펄플렉시티를 계산하여 더 낮은 값을 가진 문장을 선택\n",
        "      - 그 외의 경우: 모든 후보 문장에 대해 펄플렉시티를 계산한 후, 가장 낮은 값을 가진 문장을 선택\n",
        "\n",
        "    Returns:\n",
        "        (best_candidate, best_ppl): 선택된 문장과 그 perplexity 값 (계산하지 않은 경우 None)\n",
        "    \"\"\"\n",
        "    if len(candidates) == 1:\n",
        "        # 후보가 단 1개이면, 바로 반환 (펄플렉시티 계산 없이)\n",
        "        best_candidate = candidates[0]\n",
        "        return best_candidate\n",
        "\n",
        "    elif len(candidates) >= 200:\n",
        "        # 후보가 너무 많으면, 원본 두 문장끼리만 펄플렉시티를 계산.\n",
        "        ppl1 = calculate_perplexity(sentence1, model, tokenizer, device)\n",
        "        ppl2 = calculate_perplexity(sentence2, model, tokenizer, device)\n",
        "        best_candidate = sentence1 if ppl1 < ppl2 else sentence2\n",
        "        return best_candidate\n",
        "\n",
        "    else:\n",
        "        # 후보가 200개 미만인 경우: 모든 후보에 대해 펄플렉시티를 계산.\n",
        "        best_candidate = None\n",
        "        best_ppl = float(\"inf\")\n",
        "        for candidate in candidates:\n",
        "            ppl = calculate_perplexity(candidate, model, tokenizer, device)\n",
        "            if ppl < best_ppl:\n",
        "                best_ppl = ppl\n",
        "                best_candidate = candidate\n",
        "        return best_candidate"
      ],
      "metadata": {
        "id": "KxcFbuOzbI3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()\n",
        "data['best_sentence'] = data.progress_apply(lambda x: select_best_candidate(x['candidate'],\n",
        "                                                                            model, tokenizer, device,\n",
        "                                                                            x['kogemma'],\n",
        "                                                                            x['electra']), axis=1)"
      ],
      "metadata": {
        "id": "xnL30nNvbLIw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.read_csv(path+'/test.csv')\n",
        "sub = post_processing(test, data[['index','kogemma','electra']], data['best_sentence'])\n",
        "sub.drop('input', axis = 1, inplace = True)\n",
        "sub.columns = ['ID', 'output']\n",
        "sub.to_csv(path+'/kogemma vs electra(submission).csv', index = False)"
      ],
      "metadata": {
        "id": "UCUwaccz8VfW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Kogemma vs Kogemma_v2"
      ],
      "metadata": {
        "id": "IK7_j1r5zeO2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Candidates"
      ],
      "metadata": {
        "id": "YPSboFLTzeO3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(path+\"/data_chunked.csv\")"
      ],
      "metadata": {
        "id": "A-w_lGlizeO3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import product\n",
        "\n",
        "def generate_candidate_sentences(sentence1: str, sentence2: str) -> list:\n",
        "\n",
        "    tokens1 = sentence1.split()\n",
        "    tokens2 = sentence2.split()\n",
        "\n",
        "    if len(tokens1) != len(tokens2):\n",
        "        raise ValueError(\"두 문장의 어절 수가 동일해야 합니다.\")\n",
        "\n",
        "    candidate_tokens = []\n",
        "    for t1, t2 in zip(tokens1, tokens2):\n",
        "        # 어절이 동일하면 한 가지 선택지만, 다르면 두 가지 선택지를 사용합니다.\n",
        "        candidate_tokens.append([t1] if t1 == t2 else [t1, t2])\n",
        "\n",
        "    # Cartesian product를 사용해 모든 조합의 문장을 생성합니다.\n",
        "    candidates = [\" \".join(tokens) for tokens in product(*candidate_tokens)]\n",
        "    return candidates\n",
        "\n",
        "data['candidate'] = data.apply(lambda row: generate_candidate_sentences(row['kogemma'], row['kogemma_v2']), axis=1)\n",
        "data['len'] = data.apply(lambda x: len(x['candidate']) if len(x['candidate']) > 1 else 0, axis = 1)\n",
        "data['sent_len'] = data.apply(lambda x: len(x['kogemma'].split()), axis = 1)"
      ],
      "metadata": {
        "id": "byV4Yk01zeO3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['len'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "id": "gVkFPmMMKpr1",
        "outputId": "9d910147-89a9-4e55-a081-46ef8f66d192"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "len\n",
              "0        3003\n",
              "2        1305\n",
              "4         614\n",
              "8         227\n",
              "16        114\n",
              "32         51\n",
              "64         19\n",
              "128        12\n",
              "256         7\n",
              "512         4\n",
              "2048        2\n",
              "16384       2\n",
              "1024        1\n",
              "8192        1\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>len</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1305</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>614</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>227</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>114</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>256</th>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>512</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2048</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16384</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1024</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8192</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## comparison"
      ],
      "metadata": {
        "id": "bwfIcPAszeO5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def select_best_candidate(candidates: list, model, tokenizer, device: str, sentence1: str, sentence2: str) -> str:\n",
        "    \"\"\"\n",
        "    후보 문장 리스트에서, 후보 수에 따라 다음과 같이 선택.\n",
        "      - 후보가 1개이면: 바로 그 문장을 선택 (펄플렉시티 계산 없이)\n",
        "      - 후보가 200개 이상이면: 두 원본 문장(sentence1, sentence2)만 펄플렉시티를 계산하여 더 낮은 값을 가진 문장을 선택\n",
        "      - 그 외의 경우: 모든 후보 문장에 대해 펄플렉시티를 계산한 후, 가장 낮은 값을 가진 문장을 선택\n",
        "\n",
        "    Returns:\n",
        "        (best_candidate, best_ppl): 선택된 문장과 그 perplexity 값 (계산하지 않은 경우 None)\n",
        "    \"\"\"\n",
        "    if len(candidates) == 1:\n",
        "        # 후보가 단 1개이면, 바로 반환 (펄플렉시티 계산 없이)\n",
        "        best_candidate = candidates[0]\n",
        "        return best_candidate\n",
        "\n",
        "    elif len(candidates) >= 300: # 할만해보여서 256까지 허용\n",
        "        # 후보가 너무 많으면, 원본 두 문장끼리만 펄플렉시티를 계산.\n",
        "        ppl1 = calculate_perplexity(sentence1, model, tokenizer, device)\n",
        "        ppl2 = calculate_perplexity(sentence2, model, tokenizer, device)\n",
        "        best_candidate = sentence1 if ppl1 < ppl2 else sentence2\n",
        "        return best_candidate\n",
        "\n",
        "    else:\n",
        "        # 후보가 300개 미만인 경우: 모든 후보에 대해 펄플렉시티를 계산.\n",
        "        best_candidate = None\n",
        "        best_ppl = float(\"inf\")\n",
        "        for candidate in candidates:\n",
        "            ppl = calculate_perplexity(candidate, model, tokenizer, device)\n",
        "            if ppl < best_ppl:\n",
        "                best_ppl = ppl\n",
        "                best_candidate = candidate\n",
        "        return best_candidate\n"
      ],
      "metadata": {
        "id": "x4_MGSTHzeO5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()\n",
        "data['best_sentence'] = data.progress_apply(lambda x: select_best_candidate(x['candidate'],\n",
        "                                                                            model, tokenizer, device,\n",
        "                                                                            x['kogemma'],\n",
        "                                                                            x['kogemma_v2']), axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "2ef2e8c7-b2d4-4e86-d95f-436aa18567fd",
        "id": "NJdhYahjzeO5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-5fed14f39b67>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m data['best_sentence'] = data.progress_apply(lambda x: select_best_candidate(x['candidate'],\n\u001b[1;32m      5\u001b[0m                                                                             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def clean_blank(text):\n",
        "    text = text.strip()  # 좌우 공백 제거\n",
        "    text = re.sub(r'\\s+', ' ', text)  # 연속된 공백을 하나로 변환\n",
        "    return text\n",
        "\n",
        "def restore_original_text(original_text, decoded_text):\n",
        "\n",
        "    restored_text = \"\"\n",
        "    decoded_idx = 0  # 해독된 텍스트에서 현재 참조 중인 문자 위치\n",
        "\n",
        "    # 한글, 영어, 숫자, 공백, 문장부호만 허용하는 정규식\n",
        "    valid_char_pattern = re.compile(r'[가-힣a-zA-Z0-9(),.!?\\'\\\"\\[\\]\\{\\}:]')\n",
        "\n",
        "\n",
        "    for char in original_text:\n",
        "        if valid_char_pattern.match(char):\n",
        "            # 유효한 문자일 경우, 해독된 문자로 대체\n",
        "            if decoded_idx < len(decoded_text):\n",
        "                restored_text += decoded_text[decoded_idx]\n",
        "                decoded_idx += 1\n",
        "            else:\n",
        "                # 만약 해독된 텍스트가 끝났다면 원문 문자 그대로 추가\n",
        "                restored_text += char\n",
        "        else:\n",
        "            # 특수문자 및 불완전한 한글은 원문 그대로 유지\n",
        "            restored_text += char\n",
        "\n",
        "    return restored_text\n",
        "\n",
        "def check_double_blanks(text):\n",
        "    return bool(re.search(r' {2,}', text))\n",
        "\n",
        "def check_repeated_last_char(text):\n",
        "    return bool(re.search(r'([가-힣])\\1+$', text))\n",
        "\n",
        "def remove_trailing_unks(text):\n",
        "\n",
        "    cleaned_text = re.sub(r'(<unk>\\s*)+$', '', text)\n",
        "    return cleaned_text\n",
        "\n",
        "def post_processing(data, data_chunked, result, test_flg = True):\n",
        "  temp = data.copy()\n",
        "  temp_chunked = data_chunked.copy()\n",
        "\n",
        "  # for i in range(len(result)):\n",
        "  #   result[i] = remove_trailing_unks(result[i])\n",
        "\n",
        "  temp_chunked['result'] = result\n",
        "  data_recovered = temp_chunked.groupby(\"index\").agg(list).reset_index(drop=True)\n",
        "  if test_flg:\n",
        "    data_recovered.columns = ['kogemma','kogemma_v2', 'result']\n",
        "    data_recovered['result'] = data_recovered['result'].apply(lambda x: ' '.join(x))\n",
        "  else:\n",
        "    data_recovered.columns = ['input_DEC1','output','input_DEC2']\n",
        "    data_recovered['input_DEC2'] = data_recovered['input_DEC2'].apply(lambda x: ' '.join(x))\n",
        "\n",
        "  temp['input'] = temp.apply(lambda x: clean_blank(x['input']), axis = 1)\n",
        "\n",
        "  temp['result'] = data_recovered['result']\n",
        "  temp['result'] = temp.apply(lambda x: clean_blank(x['result']), axis = 1)\n",
        "  temp['result'] = temp.apply(lambda x: x['result'].replace(\" \",\"\"), axis= 1)\n",
        "\n",
        "  temp['result'] = temp.apply(lambda x: restore_original_text(x['input'],x['result']), axis = 1)\n",
        "\n",
        "  return temp"
      ],
      "metadata": {
        "id": "zTBnPKf9zeO5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.read_csv(path+'/test.csv')\n",
        "sub = post_processing(test, data[['index','kogemma','kogemma_v2']], data['best_sentence'])\n",
        "sub.drop('input', axis = 1, inplace = True)\n",
        "sub.columns = ['ID', 'output']\n",
        "sub.to_csv(path+'/kogemma vs kogemma_v2(submission).csv', index = False)"
      ],
      "metadata": {
        "id": "Mo7omgBUzeO5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "94548f46-ea28-46ac-cfb2-d3b62cc1c5e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'best_sentence'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'best_sentence'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-0c97de1ae46a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/test.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msub\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpost_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'index'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'kogemma'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'kogemma_v2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'best_sentence'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'input'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'ID'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'output'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/kogemma vs kogemma_v2(submission).csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'best_sentence'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# result1 vs result2"
      ],
      "metadata": {
        "id": "TedDVQ5N5H2V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results"
      ],
      "metadata": {
        "id": "Qj-gJODv5QGW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data1 = pd.read_csv(path+'/kogemma vs electra(submission).csv')\n",
        "data2 = pd.read_csv(path+'/kogemma vs kogemma_v2(submission).csv')"
      ],
      "metadata": {
        "id": "3RtTgcXc5Rbe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQs_l8zy5l3J"
      },
      "source": [
        "## Cleaning Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5BOxLnVC5l3J"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "    # 1. 한국어(가-힣), 영어(a-zA-Z), 숫자(0-9), 공백(\\s) 외 특수문자 제거\n",
        "    text = re.sub(r'[^가-힣a-zA-Z0-9\\s(),.!?\\'\\\"\\[\\]\\{\\}:]', '', text)\n",
        "\n",
        "    # 2. ㅋㅋ, ㅜㅜ, ㅠㅠ, ㅎㅎ 등과 같은 불완전한 한글 제거\n",
        "    text = re.sub(r'[ㄱ-ㅎㅏ-ㅣ]', '', text)\n",
        "\n",
        "    text = text.strip()  # 좌우 공백 제거\n",
        "    text = re.sub(r'\\s+', ' ', text)  # 연속된 공백을 하나로 변환\n",
        "\n",
        "    return text\n",
        "\n",
        "def split_sentences(text):\n",
        "    # 기본적인 문장 분리\n",
        "    sentences = re.split(r'(?<=[.!?])\\s', text)\n",
        "    sentences = [sentence.strip() for sentence in sentences if sentence]  # 공백 제거 및 빈 요소 제거\n",
        "\n",
        "    merged_sentences = []\n",
        "    temp = \"\"\n",
        "    open_bracket_count = 0  # 열린 괄호 개수\n",
        "\n",
        "    for i, sentence in enumerate(sentences):\n",
        "        # 괄호 개수 체크\n",
        "        open_bracket_count += sentence.count(\"(\")\n",
        "        open_bracket_count -= sentence.count(\")\")\n",
        "\n",
        "        # 문장이 15자 이하이거나, 괄호가 닫히지 않았다면 다음 문장과 결합\n",
        "        if (len(sentence) <= 15 and i < len(sentences) - 1) or open_bracket_count > 0:\n",
        "            temp += sentence + \" \"\n",
        "        else:\n",
        "            temp += sentence\n",
        "            merged_sentences.append(temp)\n",
        "            temp = \"\"  # temp 초기화\n",
        "\n",
        "    if temp:  # 마지막 문장이 남아 있다면 추가\n",
        "        merged_sentences.append(temp.strip())\n",
        "\n",
        "    # 마지막 문장은 반드시 마지막에서 두 번째 문장과 결합\n",
        "    if len(merged_sentences) > 1:\n",
        "        merged_sentences[-2] += \" \" + merged_sentences[-1]\n",
        "        merged_sentences.pop()  # 마지막 문장 제거 (이미 합쳐졌으므로)\n",
        "\n",
        "    return merged_sentences\n",
        "\n",
        "def clean_and_chunk_data(data):\n",
        "    data['cleaned_output'] = data['output'].apply(clean_text)\n",
        "    data['length'] = data['cleaned_output'].apply(len)\n",
        "    max_length = data['length'].max()\n",
        "    data['chunked_output'] = data['cleaned_output'].apply(split_sentences)\n",
        "    data_chunked = data.explode('chunked_output')[['chunked_output']].reset_index(drop=False)\n",
        "    data_chunked['len'] = data_chunked['chunked_output'].apply(len)\n",
        "    data_chunked.drop(columns=['len'], inplace=True, errors='ignore')\n",
        "    return data_chunked, max_length\n",
        "\n",
        "# 각 데이터에 함수 적용\n",
        "data1_chunked, max_length1 = clean_and_chunk_data(data1)\n",
        "data2_chunked, max_length2 = clean_and_chunk_data(data2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.concat([data1_chunked, data2_chunked[['chunked_output']]], axis =1)\n",
        "data.columns = ['index','result1','result2']\n",
        "data.to_csv(path+\"/results_chunked.csv\", index=False)"
      ],
      "metadata": {
        "id": "D2sv0CZ55l3M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Candidates"
      ],
      "metadata": {
        "id": "uED-8x9E5H2W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(path+\"/results_chunked.csv\")"
      ],
      "metadata": {
        "id": "iuNRJMfk5H2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import product\n",
        "\n",
        "def generate_candidate_sentences(sentence1: str, sentence2: str) -> list:\n",
        "\n",
        "    tokens1 = sentence1.split()\n",
        "    tokens2 = sentence2.split()\n",
        "\n",
        "    if len(tokens1) != len(tokens2):\n",
        "        raise ValueError(\"두 문장의 어절 수가 동일해야 합니다.\")\n",
        "\n",
        "    candidate_tokens = []\n",
        "    for t1, t2 in zip(tokens1, tokens2):\n",
        "        # 어절이 동일하면 한 가지 선택지만, 다르면 두 가지 선택지를 사용합니다.\n",
        "        candidate_tokens.append([t1] if t1 == t2 else [t1, t2])\n",
        "\n",
        "    # Cartesian product를 사용해 모든 조합의 문장을 생성합니다.\n",
        "    candidates = [\" \".join(tokens) for tokens in product(*candidate_tokens)]\n",
        "    return candidates\n",
        "\n",
        "data['candidate'] = data.apply(lambda row: generate_candidate_sentences(row['result1'], row['result2']), axis=1)\n",
        "data['len'] = data.apply(lambda x: len(x['candidate']) if len(x['candidate']) > 1 else 0, axis = 1)\n",
        "data['sent_len'] = data.apply(lambda x: len(x['result1'].split()), axis = 1)"
      ],
      "metadata": {
        "id": "aLSgWvFw5H2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## comparison"
      ],
      "metadata": {
        "id": "nwa8LVxn5H2X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def select_best_candidate(candidates: list, model, tokenizer, device: str, sentence1: str, sentence2: str) -> str:\n",
        "    \"\"\"\n",
        "    후보 문장 리스트에서, 후보 수에 따라 다음과 같이 선택.\n",
        "      - 후보가 1개이면: 바로 그 문장을 선택 (펄플렉시티 계산 없이)\n",
        "      - 후보가 200개 이상이면: 두 원본 문장(sentence1, sentence2)만 펄플렉시티를 계산하여 더 낮은 값을 가진 문장을 선택\n",
        "      - 그 외의 경우: 모든 후보 문장에 대해 펄플렉시티를 계산한 후, 가장 낮은 값을 가진 문장을 선택\n",
        "\n",
        "    Returns:\n",
        "        (best_candidate, best_ppl): 선택된 문장과 그 perplexity 값 (계산하지 않은 경우 None)\n",
        "    \"\"\"\n",
        "    if len(candidates) == 1:\n",
        "        # 후보가 단 1개이면, 바로 반환 (펄플렉시티 계산 없이)\n",
        "        best_candidate = candidates[0]\n",
        "        return best_candidate\n",
        "\n",
        "    elif len(candidates) >= 2000: # 할만해보여서 1024까지 허용\n",
        "        # 후보가 너무 많으면, 원본 두 문장끼리만 펄플렉시티를 계산.\n",
        "        ppl1 = calculate_perplexity(sentence1, model, tokenizer, device)\n",
        "        ppl2 = calculate_perplexity(sentence2, model, tokenizer, device)\n",
        "        best_candidate = sentence1 if ppl1 < ppl2 else sentence2\n",
        "        return best_candidate\n",
        "\n",
        "    else:\n",
        "        # 후보가 2000개 미만인 경우: 모든 후보에 대해 펄플렉시티를 계산.\n",
        "        best_candidate = None\n",
        "        best_ppl = float(\"inf\")\n",
        "        for candidate in candidates:\n",
        "            ppl = calculate_perplexity(candidate, model, tokenizer, device)\n",
        "            if ppl < best_ppl:\n",
        "                best_ppl = ppl\n",
        "                best_candidate = candidate\n",
        "        return best_candidate\n"
      ],
      "metadata": {
        "id": "J0rD4BxC5H2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()\n",
        "data['best_sentence'] = data.progress_apply(lambda x: select_best_candidate(x['candidate'],\n",
        "                                                                            model, tokenizer, device,\n",
        "                                                                            x['result1'],\n",
        "                                                                            x['result2']), axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "5dd39d86-d5de-40d1-a508-44950f8902ff",
        "id": "OjyAcB0p5H2X"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-b136ade24853>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m data['best_sentence'] = data.progress_apply(lambda x: select_best_candidate(x['candidate'],\n\u001b[1;32m      5\u001b[0m                                                                             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def clean_blank(text):\n",
        "    text = text.strip()  # 좌우 공백 제거\n",
        "    text = re.sub(r'\\s+', ' ', text)  # 연속된 공백을 하나로 변환\n",
        "    return text\n",
        "\n",
        "def restore_original_text(original_text, decoded_text):\n",
        "\n",
        "    restored_text = \"\"\n",
        "    decoded_idx = 0  # 해독된 텍스트에서 현재 참조 중인 문자 위치\n",
        "\n",
        "    # 한글, 영어, 숫자, 공백, 문장부호만 허용하는 정규식\n",
        "    valid_char_pattern = re.compile(r'[가-힣a-zA-Z0-9(),.!?\\'\\\"\\[\\]\\{\\}:]')\n",
        "\n",
        "\n",
        "    for char in original_text:\n",
        "        if valid_char_pattern.match(char):\n",
        "            # 유효한 문자일 경우, 해독된 문자로 대체\n",
        "            if decoded_idx < len(decoded_text):\n",
        "                restored_text += decoded_text[decoded_idx]\n",
        "                decoded_idx += 1\n",
        "            else:\n",
        "                # 만약 해독된 텍스트가 끝났다면 원문 문자 그대로 추가\n",
        "                restored_text += char\n",
        "        else:\n",
        "            # 특수문자 및 불완전한 한글은 원문 그대로 유지\n",
        "            restored_text += char\n",
        "\n",
        "    return restored_text\n",
        "\n",
        "def check_double_blanks(text):\n",
        "    return bool(re.search(r' {2,}', text))\n",
        "\n",
        "def check_repeated_last_char(text):\n",
        "    return bool(re.search(r'([가-힣])\\1+$', text))\n",
        "\n",
        "def remove_trailing_unks(text):\n",
        "\n",
        "    cleaned_text = re.sub(r'(<unk>\\s*)+$', '', text)\n",
        "    return cleaned_text\n",
        "\n",
        "def post_processing(data, data_chunked, result, test_flg = True):\n",
        "  temp = data.copy()\n",
        "  temp_chunked = data_chunked.copy()\n",
        "\n",
        "  # for i in range(len(result)):\n",
        "  #   result[i] = remove_trailing_unks(result[i])\n",
        "\n",
        "  temp_chunked['result'] = result\n",
        "  data_recovered = temp_chunked.groupby(\"index\").agg(list).reset_index(drop=True)\n",
        "  if test_flg:\n",
        "    data_recovered.columns = ['result1','result2', 'result']\n",
        "    data_recovered['result'] = data_recovered['result'].apply(lambda x: ' '.join(x))\n",
        "  else:\n",
        "    data_recovered.columns = ['input_DEC1','output','input_DEC2']\n",
        "    data_recovered['input_DEC2'] = data_recovered['input_DEC2'].apply(lambda x: ' '.join(x))\n",
        "\n",
        "  temp['input'] = temp.apply(lambda x: clean_blank(x['input']), axis = 1)\n",
        "\n",
        "  temp['result'] = data_recovered['result']\n",
        "  temp['result'] = temp.apply(lambda x: clean_blank(x['result']), axis = 1)\n",
        "  temp['result'] = temp.apply(lambda x: x['result'].replace(\" \",\"\"), axis= 1)\n",
        "\n",
        "  temp['result'] = temp.apply(lambda x: restore_original_text(x['input'],x['result']), axis = 1)\n",
        "\n",
        "  return temp"
      ],
      "metadata": {
        "id": "Q1zuZdqG5H2Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.read_csv(path+'/test.csv')\n",
        "sub = post_processing(test, data[['index','result1','result2']], data['best_sentence'])\n",
        "sub.drop('input', axis = 1, inplace = True)\n",
        "sub.columns = ['ID', 'output']\n",
        "sub.to_csv(path+'/result1 vs result2(submission).csv', index = False)"
      ],
      "metadata": {
        "id": "C-QuhlZ-5H2Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "e4328867-4db9-4e64-fdbf-b7c148aece9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'best_sentence'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'best_sentence'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-6fdbd1fabd78>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/test.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msub\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpost_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'index'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'result1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'result2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'best_sentence'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'input'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'ID'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'output'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/result1 vs result2(submission).csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'best_sentence'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 최종 제출\n",
        "아래 세 결과 중에 `kogemma_v1 vs kogemma_v2`로 결정\n",
        "- kogemma vs electra (result1)\n",
        "- kogemma_v1 vs kogemma_v2 (result2)\n",
        "- result1 vs result2"
      ],
      "metadata": {
        "id": "22WOiKyUG9Kd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ensemble2 = pd.read_csv(path+'/kogemma vs kogemma_v2(submission).csv')"
      ],
      "metadata": {
        "id": "7clexndpHc88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ensemble2.to_csv(path+'/final_submission.csv', index = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "4743f66b-d732-41f2-f1b0-41bd8d54f95f",
        "id": "6xhWmvYDHc88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          ID                                             output\n",
              "0  TEST_0000  너무너무 만족스러운 호텔이에요. 부산에 오면 꼭 추천하고 싶은 곳이에요. 최고입니다...\n",
              "1  TEST_0001  프론트가 없고, 조식도 없으며, 일반 입주민들이 사이사이에 있어 호텔처럼 관리가 잘...\n",
              "2  TEST_0002  진짜 불친절해요. 살면서 머물렀던 호텔 중에 최악이었습니다. 직원인지 사장인지 체크...\n",
              "3  TEST_0003  뷰 맛집~~ 그런데 방음이 미흡하네요. 층간 소음과 발코니가 이중창이 아니라서 밤에...\n",
              "4  TEST_0004  방 상태는 진짜 폐허 직전인데 전망은 좋아요. 보일러가 아주 잔잔하게 돌아서 추웠어..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d3fd0be3-b61e-4c4f-ae85-c2b5b06ffcec\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>TEST_0000</td>\n",
              "      <td>너무너무 만족스러운 호텔이에요. 부산에 오면 꼭 추천하고 싶은 곳이에요. 최고입니다...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>TEST_0001</td>\n",
              "      <td>프론트가 없고, 조식도 없으며, 일반 입주민들이 사이사이에 있어 호텔처럼 관리가 잘...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>TEST_0002</td>\n",
              "      <td>진짜 불친절해요. 살면서 머물렀던 호텔 중에 최악이었습니다. 직원인지 사장인지 체크...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>TEST_0003</td>\n",
              "      <td>뷰 맛집~~ 그런데 방음이 미흡하네요. 층간 소음과 발코니가 이중창이 아니라서 밤에...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TEST_0004</td>\n",
              "      <td>방 상태는 진짜 폐허 직전인데 전망은 좋아요. 보일러가 아주 잔잔하게 돌아서 추웠어...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d3fd0be3-b61e-4c4f-ae85-c2b5b06ffcec')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d3fd0be3-b61e-4c4f-ae85-c2b5b06ffcec button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d3fd0be3-b61e-4c4f-ae85-c2b5b06ffcec');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ecdf5f6a-0af4-49f6-b741-c9c6acee7165\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ecdf5f6a-0af4-49f6-b741-c9c6acee7165')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ecdf5f6a-0af4-49f6-b741-c9c6acee7165 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "ensemble2",
              "summary": "{\n  \"name\": \"ensemble2\",\n  \"rows\": 1689,\n  \"fields\": [\n    {\n      \"column\": \"ID\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1689,\n        \"samples\": [\n          \"TEST_0988\",\n          \"TEST_1634\",\n          \"TEST_0752\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"output\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1688,\n        \"samples\": [\n          \"\\uad00\\ub9ac\\ud558\\uc2dc\\ub294 \\ubd84\\ub4e4\\ub3c4 \\ucc29\\ud558\\uc2dc\\uace0 \\ubaa8\\ub4e0 \\uc2dc\\uc124\\uc774 \\uae68\\ub057\\ud574\\uc694~~ \\ub2e4\\uc74c\\uc5d0\\ub3c4 \\ub610 \\ub180\\ub7ec \\uc62c \\uac83 \\uac19\\uc544\\uc694\",\n          \"\\ubc29\\uc548\\uc5d0\\ub294 \\ucc3d\\ubb38\\uc774 \\uc5c6\\uc2b5\\ub2c8\\ub2e4. \\ud63c\\uc790 \\uc624\\uc168\\ub2e4\\uba74 2\\uc778\\uc2e4\\uc744 \\ucd94\\ucc9c\\ub4dc\\ub9bd\\ub2c8\\ub2e4. \\uacc4\\ub2e8\\ub9cc \\uc788\\uc2b5\\ub2c8\\ub2e4. \\uacf5\\uc6a9 \\uc2e4\\ub0b4\\ud654\\ub97c \\uc0ac\\uc6a9\\ud574\\uc57c \\ud569\\ub2c8\\ub2e4. 3\\uce35\\uc5d0\\uc11c \\uccb4\\ud06c\\uc778\\ud558\\uace0 4\\uce35\\uc5d0\\uc11c \\ubb35\\uc5c8\\uc5b4\\uc694. 2\\uce35\\uc740 \\ud638\\ud504\\uc9d1\\uc785\\ub2c8\\ub2e4. \\uc0dd\\uac01\\ubcf4\\ub2e4 \\uc2dc\\ub044\\ub7fd\\uc9c0 \\uc54a\\uace0 \\uc678\\uad6d\\uc778\\ub4e4\\uc774 \\ub9ce\\uc774 \\uc635\\ub2c8\\ub2e4. 5\\uc6d4\\uc778\\ub370 \\ubaa8\\uae30\\uac00 \\uc788\\uc2b5\\ub2c8\\ub2e4.\",\n          \"\\uc544\\uc8fc \\uc88b\\uc2b5\\ub2c8\\ub2e4. \\uc870\\uc2dd\\ub3c4 \\ub9ce\\uc558\\ub124\\uc694. \\uac00\\uc131\\ube44 \\ucd5c\\uace0^^\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    }
  ]
}