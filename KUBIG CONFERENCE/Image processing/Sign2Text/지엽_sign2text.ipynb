{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0837caa9-7d67-444a-acfa-d0e8d41b8df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import xmltodict\n",
    "from glob import glob\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0493c99d-d20f-4879-b212-5971526a4335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xml 파일의 키포인트, json 파일의 라벨을 합쳐 merged_keypoint 생성\n",
    "\n",
    "# 📁 경로 설정 (Lightning 기준)\n",
    "base_xml_root = 'training/keypoint/tact_keypoints/FIRE'\n",
    "base_json_root = 'training/keypoint/tact_morpheme/FIRE'\n",
    "save_dir = 'training/merged_keypoint'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# 상체 & 손 중심 keypoint 인덱스\n",
    "POSE_KEEP_IDX = [0, 1, 2, 3, 4, 5, 6, 7, 15, 16, 17, 18]\n",
    "\n",
    "# 2D pose keypoint 필터링\n",
    "def filter_pose_keypoints(points):\n",
    "    keypoints = [list(map(float, p.split(','))) for p in points]\n",
    "    return [coord for idx in POSE_KEEP_IDX if idx < len(keypoints) for coord in keypoints[idx][:2]]\n",
    "\n",
    "# hand keypoint 필터링\n",
    "def filter_hand_keypoints(points):\n",
    "    keypoints = [list(map(float, p.split(','))) for p in points]\n",
    "    return [coord for kpt in keypoints for coord in kpt[:2]]\n",
    "\n",
    "# 단일 샘플 병합 함수\n",
    "def merge_single_sample_from_path(xml_path, json_path):\n",
    "    try:\n",
    "        with open(xml_path, 'r', encoding='utf-8') as f:\n",
    "            xml_data = xmltodict.parse(f.read())\n",
    "    except Exception:\n",
    "        print(f\"[오류] XML 파싱 실패: {xml_path}\")\n",
    "        return False\n",
    "\n",
    "    frames_dict = {}\n",
    "    for track in xml_data[\"annotations\"][\"track\"]:\n",
    "        label = track[\"@label\"]\n",
    "        if label == \"face_keypoints_2d\":\n",
    "            continue\n",
    "        for key in track:\n",
    "            if key not in [\"@id\", \"@label\"]:\n",
    "                entries = track[key] if isinstance(track[key], list) else [track[key]]\n",
    "                for entry in entries:\n",
    "                    idx_f = int(entry[\"@frame\"])\n",
    "                    points = [p for p in entry[\"@points\"].split(';') if p.strip()]\n",
    "                    filtered_points = (\n",
    "                        filter_pose_keypoints(points) if label == \"pose_keypoints_2d\"\n",
    "                        else filter_hand_keypoints(points)\n",
    "                    )\n",
    "                    frames_dict.setdefault(idx_f, {})[label] = filtered_points\n",
    "\n",
    "    try:\n",
    "        with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            js = json.load(f)\n",
    "        korean_text = js.get(\"korean_text\", \"\")\n",
    "        signer_id = js.get(\"translator\", {}).get(\"id\", None)\n",
    "    except Exception:\n",
    "        print(f\"[오류] JSON 파싱 실패: {json_path}\")\n",
    "        return False\n",
    "\n",
    "    base = os.path.splitext(os.path.basename(xml_path))[0]\n",
    "    result = {\n",
    "        \"index\": base,\n",
    "        \"id\": signer_id,\n",
    "        \"korean_text\": korean_text,\n",
    "        \"frames\": []\n",
    "    }\n",
    "\n",
    "    prev_frame_vec = None\n",
    "    for idx_f in sorted(frames_dict):\n",
    "        frame_info = frames_dict[idx_f]\n",
    "        frame_vec = frame_info.get(\"pose_keypoints_2d\", []) + \\\n",
    "                    frame_info.get(\"hand_left_keypoints_2d\", []) + \\\n",
    "                    frame_info.get(\"hand_right_keypoints_2d\", [])\n",
    "        if prev_frame_vec is not None and frame_vec == prev_frame_vec:\n",
    "            continue\n",
    "        prev_frame_vec = frame_vec\n",
    "        result[\"frames\"].append({\n",
    "            \"frame_idx\": idx_f,\n",
    "            \"pose\": frame_info.get(\"pose_keypoints_2d\", []),\n",
    "            \"hand_left\": frame_info.get(\"hand_left_keypoints_2d\", []),\n",
    "            \"hand_right\": frame_info.get(\"hand_right_keypoints_2d\", [])\n",
    "        })\n",
    "\n",
    "    save_path = os.path.join(save_dir, f\"{base}.json\")\n",
    "    with open(save_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(result, f, ensure_ascii=False, indent=2)\n",
    "    return True\n",
    "\n",
    "# 전체 xml/json 병합\n",
    "xml_paths = glob(os.path.join(base_xml_root, \"**\", \"*.xml\"), recursive=True)\n",
    "\n",
    "success, fail = 0, 0\n",
    "for xml_path in tqdm(xml_paths, desc=\"병합 진행 중\"):\n",
    "    base_name = os.path.basename(xml_path)\n",
    "    json_name = base_name.replace(\"_F.xml\", \".json\")\n",
    "    relative_dir = os.path.relpath(os.path.dirname(xml_path), base_xml_root)\n",
    "    json_path = os.path.join(base_json_root, relative_dir, json_name)\n",
    "\n",
    "    if os.path.exists(json_path):\n",
    "        ok = merge_single_sample_from_path(xml_path, json_path)\n",
    "        success += int(ok)\n",
    "        fail += int(not ok)\n",
    "    else:\n",
    "        print(f\"❗ 대응 JSON 없음: {json_path}\")\n",
    "        fail += 1\n",
    "\n",
    "print(f\"\\n✅ 병합 완료: {success}개, 실패: {fail}개\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e301f90-2d67-4d98-ad8f-5903c52129cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xml, json 간 mapping 확인\n",
    "\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "# XML / JSON 경로\n",
    "xml_root = 'training/keypoint/tact_keypoints/FIRE'\n",
    "json_root = 'training/keypoint/tact_morpheme/FIRE'\n",
    "\n",
    "# 추출 함수\n",
    "def extract_key_from_filename(path, suffix_to_strip):\n",
    "    base = os.path.basename(path)\n",
    "    key = base.replace(suffix_to_strip, '')  # 예: '_F.xml' 또는 '.json'\n",
    "    return key\n",
    "\n",
    "# 목록 수집\n",
    "xml_paths = glob(os.path.join(xml_root, \"**\", \"*.xml\"), recursive=True)\n",
    "json_paths = glob(os.path.join(json_root, \"**\", \"*.json\"), recursive=True)\n",
    "\n",
    "xml_keys = set(extract_key_from_filename(p, '_F.xml') for p in xml_paths)\n",
    "json_keys = set(extract_key_from_filename(p, '.json') for p in json_paths)\n",
    "\n",
    "# 교집합, 차집합 확인\n",
    "only_in_xml = sorted(xml_keys - json_keys)\n",
    "only_in_json = sorted(json_keys - xml_keys)\n",
    "matched = sorted(xml_keys & json_keys)\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"📊 총 XML 파일: {len(xml_keys)}\")\n",
    "print(f\"📊 총 JSON 파일: {len(json_keys)}\")\n",
    "print(f\"✅ 매칭된 파일 수: {len(matched)}\")\n",
    "print(f\"❗ XML만 있고 JSON 없는 파일 수: {len(only_in_xml)}\")\n",
    "print(f\"❗ JSON만 있고 XML 없는 파일 수: {len(only_in_json)}\")\n",
    "\n",
    "# 샘플 출력\n",
    "if only_in_xml:\n",
    "    print(\"\\n📁 XML만 있는 파일 예시:\", only_in_xml[:5])\n",
    "if only_in_json:\n",
    "    print(\"\\n📁 JSON만 있는 파일 예시:\", only_in_json[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73c9ef9e-ae2c-4093-98a2-7c367cf84aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-level keys: ['index', 'id', 'korean_text', 'frames', 'masked_korean_text', 'slot_values']\n",
      "Sample index: NIA_SL_G2_FIRE000003_1_TW03_F\n",
      "Signer ID: None\n",
      "Korean text: 안전안내. 오늘 02:00 반월공단 내 화재 발생, 연기확산에 주의하세요\n",
      "Total frames: 415\n",
      "First frame example:\n",
      " {'frame_idx': 0, 'pose': [-0.5705703748867382, -1.293855761361989, -0.9978378664332288, 0.38877772926518217, -1.333126966363792, 0.4141644645741816, -0.19592469723364872, 1.0743982394172575, -0.6269272316283744, 1.9253424647875002, 0.09971286732763626, 0.22130937010234883, -0.8861206474747211, 0.9415592908037219, 0.06099393017401008, 1.0303200784063804, -0.4102040536331944, -1.2634992735993633, -0.4574661803063296, -1.1997975506862708, -0.3532081551955483, -0.9235349309592826, -0.25358581902873323, -1.2418483940684855], 'hand_left': [0.2562509398573034, 0.3781380067836563, 0.23828920569760192, 0.40224842894696955, 0.22913406363610123, 0.44531825872919373, 0.2135864074856869, 0.44406526391357304, 0.19717924048813995, 0.44449387108595795, 0.24385194006458566, 0.4596639511103904, 0.22975386654987107, 0.4600255993604093, 0.21231373800168685, 0.4582818651957242, 0.19865914827591602, 0.4560792817378445, 0.25383824536837674, 0.45897034771122835, 0.23038244194588509, 0.45953865213113276, 0.21477481874862436, 0.45976629160559046, 0.201800457440641, 0.4592198245556409, 0.2586831669577556, 0.45316991902811665, 0.2371309259259502, 0.45892582865818843, 0.22050660981460501, 0.45854368931108214, 0.2099147517841472, 0.45748645471091476, 0.2642908083443215, 0.4450552791221709, 0.24543862012703532, 0.45543876826205765, 0.23247872368318667, 0.4486923302875042, 0.22184827967642695, 0.44704570252366216], 'hand_right': [0.14375497084605948, 0.44750585655239195, 0.1555338799840088, 0.44579148453283735, 0.16317196174918336, 0.44285070744575983, 0.1574357692015892, 0.4413579328379571, 0.15384940875471154, 0.4403444392577244, 0.12699279995173895, 0.4411215880799888, 0.1177980432372735, 0.4426679462481511, 0.11278776176583405, 0.43969133881136513, 0.10776411623746829, 0.43337171082307324, 0.10889238941956325, 0.4420328662150086, 0.10299058379960091, 0.4464366163340865, 0.09843604211579782, 0.44211075689581525, 0.09610042072438185, 0.4390355870492948, 0.09771126760101845, 0.4448349328885265, 0.0935771995821214, 0.445990715941349, 0.09085309744582182, 0.43857860351819633, 0.09153391854425363, 0.4363044982612567, 0.09025260993756046, 0.44391056088495195, 0.0843549945601495, 0.44432322916558564, 0.08490383109037491, 0.43974216321087634, 0.08418686905471828, 0.4366570304636118]}\n",
      "\n",
      " Frame 1 pose keypoints vector length: 24 (expected 24)\n"
     ]
    }
   ],
   "source": [
    "# Merged_keypoint 파일 확인\n",
    "\n",
    "# 실제 병합된 JSON 경로로 수정\n",
    "sample_path = 'training/train/norm_keypoint/NIA_SL_G2_FIRE000003_1_TW03_F_norm.json'\n",
    "\n",
    "# JSON 파일 열기\n",
    "with open(sample_path, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# 병합된 구조 정보 출력\n",
    "print(\"Top-level keys:\", list(data.keys()))\n",
    "print(\"Sample index:\", data['index'])\n",
    "print(\"Signer ID:\", data.get('id'))\n",
    "print(\"Korean text:\", data['korean_text'])\n",
    "print(\"Total frames:\", len(data['frames']))\n",
    "print(\"First frame example:\\n\", data['frames'][0])\n",
    "\n",
    "# 키포인트 확인 (예: pose = 12 keypoints × (x, y) = 24차원)\n",
    "pose_len = len(data['frames'][1]['pose'])\n",
    "print(f\"\\n Frame 1 pose keypoints vector length: {pose_len} (expected 24)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef02c6ab-dcba-4f32-93b2-9a6ff878a748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 문장 ID 수: 1828\n"
     ]
    }
   ],
   "source": [
    "# 문장 수 세기\n",
    "\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "DATA_DIR = \"/teamspace/studios/this_studio/training/merged_keypoint\"\n",
    "file_list = [f for f in os.listdir(DATA_DIR) if f.endswith(\".json\")]\n",
    "\n",
    "sentence_to_files = defaultdict(list)\n",
    "\n",
    "for fname in file_list:\n",
    "    # 예: NIA_SL_G2_FIRE000004_1_KU02_F.json\n",
    "    parts = fname.split(\"_\")\n",
    "    if len(parts) >= 4:\n",
    "        sentence_id = parts[3]  # FIRE000004\n",
    "        sentence_to_files[sentence_id].append(fname)\n",
    "\n",
    "print(\"총 문장 ID 수:\", len(sentence_to_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c44521d-9099-4fe8-a93d-24a6fe75435d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 100%|██████████| 1828/1828 [00:20<00:00, 90.94it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 분리 완료! 총 문장 수: 1828 / Validation 문장 수: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Train, val split\n",
    "\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 경로 설정\n",
    "SOURCE_DIR = \"/teamspace/studios/this_studio/training/merged_keypoint\"\n",
    "TRAIN_DIR = \"/teamspace/studios/this_studio/training/train/merged_keypoint\"\n",
    "VAL_DIR = \"/teamspace/studios/this_studio/training/val/merged_keypoint\"\n",
    "\n",
    "os.makedirs(TRAIN_DIR, exist_ok=True)\n",
    "os.makedirs(VAL_DIR, exist_ok=True)\n",
    "\n",
    "# 모든 json 파일 수집\n",
    "all_files = [f for f in os.listdir(SOURCE_DIR) if f.endswith(\".json\")]\n",
    "\n",
    "# 문장 ID 추출 (예: NIA_SL_G2_FIRE000004_1_KU02_F.json → FIRE000004)\n",
    "sentence_to_files = dict()\n",
    "for fname in all_files:\n",
    "    parts = fname.split(\"_\")\n",
    "    if len(parts) >= 4:\n",
    "        sentence_id = parts[3]  # 올바른 문장 ID\n",
    "        sentence_to_files.setdefault(sentence_id, []).append(fname)\n",
    "\n",
    "# 문장 ID 중에서 200개 랜덤 선택 (검증용)\n",
    "all_sentence_ids = list(sentence_to_files.keys())\n",
    "val_sentence_ids = set(random.sample(all_sentence_ids, 200))\n",
    "\n",
    "# 파일 분배\n",
    "for sid, fnames in tqdm(sentence_to_files.items(), desc=\"Copying files\"):\n",
    "    target_dir = VAL_DIR if sid in val_sentence_ids else TRAIN_DIR\n",
    "    for fname in fnames:\n",
    "        src = os.path.join(SOURCE_DIR, fname)\n",
    "        dst = os.path.join(target_dir, fname)\n",
    "        shutil.copy2(src, dst)\n",
    "\n",
    "print(f\"✅ 분리 완료! 총 문장 수: {len(all_sentence_ids)} / Validation 문장 수: {len(val_sentence_ids)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2eb3b0b6-8270-4258-ae70-ab547b8cf974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Train JSON 파일 수: 3183\n",
      "📂 Validation JSON 파일 수: 408\n"
     ]
    }
   ],
   "source": [
    "# Train, Val 파일 수 확인\n",
    "\n",
    "import os\n",
    "\n",
    "TRAIN_DIR = \"/teamspace/studios/this_studio/training/train/merged_keypoint\"\n",
    "VAL_DIR = \"/teamspace/studios/this_studio/training/val/merged_keypoint\"\n",
    "\n",
    "num_train = len([f for f in os.listdir(TRAIN_DIR) if f.endswith(\".json\")])\n",
    "num_val = len([f for f in os.listdir(VAL_DIR) if f.endswith(\".json\")])\n",
    "\n",
    "print(f\"📂 Train JSON 파일 수: {num_train}\")\n",
    "print(f\"📂 Validation JSON 파일 수: {num_val}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d32dc50d-5170-4c89-ba70-787b61cd698b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Collecting train keypoints: 100%|██████████| 3183/3183 [00:41<00:00, 77.32it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Train 기반 정규화 통계 저장 완료 → /teamspace/studios/this_studio/training/norm_stat.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🌀 Normalizing → /teamspace/studios/this_studio/training/train/norm_keypoint: 100%|██████████| 3183/3183 [14:25<00:00,  3.68it/s]\n",
      "🌀 Normalizing → /teamspace/studios/this_studio/training/val/norm_keypoint: 100%|██████████| 408/408 [01:52<00:00,  3.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Train & Validation 정규화 완료!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Train, Val 각각 normalization 적용 \n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 경로 설정\n",
    "TRAIN_SRC = \"/teamspace/studios/this_studio/training/train/merged_keypoint\"\n",
    "VAL_SRC = \"/teamspace/studios/this_studio/training/val/merged_keypoint\"\n",
    "TRAIN_DST = \"/teamspace/studios/this_studio/training/train/norm_keypoint\"\n",
    "VAL_DST = \"/teamspace/studios/this_studio/training/val/norm_keypoint\"\n",
    "STAT_PATH = \"/teamspace/studios/this_studio/training/norm_stat.npz\"\n",
    "\n",
    "# 디렉토리 생성\n",
    "os.makedirs(TRAIN_DST, exist_ok=True)\n",
    "os.makedirs(VAL_DST, exist_ok=True)\n",
    "\n",
    "### 1. 통계 계산용 데이터 수집 (Train 기준)\n",
    "pose_all, left_all, right_all = [], [], []\n",
    "\n",
    "train_files = sorted(glob(os.path.join(TRAIN_SRC, \"*.json\")))\n",
    "for file in tqdm(train_files, desc=\"🔍 Collecting train keypoints\"):\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    for frame in data['frames']:\n",
    "        if frame.get('pose'): pose_all.append(frame['pose'])\n",
    "        if frame.get('hand_left'): left_all.append(frame['hand_left'])\n",
    "        if frame.get('hand_right'): right_all.append(frame['hand_right'])\n",
    "\n",
    "pose_all = np.array(pose_all)\n",
    "left_all = np.array(left_all)\n",
    "right_all = np.array(right_all)\n",
    "\n",
    "# 통계 계산 및 저장\n",
    "pose_mu = pose_all.mean(axis=0)\n",
    "pose_sd = pose_all.std(axis=0)\n",
    "left_min = left_all.min(axis=0)\n",
    "left_max = left_all.max(axis=0)\n",
    "right_min = right_all.min(axis=0)\n",
    "right_max = right_all.max(axis=0)\n",
    "\n",
    "np.savez(STAT_PATH, pose_mu=pose_mu, pose_sd=pose_sd,\n",
    "         left_min=left_min, left_max=left_max,\n",
    "         right_min=right_min, right_max=right_max)\n",
    "print(f\"📊 Train 기반 정규화 통계 저장 완료 → {STAT_PATH}\")\n",
    "\n",
    "### 2. 정규화 함수 정의\n",
    "def normalize_pose(x, mu, sd):\n",
    "    return (np.array(x) - mu) / (sd + 1e-8)\n",
    "\n",
    "def normalize_hand(x, minv, maxv):\n",
    "    return (np.array(x) - minv) / (maxv - minv + 1e-8) - 0.5\n",
    "\n",
    "### 3. 정규화 적용 함수\n",
    "def apply_normalization_and_save(src_files, dst_dir, stats):\n",
    "    for file in tqdm(src_files, desc=f\"🌀 Normalizing → {dst_dir}\"):\n",
    "        with open(file, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        for frame in data['frames']:\n",
    "            if frame.get('pose'):\n",
    "                frame['pose'] = list(normalize_pose(frame['pose'], stats['pose_mu'], stats['pose_sd']))\n",
    "            if frame.get('hand_left'):\n",
    "                frame['hand_left'] = list(normalize_hand(frame['hand_left'], stats['left_min'], stats['left_max']))\n",
    "            if frame.get('hand_right'):\n",
    "                frame['hand_right'] = list(normalize_hand(frame['hand_right'], stats['right_min'], stats['right_max']))\n",
    "        fname = os.path.basename(file).replace('.json', '_norm.json')\n",
    "        with open(os.path.join(dst_dir, fname), 'w', encoding='utf-8') as f:\n",
    "            json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "### 4. 정규화 실행\n",
    "stats = np.load(STAT_PATH)\n",
    "\n",
    "# Train 정규화\n",
    "apply_normalization_and_save(train_files, TRAIN_DST, stats)\n",
    "\n",
    "# Val 정규화 (stat은 train 기준)\n",
    "val_files = sorted(glob(os.path.join(VAL_SRC, \"*.json\")))\n",
    "apply_normalization_and_save(val_files, VAL_DST, stats)\n",
    "\n",
    "print(\"✅ Train & Validation 정규화 완료!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a240592-5724-4301-9fc9-9ba5ccbdeed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Checking normalized data: 100%|██████████| 3183/3183 [01:35<00:00, 33.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Normalized Pose:\n",
      "  mean: [ 0.  0.  0. -0.  0.]\n",
      "  std:  [1. 1. 1. 1. 1.]\n",
      "\n",
      "✅ Normalized Hand Left:\n",
      "  min: [-0.5 -0.5 -0.5 -0.5 -0.5]\n",
      "  max: [0.5 0.5 0.5 0.5 0.5]\n",
      "\n",
      "✅ Normalized Hand Right:\n",
      "  min: [-0.5 -0.5 -0.5 -0.5 -0.5]\n",
      "  max: [0.5 0.5 0.5 0.5 0.5]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 정규화된 데이터 경로\n",
    "NORM_TRAIN_DIR = \"/teamspace/studios/this_studio/training/train/norm_keypoint\"\n",
    "\n",
    "# 누적 저장\n",
    "pose_all, left_all, right_all = [], [], []\n",
    "\n",
    "# 모든 정규화된 train json 읽기\n",
    "norm_files = sorted(glob(os.path.join(NORM_TRAIN_DIR, \"*.json\")))\n",
    "for file in tqdm(norm_files, desc=\"🔍 Checking normalized data\"):\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    for frame in data['frames']:\n",
    "        if frame.get('pose'): pose_all.append(frame['pose'])\n",
    "        if frame.get('hand_left'): left_all.append(frame['hand_left'])\n",
    "        if frame.get('hand_right'): right_all.append(frame['hand_right'])\n",
    "\n",
    "# numpy 변환\n",
    "pose_all = np.array(pose_all)\n",
    "left_all = np.array(left_all)\n",
    "right_all = np.array(right_all)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"✅ Normalized Pose:\")\n",
    "print(\"  mean:\", np.round(pose_all.mean(axis=0)[:5], 4))\n",
    "print(\"  std: \", np.round(pose_all.std(axis=0)[:5], 4))\n",
    "\n",
    "print(\"\\n✅ Normalized Hand Left:\")\n",
    "print(\"  min:\", np.round(left_all.min(axis=0)[:5], 4))\n",
    "print(\"  max:\", np.round(left_all.max(axis=0)[:5], 4))\n",
    "\n",
    "print(\"\\n✅ Normalized Hand Right:\")\n",
    "print(\"  min:\", np.round(right_all.min(axis=0)[:5], 4))\n",
    "print(\"  max:\", np.round(right_all.max(axis=0)[:5], 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17e658fc-a702-45a5-ae0f-44297d653e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔁 Skip Sampling Augmentation (train only): 100%|██████████| 3183/3183 [1:05:35<00:00,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ 모든 train 파일에서 augmentation 결과를 '/teamspace/studios/this_studio/training/train/augmented_keypoint'에 저장했습니다.\n",
      "🔍 중복된 frame이 포함된 augmentation 수: 288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Data Augmentation via Skip Sampling 적용 (중복된 frame 출력)\n",
    "\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import copy\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 설정\n",
    "NORM_DIR = \"/teamspace/studios/this_studio/training/train/norm_keypoint\"\n",
    "AUG_DIR = \"/teamspace/studios/this_studio/training/train/augmented_keypoint\"\n",
    "os.makedirs(AUG_DIR, exist_ok=True)\n",
    "\n",
    "AUG_FACTOR = 50\n",
    "N_FRAMES_SAMPLED = 50\n",
    "\n",
    "file_list = sorted(glob(os.path.join(NORM_DIR, \"*_norm.json\")))\n",
    "\n",
    "# 중복이 발생한 augmentation 수\n",
    "duplicate_aug_count = 0\n",
    "\n",
    "def safe_sampling_indices(l, n):\n",
    "    z = int(np.floor(l / (n - 1)))\n",
    "    y = int(np.floor((l - z * (n - 1)) / 2))\n",
    "    baseline_idx = [y + z * k for k in range(n)]\n",
    "\n",
    "    # soft clipping\n",
    "    if baseline_idx[-1] >= l:\n",
    "        baseline_idx[-1] = l - 1\n",
    "\n",
    "    return baseline_idx, z\n",
    "\n",
    "for src_path in tqdm(file_list, desc=\"🔁 Skip Sampling Augmentation (train only)\"):\n",
    "    basename = os.path.basename(src_path)\n",
    "    file_idx = basename.replace('_norm.json', '')\n",
    "\n",
    "    with open(src_path, 'r', encoding='utf-8') as f:\n",
    "        src_data = json.load(f)\n",
    "\n",
    "    frames = src_data['frames']\n",
    "    l = len(frames)\n",
    "    n = N_FRAMES_SAMPLED\n",
    "\n",
    "    if l < n:\n",
    "        # 길이 부족 시 패딩\n",
    "        indices = list(range(l)) + [l - 1] * (n - l)\n",
    "        sampled_frames = [frames[i] for i in indices]\n",
    "        new_data = copy.deepcopy(src_data)\n",
    "        new_data['frames'] = sampled_frames\n",
    "        for i, frame in enumerate(new_data['frames']):\n",
    "            frame['frame_idx'] = i\n",
    "        save_path = os.path.join(AUG_DIR, f\"augmented_{file_idx}_1.json\")\n",
    "        with open(save_path, 'w', encoding='utf-8') as wf:\n",
    "            json.dump(new_data, wf, ensure_ascii=False, indent=2)\n",
    "    else:\n",
    "        baseline_idx, z = safe_sampling_indices(l, n)\n",
    "\n",
    "        if z == 1:\n",
    "            indices = [min(l - 1, max(0, idx)) for idx in baseline_idx]\n",
    "            sampled_frames = [frames[i] for i in indices]\n",
    "            new_data = copy.deepcopy(src_data)\n",
    "            new_data['frames'] = sampled_frames\n",
    "            for i, frame in enumerate(new_data['frames']):\n",
    "                frame['frame_idx'] = i\n",
    "            save_path = os.path.join(AUG_DIR, f\"augmented_{file_idx}_1.json\")\n",
    "            with open(save_path, 'w', encoding='utf-8') as wf:\n",
    "                json.dump(new_data, wf, ensure_ascii=False, indent=2)\n",
    "        else:\n",
    "            for aug_idx in range(1, AUG_FACTOR + 1):\n",
    "                indices = []\n",
    "                for k in range(n):\n",
    "                    base = baseline_idx[k]\n",
    "                    if base >= l - 1:\n",
    "                        noise = 0\n",
    "                    else:\n",
    "                        noise_max = max(1, l - 1 - base) if k == n - 1 else max(1, z)\n",
    "                        noise = random.randint(0, noise_max - 1)\n",
    "                    idx = min(base + noise, l - 1)\n",
    "                    indices.append(idx)\n",
    "\n",
    "                # ✅ 중복 여부 확인\n",
    "                if len(set(indices)) < len(indices):\n",
    "                    duplicate_aug_count += 1\n",
    "\n",
    "                sampled_frames = [frames[i] for i in indices]\n",
    "                new_data = copy.deepcopy(src_data)\n",
    "                new_data['frames'] = sampled_frames\n",
    "                for i, frame in enumerate(new_data['frames']):\n",
    "                    frame['frame_idx'] = i\n",
    "                save_path = os.path.join(AUG_DIR, f\"augmented_{file_idx}_{aug_idx}.json\")\n",
    "                with open(save_path, 'w', encoding='utf-8') as wf:\n",
    "                    json.dump(new_data, wf, ensure_ascii=False, indent=2)\n",
    "\n",
    "# 🔚 최종 결과 출력\n",
    "print(f\"\\n✅ 모든 train 파일에서 augmentation 결과를 '{AUG_DIR}'에 저장했습니다.\")\n",
    "print(f\"🔍 중복된 frame이 포함된 augmentation 수: {duplicate_aug_count:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66528bf6-32dc-465d-adb7-14f4b1c9ad28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📚 Korean Text Samples (max 50):\n",
      "\n",
      "01. 화재관련, 중구 북성동에서 화재가 발생하여 진압중이니 인근 주민들께서는 안전에 유의하시기 바랍니다.\n",
      "02. 7.8 07:37 구포동 516번지 일원 단독주택 화재 발생으로 일대가 혼잡하오니 주민들께서는 외출을 자제하시기 바랍니다.\n",
      "03. 금일 09:30 고양시 일산서구 덕이동 177-19번지 인근에 화재 발생. 이 지역을 우회하여 주시고 인근 주민은 안전사고 발생에 유의 바랍니다.\n",
      "04. 오늘 09:17 대전시 동구 상소동 628-22번지 인근 단독주택 화재 발생. 인근 주민은 안전한 곳으로 대피하고 차량은 우회 바랍니다.\n",
      "05. 오늘 09:00 우장산 스포츠센터 화재 발생. 인근 주민은 안전한 곳으로 대피하여 주시기 바랍니다.\n",
      "06. 오늘 09:30 남원시 사매2터널 인근 전주폐차장에서 화재 발생, 인근주민께서는 화재 등 안전에 유의하시기 바랍니다.\n",
      "07. 오늘 12:40 오포읍 문형리 908-36번지 대형화재 발생. 이 지역을 우회하여 주시고 인근 주민은 안전사고 발생에 유의 바랍니다.\n",
      "08. 동점→석포 행 도로 탱크로리 화재 사고. 탱크로리 화재로 인하여 전면통제 하오니 우회하시기 바랍니다.\n",
      "09. 오늘 14:50 남구 대명동 995-96번지 인근에 화재가 발생하였으니, 인근 주민은 안전사고에 주의하시기 바랍니다\n",
      "10. 오늘 오후 7시부터 광명시 노온사동 비닐하우스에서 화재 발생, 인근 주민은 안전한 곳으로 대피 바랍니다.\n",
      "11. 금일 09:02 광명시 노온사동 신대호수사거리 고가도로 화재 발생, 인근 주민은 안전한 곳으로 대피하시기 바랍니다.\n",
      "12. 오늘 07:50 상동면 우계리 479-88 송유관공사 화재 발생으로 인근 주민은 안전사고에 유의하시기 바랍니다.\n",
      "13. 04시 15분경 오포읍 문형리 312-79번지 오피스텔 화재 발생. 인근 주민은 안전한 곳으로 대피하시기 바랍니다.\n",
      "14. 오늘 16:20 석남동 840-21 화재 발생. 주변으로 확산될 우려가 있으니 인근 주민은 대피 바랍니다.\n",
      "15. 안전안내.오늘 09:34 서울 역촌면 롯데리아 화재 발생, 인근 주민은 안전에 유의하세요!\n",
      "16. 금일 11:30 고잔동 화재 발생. 인근 주민은 외출을 자제하는 등 안전사고 발생에 유의 바랍니다.\n",
      "17. 오늘 03시 서울 광진구 광장에서 화재가 발생하였으니, 인근 주민은 안전사고 발생에 유의하시기 바랍니다.\n",
      "18. 오늘 09:43 광명동 513-28 백두한양아파트 화재 발생, 인근 주민은 안전한 곳으로 대피바랍니다.\n",
      "19. 금일 15시 10분경 반여농산물시장 화재로 인해 양동 태평교 주변 교통이 정체되오니 우회하여 주시기 바랍니다.\n",
      "20. 오늘 08:32 해운대 우동 12-1 건물 화재발생. 인근 주민은 안전한 곳으로 대피하여 주시기 바랍니다.\n",
      "21. 오늘 16시 10분경 석남동 920-23 인근에서 화재 발생, 인근 주민은 창문을 닫아주시기 바랍니다.\n",
      "22. 오늘 12:30 현재 사천면 공장 화재 발생. 인근 주민은 안전사고 발생에 유의 바랍니다.\n",
      "23. 주천면 신월리 인근 도로 탱크로리 화재 사고발생으로 인근 도로가 혼잡하오니 우회하여 주시기 바랍니다.\n",
      "24. 오늘 09:20 고양시 일산서구 덕이동 809-65번지 일산도원창 폐차장에서 화재 발생으로 일대가 혼잡하오니 우회 바랍니다.\n",
      "25. 오늘 09:00 운보산업 공장 화재 발생. 이 지역을 우회하여 주시고 인근 주민은 안전사고 발생에 유의 바랍니다.\n",
      "26. 오늘 09:00 달동 삼환아르누보 아파트 화재로 인한 아파트단지 내 도로통제 중이오니, 우회하여 주시기 바랍니다.\n",
      "27. 8월 31일 6시 2분 의왕시 고천동 614-18번지 화재발생, 인근 주민은 안전한 곳으로 대피하시기 바랍니다.\n",
      "28. 오늘 09:30 관저동 925-80번지 근생건물 화재 발생, 인근 주민은 안전에 주의하시기 바랍니다.\n",
      "29. 금일 14:10 사하구 동아공고 체육관 공사장 화재발생으로 인근 도로가 혼잡하오니 우회하여 주시기 바랍니다.\n",
      "30. 오늘 09:00 관저동 740-46 건물화재 발생, 인근 주민은 안전에 유의하기 바랍니다.\n",
      "31. 금일 10:30 음식물자원시설 화재 발생으로 다량의 연기 발생, 인근 주민은 안전에 주의하시기 바랍니다.\n",
      "32. 오늘 09:39 의왕시 고천동 675-24 화재 발생. 인근 주민은 안전사고 발생에 주의 바랍니다.\n",
      "33. 오늘 08:26 광명동 937-30 광명종합화력발전소 화재 발생, 인근 주민은 안전에 유의바랍니다.\n",
      "34. 오늘 09:48 서구 비산동 926-40 화재 발생. 인근 주민은 안전사고 발생에 유의하시기 바랍니다.\n",
      "35. 10.26 12:33 광진구 염포부두에 정박중인 선박 화재로 차량통행을 전면통제하오니 우회하시기 바랍니다.\n",
      "36. 오늘 08:40 광명시 노온사동 비닐하우스 화재 발생. 인근 주민은 안전한 곳으로 대피하시기 바랍니다.\n",
      "37. 오늘 08:00 서구 비산동 971-78번지 화재 발생, 인근 주민은 안전에 주의하세요\n",
      "38. 오늘 02시40분 구포동 516-98번지 단독주택 화재 발생, 인근 주민은 안전에 주의 바랍니다.\n",
      "39. 오늘 09:50 상동면 소재 고잔동 902-83번지 화재 발생. 이 지역을 우회하여 주시고 인근 주민은 안전사고 발생에 유의 바랍니다.\n",
      "40. 오늘 11시 40분경 서울 영등포구 도림동에 화재 발생. 인근 주민은 창문을 닫고 차량은 우회하기 바랍니다.\n",
      "41. 오늘 09:10 감전동 광일케미스틸 뒤 화재 발생, 인근 주민은 안전사고 발생에 유의하시기 바랍니다.\n",
      "42. 오늘 04:22 서구 비산동 672-64번지 인근에서 발생한 화재로 인근 도로가 혼잡하오니 우회하여 주시기 바랍니다.\n",
      "43. 오늘 00:00 고잔동 897-83 송유관공사 화재 발생. 인근 주민은 안전한 곳으로 대피하시기 바랍니다.\n",
      "44. 오늘 15:00 달동 달동지 화재 발생. 달동기 주변 지역주민들께서는 안전에 유의하시기 바랍니다.\n",
      "45. 금일 09:30 오포읍 문형리 백두한양 아파트 화재 발생. 인근 주민은 안전한 곳으로 대피하시기 바랍니다.\n",
      "46. 오늘 08:53 월산면 월산리 719-40 백두한양아파트 화재발생, 인근 주민은 안전사고 발생에 유의 바랍니다.\n",
      "47. 7.26 18:00 광명시 노온사동 비닐하우스 화재 발생, 인근 주민들은 안전에 주의하시기 바랍니다.\n",
      "48. 오늘 09:00 발생한 용암동 부영3차 화재 진압으로 인근 도로가 혼잡하오니 우회하여 주시기 바랍니다.\n",
      "49. 오늘 09:00 중구 신당동 동대문역사문화공원 인근에서 대형화재 발생. 인근 주민은 안전에 주의 바랍니다.\n",
      "50. 05시 40분부터 광명동 593-412번지 화재 발생, 인근 주민들은 안전에 유의하시기 바랍니다.\n"
     ]
    }
   ],
   "source": [
    "# 50개의 프레임은 너무 작은 거 아닐까? - 100 프레임으로 늘리는 것 고려\n",
    "# 학습 자체가 어려울 수 있음 (고유명사가 너무 많고 데이터가 부족)\n",
    "\n",
    "import os\n",
    "import json\n",
    "from glob import glob\n",
    "import random\n",
    "\n",
    "# 🔧 경로 설정: train 기준\n",
    "MERGED_DIR = \"/teamspace/studios/this_studio/training/train/merged_keypoint\"  # 또는 norm_keypoint\n",
    "file_list = sorted(glob(os.path.join(MERGED_DIR, \"*.json\")))\n",
    "\n",
    "# 🔀 무작위 50개 샘플 추출\n",
    "sample_files = random.sample(file_list, 50)\n",
    "\n",
    "# 🔍 korean_text 추출\n",
    "texts = []\n",
    "for path in sample_files:\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "        text = data.get(\"korean_text\", \"\").strip()\n",
    "        if text:  # 빈 문장 제외\n",
    "            texts.append(text)\n",
    "\n",
    "# 📤 출력\n",
    "print(\"📚 Korean Text Samples (max 50):\\n\")\n",
    "for i, t in enumerate(texts, 1):\n",
    "    print(f\"{i:02d}. {t}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ba00785-ce30-4650-ad6b-6bf1b7ef5d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "END_PATTERNS = [\n",
    "    \"바랍니다\", \"주십시오\", \"주세요\", \"주시오\",\n",
    "    \"권고드립니다\", \"안내드립니다\", \"알려드립니다\",\n",
    "    \"하십시오\", \"하십시오.\", \"해 주십시오\", \"해 주세요\"\n",
    "]\n",
    "\n",
    "def extract_expanded_endings(json_dir: str, field=\"korean_text\", top_n=50):\n",
    "    from collections import Counter\n",
    "    from pathlib import Path\n",
    "    import json\n",
    "\n",
    "    counter = Counter()\n",
    "\n",
    "    for file in Path(json_dir).glob(\"*.json\"):\n",
    "        with open(file, encoding=\"utf-8\") as f:\n",
    "            text = json.load(f).get(field, \"\").strip()\n",
    "\n",
    "        for n in range(4, 20):  # 최대 20글자까지 뒤에서 잘라봄\n",
    "            candidate = text[-n:]\n",
    "            if any(p in candidate for p in END_PATTERNS):\n",
    "                counter[candidate] += 1\n",
    "\n",
    "    return counter.most_common(top_n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88a41332-38d7-4a37-ad82-0db7a430b52b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "바랍니다.: 2892\n",
      " 바랍니다.: 2664\n",
      "기 바랍니다.: 1917\n",
      "시기 바랍니다.: 1832\n",
      "하시기 바랍니다.: 1411\n",
      "의하시기 바랍니다.: 849\n",
      "유의하시기 바랍니다.: 560\n",
      " 유의하시기 바랍니다.: 560\n",
      "에 유의하시기 바랍니다.: 559\n",
      "의 바랍니다.: 554\n",
      "유의 바랍니다.: 429\n",
      " 유의 바랍니다.: 429\n",
      "에 유의 바랍니다.: 429\n",
      "주시기 바랍니다.: 421\n",
      " 주시기 바랍니다.: 405\n",
      "생에 유의 바랍니다.: 331\n",
      "발생에 유의 바랍니다.: 331\n",
      " 발생에 유의 바랍니다.: 331\n",
      "고 발생에 유의 바랍니다.: 331\n",
      "사고 발생에 유의 바랍니다.: 331\n",
      "전사고 발생에 유의 바랍니다.: 331\n",
      "안전사고 발생에 유의 바랍니다.: 331\n",
      " 안전사고 발생에 유의 바랍니다.: 331\n",
      "은 안전사고 발생에 유의 바랍니다.: 320\n",
      "피하시기 바랍니다.: 314\n",
      "대피하시기 바랍니다.: 314\n",
      " 대피하시기 바랍니다.: 314\n",
      "전에 유의하시기 바랍니다.: 294\n",
      "안전에 유의하시기 바랍니다.: 294\n",
      " 안전에 유의하시기 바랍니다.: 291\n",
      "주의하시기 바랍니다.: 289\n",
      " 주의하시기 바랍니다.: 289\n",
      "로 대피하시기 바랍니다.: 268\n",
      "여 주시기 바랍니다.: 264\n",
      "하여 주시기 바랍니다.: 264\n",
      "으로 대피하시기 바랍니다.: 262\n",
      "곳으로 대피하시기 바랍니다.: 253\n",
      " 곳으로 대피하시기 바랍니다.: 253\n",
      "한 곳으로 대피하시기 바랍니다.: 253\n",
      "전한 곳으로 대피하시기 바랍니다.: 253\n",
      "안전한 곳으로 대피하시기 바랍니다.: 253\n",
      "에 주의하시기 바랍니다.: 252\n",
      "생에 유의하시기 바랍니다.: 203\n",
      "발생에 유의하시기 바랍니다.: 203\n",
      " 발생에 유의하시기 바랍니다.: 200\n",
      "고 발생에 유의하시기 바랍니다.: 200\n",
      "사고 발생에 유의하시기 바랍니다.: 200\n",
      "전사고 발생에 유의하시기 바랍니다.: 200\n",
      "회하여 주시기 바랍니다.: 166\n",
      "우회하여 주시기 바랍니다.: 166\n"
     ]
    }
   ],
   "source": [
    "top_endings = extract_expanded_endings(\"training/train/norm_keypoint\")\n",
    "for phrase, count in top_endings:\n",
    "    print(f\"{phrase}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af19321a-6375-4d89-8c32-95ef0c5da4bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 3183 files in: training/train/norm_keypoint\n",
      "Processing 408 files in: training/val/norm_keypoint\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# ✅ 유의 바랍니다로 정규화\n",
    "NORMALIZATION_DICT = {\n",
    "#    \"주의하시기 바랍니다\": \"유의 바랍니다\",\n",
    "#    \"유의하시기 바랍니다.\": \"유의 바랍니다\",\n",
    "#    \"유의하시기 바랍니다\": \"유의 바랍니다\", \n",
    "    \"주의 바랍니다\": \"유의 바랍니다\"\n",
    "}\n",
    "\n",
    "def normalize_text_fields(data: dict, norm_dict: dict) -> dict:\n",
    "    for key in [\"korean_text\", \"masked_korean_text\"]:\n",
    "        if key in data:\n",
    "            for from_expr, to_expr in norm_dict.items():\n",
    "                data[key] = data[key].replace(from_expr, to_expr)\n",
    "    return data\n",
    "\n",
    "def apply_normalization_to_dir(json_dir: Path):\n",
    "    json_files = list(json_dir.glob(\"*.json\"))\n",
    "    print(f\"Processing {len(json_files)} files in: {json_dir}\")\n",
    "    \n",
    "    for file in json_files:\n",
    "        with open(file, encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        # 정규화 적용\n",
    "        data = normalize_text_fields(data, NORMALIZATION_DICT)\n",
    "\n",
    "        # 덮어쓰기 저장\n",
    "        with open(file, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# ✅ 적용 대상 디렉토리\n",
    "train_dir = Path(\"training/train/norm_keypoint\")\n",
    "val_dir = Path(\"training/val/norm_keypoint\")\n",
    "\n",
    "# 🔁 정규화 실행\n",
    "apply_normalization_to_dir(train_dir)\n",
    "apply_normalization_to_dir(val_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e073fee3-53eb-4331-8b0e-f67f6b9b666a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📂 Normalizing 'korean_text' in training/train/norm_keypoint: 100%|██████████| 3183/3183 [04:13<00:00, 12.53it/s]\n",
      "📂 Normalizing 'korean_text' in training/val/norm_keypoint: 100%|██████████| 408/408 [00:32<00:00, 12.48it/s]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "def normalize_day_in_json(json_dir: str, field=\"korean_text\"):\n",
    "    files = list(Path(json_dir).glob(\"*.json\"))\n",
    "\n",
    "    for file in tqdm(files, desc=f\"📂 Normalizing '{field}' in {json_dir}\"):\n",
    "        with open(file, encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        if field in data:\n",
    "            original = data[field]\n",
    "            normalized = re.sub(r\"(금일|당일)\", \"오늘\", original)\n",
    "            data[field] = normalized\n",
    "\n",
    "        with open(file, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "train_dir = Path(\"training/train/norm_keypoint\")\n",
    "val_dir = Path(\"training/val/norm_keypoint\")\n",
    "\n",
    "normalize_day_in_json(train_dir)\n",
    "normalize_day_in_json(val_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4fc26671-d389-4b8d-adb7-30c9e9113bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 결과 (in training/train/norm_keypoint):\n",
      "  🔎 '주의하시기 바랍니다': 0회\n",
      "  🔎 '유의하시기 바랍니다': 0회\n",
      "  🔎 '유의하시기 바랍니다.': 0회\n",
      "  🔎 '주의 바랍니다': 0회\n",
      "  🔎 '유의 바랍니다': 1437회\n",
      "📂 결과 (in training/val/norm_keypoint):\n",
      "  🔎 '주의하시기 바랍니다': 0회\n",
      "  🔎 '유의하시기 바랍니다': 0회\n",
      "  🔎 '유의하시기 바랍니다.': 0회\n",
      "  🔎 '주의 바랍니다': 0회\n",
      "  🔎 '유의 바랍니다': 174회\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "# 확인하고 싶은 표현들 (정규화 전 표현 + 정규화 후 표현)\n",
    "CHECK_PHRASES = [\n",
    "    \"주의하시기 바랍니다\",\n",
    "    \"유의하시기 바랍니다\",\n",
    "    \"유의하시기 바랍니다.\",\n",
    "    \"주의 바랍니다\",\n",
    "    \"유의 바랍니다\"\n",
    "]\n",
    "\n",
    "def count_phrases_in_dir(json_dir: Path, check_phrases):\n",
    "    counter = Counter()\n",
    "    files = list(json_dir.glob(\"*.json\"))\n",
    "\n",
    "    for file in files:\n",
    "        with open(file, encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        for key in [\"korean_text\", \"masked_korean_text\"]:\n",
    "            text = data.get(key, \"\")\n",
    "            for phrase in check_phrases:\n",
    "                if phrase in text:\n",
    "                    counter[phrase] += 1\n",
    "\n",
    "    print(f\"📂 결과 (in {json_dir}):\")\n",
    "    for phrase in check_phrases:\n",
    "        print(f\"  🔎 '{phrase}': {counter[phrase]}회\")\n",
    "\n",
    "# ✅ 실행\n",
    "train_dir = Path(\"training/train/norm_keypoint\")\n",
    "val_dir = Path(\"training/val/norm_keypoint\")\n",
    "\n",
    "count_phrases_in_dir(train_dir, CHECK_PHRASES)\n",
    "count_phrases_in_dir(val_dir, CHECK_PHRASES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b0263c-2391-4f5c-9d74-f9f3c830c9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ 가장 마지막에 등장하는 slot_value만 저장하는 방식으로 유지하며,\n",
    "#    동작을 명확히 하기 위해 덮어쓰기 로직을 명시함 (기존에도 이 방식이었음)\n",
    "\n",
    "import re\n",
    "from typing import Tuple, Dict\n",
    "\n",
    "def grouped_region_mask_korean_text_final(text: str) -> Tuple[str, Dict[str, str]]:\n",
    "    slot_values = {}\n",
    "    REGION_END = r'(?=\\s|[.,은는이가의에에서와]|[0-9]|$)'\n",
    "    JOSA = r\"(은|는|이|가|에|에서|로|를|과|와|도|까|까지|만|으로|요|도)\"\n",
    "    EXCLUDE_PATTERN = r'\\b[가-힣]{1,10}(사고|중|발생)\\b'\n",
    "    EXCLUDE_FOR_STATION = r'(사거리|삼거리|오거리|도로|고가도로|역사|하상도로|지하차도|차도|우회도로)'\n",
    "\n",
    "    patterns = [\n",
    "        (r'([0-2]?[0-9]:[0-5][0-9])', lambda m: [(\"<시간>\", m.group(1))]),\n",
    "        (r'([0-9]{1,2}시\\s?[0-9]{0,2}분?)', lambda m: [(\"<시간>\", m.group(1))]),\n",
    "        # ✅ 먼저 복합 지역 단어 (산 들어간 지역 방어용)\n",
    "        (r'\\b[가-힣]{2,10}(시|군|구|서구|북구|남구|동구)\\b', lambda m: [(\"<지역>\", m.group(0))]),\n",
    "    \n",
    "        # ✅ 산 (예외 단어 방어 포함)\n",
    "        (r'(?<!부산)(?<!확산)(?<!등산)(?<!우산)(?<!횡산)([가-힣]{1,10}산)(?=\\s|[.,은는이가의에에서와]|[0-9]|$)', \n",
    "         lambda m: [(\"<산>\", m.group(1))]),\n",
    "        (r'([가-힣0-9]{1,20}(사거리|삼거리|오거리|육거리)?\\s?(고가도로|하상도로|지하차도|도로|차도|우회도로))',\n",
    "         lambda m: [(\"<도로>\", m.group(0))]),\n",
    "        (r'([가-힣]{1,20}(사거리|삼거리|오거리|육거리))',\n",
    "         lambda m: [(\"<도로>\", m.group(1))]),\n",
    "        (rf'([가-힣]{{1,10}}(읍|면|동|리))\\s([가-힣]{{1,10}}(리)){REGION_END}',\n",
    "         lambda m: [(\"<지역>\", f\"{m.group(1)} {m.group(3)}\")]),\n",
    "        (rf'([가-힣]{{1,10}}(시|도|군|구))\\s?([가-힣]{{1,10}}(동|읍|면|리)){REGION_END}',\n",
    "         lambda m: [(\"<지역>\", f\"{m.group(1)} {m.group(3)}\")]),\n",
    "        (r'\\b([가-힣]{1,10}(시|도|군|구|읍|면|동|리))\\b', lambda m: [(\"<지역>\", m.group(1))]),\n",
    "        (r'([가-힣]{2,10}[0-9]{1,2}가)', lambda m: [(\"<주소>\", m.group(1))]),\n",
    "        (r'([0-9]{1,5}-[0-9]{1,5}(번지)?)', lambda m: [(\"<주소>\", m.group(1))]),\n",
    "        (r'([가-힣]{1,20}(로|길)\\s?[0-9]{1,4}(-[0-9]{1,4})?(번지)?)', lambda m: [(\"<주소>\", m.group(1))]),\n",
    "        (r'([0-9]{1,4}동)', lambda m: [(\"<주소>\", m.group(1))]),\n",
    "        (r'([가-힣A-Za-z0-9]{1,30}(아파트|오피스텔|주택|고시원|빌딩|건물|맨션|연립주택|사옥|하우스|타워|상가|점포|회관|센터|몰|모델하우스|아울렛|백화점))(?=\\s|' + JOSA + r'|\\b)',\n",
    "         lambda m: [(\"<건물>\", m.group(1))]),\n",
    "        (r'\\b(건물|아파트|빌딩|주택|하우스)\\b', lambda m: [(\"<건물>\", m.group(1))]),\n",
    "        (r'([가-힣A-Za-z0-9]{1,30}(호텔|모텔|펜션))', lambda m: [(\"<숙박시설>\", m.group(1))]),\n",
    "        (r'([가-힣]{2,20}공원)', lambda m: [(\"<공원>\", m.group(1))]),\n",
    "        (r'([가-힣]{2,10}공고)', lambda m: [(\"<학교>\", m.group(1))]),\n",
    "        (rf'\\b(?!안전?사고)([가-힣]{{2,10}}고)(?={JOSA})', lambda m: [(\"<학교>\", m.group(1))]),\n",
    "        (rf'\\b((?!{EXCLUDE_FOR_STATION})[가-힣0-9]{{2,20}}역)(?=\\s|' + JOSA + r'|\\b)',\n",
    "         lambda m: [(\"<역>\", m.group(1))]),\n",
    "        (EXCLUDE_PATTERN, lambda m: [(\"##EXCLUDE##\", m.group(0))]),\n",
    "    ]\n",
    "\n",
    "    matches = []\n",
    "    replaced_spans = []\n",
    "\n",
    "    # ✅ 원본 text 기준으로 전체 매치 수집\n",
    "    for pattern, slot_func in patterns:\n",
    "        for match in re.finditer(pattern, text):\n",
    "            start, end = match.span()\n",
    "            if any(s < end and start < e for s, e in replaced_spans):\n",
    "                continue\n",
    "            for slot, value in slot_func(match):\n",
    "                if slot != \"##EXCLUDE##\":\n",
    "                    matches.append((start, end, slot, value))\n",
    "                    replaced_spans.append((start, end))\n",
    "                    slot_values[slot] = value  # ✅ 항상 마지막 slot_value만 저장됨\n",
    "                    break\n",
    "\n",
    "    # ✅ masked_text를 뒤에서 앞으로 치환하여 인덱스 보존\n",
    "    masked_text = text\n",
    "    for start, end, slot, _ in sorted(matches, reverse=True):\n",
    "        masked_text = masked_text[:start] + slot + masked_text[end:]\n",
    "\n",
    "    return masked_text, slot_values\n",
    "\n",
    "\n",
    "# ✅ 테스트\n",
    "text = \"금일 10:10 고잔동 102-57번지 삼성화재 광주상무사옥 102-57호에 화재 발생. 이 지역을 우회하여 주시고 인근 주민은 안전사고 발생에 유의 바랍니다.\"\n",
    "masked, slots = grouped_region_mask_korean_text_final(text)\n",
    "print(\"🔹 Masked Text:\", masked)\n",
    "print(\"🔑 Slot Values:\", slots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8522f551-9dd7-40cd-ab45-eea5c2468270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ 마스킹 적용 및 출력\n",
    "TARGET_DIR = \"/teamspace/studios/this_studio/training/train/norm_keypoint\"\n",
    "print_limit = 200\n",
    "masked_results = []\n",
    "import re\n",
    "\n",
    "for path in sorted(glob(os.path.join(TARGET_DIR, \"*.json\")))[:print_limit]:\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    korean_text = data.get(\"korean_text\", \"\")\n",
    "    masked_text, slot_values = grouped_region_mask_korean_text_final(korean_text)\n",
    "\n",
    "    # 저장\n",
    "    data[\"masked_korean_text\"] = masked_text\n",
    "    data[\"slot_values\"] = slot_values\n",
    "    with open(path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    masked_results.append((os.path.basename(path), korean_text, masked_text, slot_values))\n",
    "\n",
    "for i, (fname, orig, masked, slots) in enumerate(masked_results[60:80], 1):\n",
    "    print(f\"📁 {i:02d}. File: {fname}\")\n",
    "    print(f\"🔸 Original: {orig}\")\n",
    "    print(f\"🔹 Masked  : {masked}\")\n",
    "    print(f\"🔑 Slot Values: {json.dumps(slots, ensure_ascii=False)}\\n{'-'*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cefbee15-7a5d-41b8-ba79-0b1a90d4711e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📂 Masking in training/train/norm_keypoint: 100%|██████████| 3183/3183 [04:21<00:00, 12.18it/s]\n",
      "📂 Masking in training/val/norm_keypoint: 100%|██████████| 408/408 [00:33<00:00, 12.28it/s]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 📌 마스킹 함수는 이미 정의되었다고 가정 (grouped_region_mask_korean_text_final)\n",
    "\n",
    "def apply_masking_to_json_dir(json_dir: str, field=\"korean_text\"):\n",
    "    for file in tqdm(list(Path(json_dir).glob(\"*.json\")), desc=f\"📂 Masking in {json_dir}\"):\n",
    "        with open(file, encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        if field in data:\n",
    "            text = data[field].strip()\n",
    "            masked_text, slot_values = grouped_region_mask_korean_text_final(text)\n",
    "            data[\"masked_text\"] = masked_text\n",
    "            data[\"slot_values\"] = slot_values\n",
    "\n",
    "            with open(file, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# ✅ 경로 지정\n",
    "train_dir = Path(\"training/train/norm_keypoint\")\n",
    "val_dir = Path(\"training/val/norm_keypoint\")\n",
    "\n",
    "# ✅ 적용\n",
    "apply_masking_to_json_dir(train_dir)\n",
    "apply_masking_to_json_dir(val_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dd54a967-3fdf-49a3-b92a-b69d9b38a658",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔁 Skip Sampling Augmentation: 100%|██████████| 3183/3183 [29:31<00:00,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ 모든 train 파일에서 augmentation 결과를 '/teamspace/studios/this_studio/training/train/augmented_keypoint'에 저장했습니다.\n",
      "🔍 중복된 frame이 포함된 augmentation 수: 217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Augmentation via Skip Sampling (Masking 이후)\n",
    "\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import copy\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 📁 디렉토리 설정\n",
    "NORM_DIR = \"/teamspace/studios/this_studio/training/train/norm_keypoint\"\n",
    "AUG_DIR = \"/teamspace/studios/this_studio/training/train/augmented_keypoint\"\n",
    "os.makedirs(AUG_DIR, exist_ok=True)\n",
    "\n",
    "# 📌 하이퍼파라미터 설정\n",
    "AUG_FACTOR = 50\n",
    "N_FRAMES_SAMPLED = 100\n",
    "\n",
    "# 파일 목록\n",
    "file_list = sorted(glob(os.path.join(NORM_DIR, \"*_norm.json\")))\n",
    "\n",
    "# 중복 frame 발생 수 기록용\n",
    "duplicate_aug_count = 0\n",
    "\n",
    "# 🔧 균일 sampling 인덱스 계산 함수\n",
    "def safe_sampling_indices(l, n):\n",
    "    z = int(np.floor(l / (n - 1)))\n",
    "    y = int(np.floor((l - z * (n - 1)) / 2))\n",
    "    baseline_idx = [y + z * k for k in range(n)]\n",
    "\n",
    "    # soft clipping\n",
    "    if baseline_idx[-1] >= l:\n",
    "        baseline_idx[-1] = l - 1\n",
    "\n",
    "    return baseline_idx, z\n",
    "\n",
    "# 🔁 파일별 augmentation 적용\n",
    "for src_path in tqdm(file_list, desc=\"🔁 Skip Sampling Augmentation\"):\n",
    "    basename = os.path.basename(src_path)\n",
    "    file_idx = basename.replace('_norm.json', '')\n",
    "\n",
    "    with open(src_path, 'r', encoding='utf-8') as f:\n",
    "        src_data = json.load(f)\n",
    "\n",
    "    frames = src_data['frames']\n",
    "    l = len(frames)\n",
    "    n = N_FRAMES_SAMPLED\n",
    "\n",
    "    if l < n:\n",
    "        # 🔸 길이 부족 시 복제 padding\n",
    "        indices = list(range(l)) + [l - 1] * (n - l)\n",
    "        sampled_frames = [frames[i] for i in indices]\n",
    "\n",
    "        new_data = {\n",
    "            \"id\": src_data[\"id\"],\n",
    "            \"masked_text\": src_data[\"masked_text\"],\n",
    "            \"frames\": sampled_frames,\n",
    "        }\n",
    "        for i, frame in enumerate(new_data[\"frames\"]):\n",
    "            frame[\"frame_idx\"] = i\n",
    "\n",
    "        save_path = os.path.join(AUG_DIR, f\"augmented_{file_idx}_1.json\")\n",
    "        with open(save_path, 'w', encoding='utf-8') as wf:\n",
    "            json.dump(new_data, wf, ensure_ascii=False, indent=2)\n",
    "\n",
    "    else:\n",
    "        baseline_idx, z = safe_sampling_indices(l, n)\n",
    "\n",
    "        if z == 1:\n",
    "            # 🔸 간격이 1이면 동일한 결과만 나오므로 1개만 생성\n",
    "            indices = [min(l - 1, max(0, idx)) for idx in baseline_idx]\n",
    "            sampled_frames = [frames[i] for i in indices]\n",
    "\n",
    "            new_data = {\n",
    "                \"id\": src_data[\"id\"],\n",
    "                \"masked_text\": src_data[\"masked_text\"],\n",
    "                \"frames\": sampled_frames,\n",
    "            }\n",
    "            for i, frame in enumerate(new_data[\"frames\"]):\n",
    "                frame[\"frame_idx\"] = i\n",
    "\n",
    "            save_path = os.path.join(AUG_DIR, f\"augmented_{file_idx}_1.json\")\n",
    "            with open(save_path, 'w', encoding='utf-8') as wf:\n",
    "                json.dump(new_data, wf, ensure_ascii=False, indent=2)\n",
    "\n",
    "        else:\n",
    "            # 🔸 다양한 noise 기반 augmentation 생성\n",
    "            for aug_idx in range(1, AUG_FACTOR + 1):\n",
    "                indices = []\n",
    "                for k in range(n):\n",
    "                    base = baseline_idx[k]\n",
    "                    if base >= l - 1:\n",
    "                        noise = 0\n",
    "                    else:\n",
    "                        noise_max = max(1, l - 1 - base) if k == n - 1 else max(1, z)\n",
    "                        noise = random.randint(0, noise_max - 1)\n",
    "                    idx = min(base + noise, l - 1)\n",
    "                    indices.append(idx)\n",
    "\n",
    "                if len(set(indices)) < len(indices):\n",
    "                    duplicate_aug_count += 1\n",
    "\n",
    "                sampled_frames = [frames[i] for i in indices]\n",
    "\n",
    "                new_data = {\n",
    "                    \"id\": src_data[\"id\"],\n",
    "                    \"masked_text\": src_data[\"masked_text\"],\n",
    "                    \"frames\": sampled_frames,\n",
    "                }\n",
    "                for i, frame in enumerate(new_data[\"frames\"]):\n",
    "                    frame[\"frame_idx\"] = i\n",
    "\n",
    "                save_path = os.path.join(AUG_DIR, f\"augmented_{file_idx}_{aug_idx}.json\")\n",
    "                with open(save_path, 'w', encoding='utf-8') as wf:\n",
    "                    json.dump(new_data, wf, ensure_ascii=False, indent=2)\n",
    "\n",
    "# ✅ 요약 출력\n",
    "print(f\"\\n✅ 모든 train 파일에서 augmentation 결과를 '{AUG_DIR}'에 저장했습니다.\")\n",
    "print(f\"🔍 중복된 frame이 포함된 augmentation 수: {duplicate_aug_count:,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "794f5437-a265-4fb8-83b5-c6a325ce12c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ujson\n",
      "  Downloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.3 kB)\n",
      "Downloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
      "Installing collected packages: ujson\n",
      "Successfully installed ujson-5.10.0\n"
     ]
    }
   ],
   "source": [
    "!pip install ujson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "34428e1d-131c-4939-806b-9240920ccab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'총 파일 수': 159150,\n",
       " 'frame 수가 100이 아닌 파일 수': 0,\n",
       " 'masked_text가 없는 파일 수': 0,\n",
       " '예시 frame 오류 파일': [],\n",
       " '예시 masked_text 오류 파일': []}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 코드 상태 초기화로 재실행\n",
    "import os\n",
    "import ujson  # ultra fast JSON parser\n",
    "from glob import glob\n",
    "\n",
    "# 디렉토리 설정\n",
    "AUG_DIR = \"/teamspace/studios/this_studio/training/train/augmented_keypoint\"\n",
    "\n",
    "# 체크용 결과 저장\n",
    "invalid_frame_counts = []\n",
    "missing_masked_text = []\n",
    "\n",
    "# 파일 목록\n",
    "aug_files = glob(os.path.join(AUG_DIR, \"augmented_*.json\"))\n",
    "\n",
    "# 빠른 검사\n",
    "for file_path in aug_files:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = ujson.load(f)\n",
    "\n",
    "    if len(data.get(\"frames\", [])) != 100:\n",
    "        invalid_frame_counts.append(os.path.basename(file_path))\n",
    "\n",
    "    if not data.get(\"masked_text\", \"\").strip():\n",
    "        missing_masked_text.append(os.path.basename(file_path))\n",
    "\n",
    "{\n",
    "    \"총 파일 수\": len(aug_files),\n",
    "    \"frame 수가 100이 아닌 파일 수\": len(invalid_frame_counts),\n",
    "    \"masked_text가 없는 파일 수\": len(missing_masked_text),\n",
    "    \"예시 frame 오류 파일\": invalid_frame_counts[:3],\n",
    "    \"예시 masked_text 오류 파일\": missing_masked_text[:3]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "24c08eaf-645c-42cb-bbd4-65da5a5f7e1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔄 Converting JSON to Numpy:   6%|▋         | 9988/159150 [00:47<10:24, 238.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved X_part_0.npy → shape (10000, 100, 108)\n",
      "📎 file_id_part_0.npy → 10000개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔄 Converting JSON to Numpy:  13%|█▎        | 19980/159150 [01:35<09:24, 246.38it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved X_part_1.npy → shape (10000, 100, 108)\n",
      "📎 file_id_part_1.npy → 10000개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔄 Converting JSON to Numpy:  19%|█▉        | 29999/159150 [02:23<08:37, 249.55it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved X_part_2.npy → shape (10000, 100, 108)\n",
      "📎 file_id_part_2.npy → 10000개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔄 Converting JSON to Numpy:  25%|██▌       | 39992/159150 [03:11<07:27, 266.40it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved X_part_3.npy → shape (10000, 100, 108)\n",
      "📎 file_id_part_3.npy → 10000개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔄 Converting JSON to Numpy:  31%|███▏      | 49997/159150 [04:00<07:47, 233.62it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved X_part_4.npy → shape (10000, 100, 108)\n",
      "📎 file_id_part_4.npy → 10000개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔄 Converting JSON to Numpy:  38%|███▊      | 59999/159150 [04:47<07:42, 214.52it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved X_part_5.npy → shape (10000, 100, 108)\n",
      "📎 file_id_part_5.npy → 10000개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔄 Converting JSON to Numpy:  44%|████▍     | 69998/159150 [05:36<07:45, 191.67it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved X_part_6.npy → shape (10000, 100, 108)\n",
      "📎 file_id_part_6.npy → 10000개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔄 Converting JSON to Numpy:  50%|█████     | 79991/159150 [06:22<05:33, 237.24it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved X_part_7.npy → shape (10000, 100, 108)\n",
      "📎 file_id_part_7.npy → 10000개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔄 Converting JSON to Numpy:  57%|█████▋    | 89999/159150 [07:10<04:43, 243.71it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved X_part_8.npy → shape (10000, 100, 108)\n",
      "📎 file_id_part_8.npy → 10000개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔄 Converting JSON to Numpy:  63%|██████▎   | 99997/159150 [07:58<03:45, 262.62it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved X_part_9.npy → shape (10000, 100, 108)\n",
      "📎 file_id_part_9.npy → 10000개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔄 Converting JSON to Numpy:  69%|██████▉   | 109977/159150 [08:47<03:08, 260.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved X_part_10.npy → shape (10000, 100, 108)\n",
      "📎 file_id_part_10.npy → 10000개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔄 Converting JSON to Numpy:  75%|███████▌  | 119985/159150 [09:36<10:24, 62.73it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved X_part_11.npy → shape (10000, 100, 108)\n",
      "📎 file_id_part_11.npy → 10000개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔄 Converting JSON to Numpy:  82%|████████▏ | 129995/159150 [10:24<01:51, 261.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved X_part_12.npy → shape (10000, 100, 108)\n",
      "📎 file_id_part_12.npy → 10000개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔄 Converting JSON to Numpy:  88%|████████▊ | 139993/159150 [11:11<01:13, 259.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved X_part_13.npy → shape (10000, 100, 108)\n",
      "📎 file_id_part_13.npy → 10000개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔄 Converting JSON to Numpy:  94%|█████████▍| 149996/159150 [12:01<00:39, 232.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved X_part_14.npy → shape (10000, 100, 108)\n",
      "📎 file_id_part_14.npy → 10000개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔄 Converting JSON to Numpy: 100%|█████████▉| 159142/159150 [12:44<00:00, 258.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved X_part_15.npy → shape (9150, 100, 108)\n",
      "📎 file_id_part_15.npy → 9150개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔄 Converting JSON to Numpy: 100%|██████████| 159150/159150 [12:45<00:00, 207.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎉 All data has been converted and saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ✅ 경로 설정\n",
    "DATA_DIR = \"./training/train/augmented_keypoint\"\n",
    "SAVE_DIR = \"./training/train/processed\"\n",
    "PART_SIZE = 10_000\n",
    "EXPECTED_FRAME_LEN = 100\n",
    "\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# 📄 JSON 파일 목록\n",
    "file_list = sorted([\n",
    "    os.path.join(DATA_DIR, f)\n",
    "    for f in os.listdir(DATA_DIR)\n",
    "    if f.endswith(\".json\")\n",
    "])\n",
    "total_files = len(file_list)\n",
    "\n",
    "# 🔁 변환용 리스트 초기화\n",
    "X_list, text_list, file_id_list = [], [], []\n",
    "part_idx = 0\n",
    "\n",
    "progress = tqdm(file_list, desc=\"🔄 Converting JSON to Numpy\")\n",
    "\n",
    "for i, file_path in enumerate(progress):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    masked_text = data.get(\"masked_text\", \"\").strip()\n",
    "    if not masked_text:\n",
    "        tqdm.write(f\"⚠️ Skipped (no masked_text): {file_path}\")\n",
    "        continue\n",
    "\n",
    "    frames = data.get(\"frames\", [])\n",
    "    if len(frames) != EXPECTED_FRAME_LEN:\n",
    "        tqdm.write(f\"⚠️ Skipped (wrong frame length = {len(frames)}): {file_path}\")\n",
    "        continue\n",
    "\n",
    "    keypoints = []\n",
    "    for frame in frames:\n",
    "        pose = frame.get(\"pose\", [])\n",
    "        hand_l = frame.get(\"hand_left\", [])\n",
    "        hand_r = frame.get(\"hand_right\", [])\n",
    "        keypoint = pose + hand_l + hand_r\n",
    "        if len(keypoint) != 108:\n",
    "            tqdm.write(f\"⚠️ Skipped (bad keypoint length): {file_path}\")\n",
    "            keypoints = []\n",
    "            break\n",
    "        keypoints.append(keypoint)\n",
    "\n",
    "    if len(keypoints) != EXPECTED_FRAME_LEN:\n",
    "        continue\n",
    "\n",
    "    X_list.append(keypoints)\n",
    "    text_list.append(masked_text)\n",
    "    file_id = os.path.basename(file_path).replace(\".json\", \"\")\n",
    "    file_id_list.append(file_id)\n",
    "\n",
    "    if len(X_list) == PART_SIZE or i == total_files - 1:\n",
    "        X_array = np.array(X_list, dtype=np.float32)\n",
    "        np.save(os.path.join(SAVE_DIR, f\"X_part_{part_idx}.npy\"), X_array)\n",
    "        np.save(os.path.join(SAVE_DIR, f\"file_id_part_{part_idx}.npy\"), np.array(file_id_list))\n",
    "\n",
    "        with open(os.path.join(SAVE_DIR, \"spm_input.txt\"), \"a\", encoding=\"utf-8\") as txt_file:\n",
    "            for line in text_list:\n",
    "                txt_file.write(line.strip() + \"\\n\")\n",
    "\n",
    "        tqdm.write(f\"✅ Saved X_part_{part_idx}.npy → shape {X_array.shape}\")\n",
    "        tqdm.write(f\"📎 file_id_part_{part_idx}.npy → {len(file_id_list)}개\")\n",
    "\n",
    "        X_list, text_list, file_id_list = [], [], []\n",
    "        part_idx += 1\n",
    "\n",
    "tqdm.write(\"\\n🎉 All data has been converted and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "20b72a7b-771f-4283-ba60-3c13c0ec4218",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ SentencePiece tokenizer 학습 완료!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: ./training/train/processed/spm_input.txt\n",
      "  input_format: \n",
      "  model_prefix: ./training/train/processed/spm\n",
      "  model_type: BPE\n",
      "  vocab_size: 1000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  user_defined_symbols: <건물>\n",
      "  user_defined_symbols: <지역>\n",
      "  user_defined_symbols: <시간>\n",
      "  user_defined_symbols: <도로>\n",
      "  user_defined_symbols: <주소>\n",
      "  user_defined_symbols: <학교>\n",
      "  user_defined_symbols: <산>\n",
      "  user_defined_symbols: <공원>\n",
      "  user_defined_symbols: <역>\n",
      "  user_defined_symbols: <숙박시설>\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  seed_sentencepieces_file: \n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: 3\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(353) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(185) LOG(INFO) Loading corpus: ./training/train/processed/spm_input.txt\n",
      "trainer_interface.cc(409) LOG(INFO) Loaded all 159150 sentences\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <pad>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <건물>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <지역>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <시간>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <도로>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <주소>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <학교>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <산>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <공원>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <역>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <숙박시설>\n",
      "trainer_interface.cc(430) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(539) LOG(INFO) all chars count=7606550\n",
      "trainer_interface.cc(550) LOG(INFO) Done: 99.9507% characters are covered.\n",
      "trainer_interface.cc(560) LOG(INFO) Alphabet size=349\n",
      "trainer_interface.cc(561) LOG(INFO) Final character coverage=0.999507\n",
      "trainer_interface.cc(592) LOG(INFO) Done! preprocessed 159150 sentences.\n",
      "trainer_interface.cc(598) LOG(INFO) Tokenizing input sentences with whitespace: 159150\n",
      "trainer_interface.cc(609) LOG(INFO) Done! 1183\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=184250 min_freq=150\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=50250 size=20 all=2028 active=1113 piece=사고\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=17000 size=40 all=2119 active=1204 piece=시고\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10200 size=60 all=2176 active=1261 piece=공사\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7000 size=80 all=2247 active=1332 piece=▁있\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5600 size=100 all=2287 active=1372 piece=▁반월\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=5600 min_freq=150\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4700 size=120 all=2313 active=1026 piece=공장\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3750 size=140 all=2350 active=1063 piece=▁창고\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3250 size=160 all=2417 active=1130 piece=되오니\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2550 size=180 all=2456 active=1169 piece=류창\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2200 size=200 all=2474 active=1187 piece=▁신속히\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2150 min_freq=150\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1800 size=220 all=2505 active=1032 piece=▁해\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1600 size=240 all=2541 active=1068 piece=하세요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1350 size=260 all=2565 active=1092 piece=▁계\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1200 size=280 all=2603 active=1130 piece=▁백\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1100 size=300 all=2641 active=1168 piece=▁인하여\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1100 min_freq=100\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1000 size=320 all=2657 active=1017 piece=케미스틸\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=950 size=340 all=2679 active=1039 piece=▁우회바랍니다\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=850 size=360 all=2702 active=1062 piece=▁대화\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=750 size=380 all=2722 active=1082 piece=▁사\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=700 size=400 all=2736 active=1096 piece=▁대중\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=700 min_freq=100\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=650 size=420 all=2741 active=1005 piece=철소\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=600 size=440 all=2753 active=1017 piece=되니\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=550 size=460 all=2764 active=1028 piece=▁[\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=550 size=480 all=2768 active=1032 piece=▁외출자제\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=500 size=500 all=2779 active=1043 piece=신장\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=500 min_freq=100\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=500 size=520 all=2797 active=1016 piece=신장애가\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=450 size=540 all=2802 active=1021 piece=▁삼가\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=450 size=560 all=2806 active=1025 piece=▁주유소에서\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=400 size=580 all=2819 active=1038 piece=▁오전\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=400 size=600 all=2822 active=1041 piece=▁상가주민들은\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=400 min_freq=50\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=350 size=620 all=2843 active=1022 piece=▁11\n",
      "trainer_interface.cc(687) LOG(INFO) Saving model: ./training/train/processed/spm.model\n",
      "trainer_interface.cc(699) LOG(INFO) Saving vocabs: ./training/train/processed/spm.vocab\n"
     ]
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "\n",
    "# 학습용 txt 경로\n",
    "input_txt = \"./training/train/processed/spm_input.txt\"\n",
    "\n",
    "# 저장 prefix\n",
    "model_prefix = \"./training/train/processed/spm\"\n",
    "vocab_size = 1000  # ✅ vocab 사이즈 확장\n",
    "\n",
    "# SentencePiece 모델 학습\n",
    "spm.SentencePieceTrainer.Train(\n",
    "    input=input_txt,\n",
    "    model_prefix=model_prefix,\n",
    "    vocab_size=vocab_size,\n",
    "    character_coverage=0.9995,\n",
    "    model_type=\"bpe\",\n",
    "    unk_id=0,              # ✅ UNK = 0 (기본값과 동일하지만 명시적으로 지정)\n",
    "    bos_id=1,              # ✅ BOS = 1\n",
    "    eos_id=2,              # ✅ EOS = 2\n",
    "    pad_id=3,              # ✅ PAD = 3\n",
    "    pad_piece=\"<pad>\",     # ✅ PAD 토큰 명시\n",
    "    user_defined_symbols=[\n",
    "        \"<건물>\", \"<지역>\", \"<시간>\", \"<도로>\", \"<주소>\",\n",
    "        \"<학교>\", \"<산>\", \"<공원>\", \"<역>\", \"<숙박시설>\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"✅ SentencePiece tokenizer 학습 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "32e3d4af-9f1a-4d22-88e6-32972913685a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🌤️ Encoding masked_text to y.npy:   6%|▋         | 10028/159150 [00:37<09:01, 275.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved y_part_0.npy → 10000 sequences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🌤️ Encoding masked_text to y.npy:  13%|█▎        | 20051/159150 [01:16<09:08, 253.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved y_part_1.npy → 10000 sequences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🌤️ Encoding masked_text to y.npy:  19%|█▉        | 30049/159150 [01:54<08:43, 246.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved y_part_2.npy → 10000 sequences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🌤️ Encoding masked_text to y.npy:  25%|██▌       | 40031/159150 [02:32<06:57, 285.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved y_part_3.npy → 10000 sequences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🌤️ Encoding masked_text to y.npy:  31%|███▏      | 50046/159150 [03:09<06:29, 280.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved y_part_4.npy → 10000 sequences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🌤️ Encoding masked_text to y.npy:  38%|███▊      | 60051/159150 [03:48<06:41, 247.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved y_part_5.npy → 10000 sequences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🌤️ Encoding masked_text to y.npy:  44%|████▍     | 70036/159150 [04:26<05:51, 253.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved y_part_6.npy → 10000 sequences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🌤️ Encoding masked_text to y.npy:  50%|█████     | 80052/159150 [05:04<05:06, 258.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved y_part_7.npy → 10000 sequences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🌤️ Encoding masked_text to y.npy:  57%|█████▋    | 90040/159150 [05:41<04:43, 243.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved y_part_8.npy → 10000 sequences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🌤️ Encoding masked_text to y.npy:  63%|██████▎   | 100054/159150 [06:20<03:28, 283.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved y_part_9.npy → 10000 sequences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🌤️ Encoding masked_text to y.npy:  69%|██████▉   | 110042/159150 [06:58<02:56, 278.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved y_part_10.npy → 10000 sequences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🌤️ Encoding masked_text to y.npy:  75%|███████▌  | 120042/159150 [07:36<02:54, 223.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved y_part_11.npy → 10000 sequences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🌤️ Encoding masked_text to y.npy:  82%|████████▏ | 130048/159150 [08:14<02:00, 241.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved y_part_12.npy → 10000 sequences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🌤️ Encoding masked_text to y.npy:  88%|████████▊ | 140049/159150 [08:52<01:05, 290.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved y_part_13.npy → 10000 sequences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🌤️ Encoding masked_text to y.npy:  94%|█████████▍| 150042/159150 [09:30<00:33, 274.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved y_part_14.npy → 10000 sequences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🌤️ Encoding masked_text to y.npy: 100%|██████████| 159150/159150 [10:05<00:00, 262.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved y_part_15.npy → 9150 sequences\n",
      "\n",
      "🎉 All masked_text → y numpy 변환 완료!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import sentencepiece as spm\n",
    "\n",
    "# 📌 SentencePiece tokenizer 로드\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load(\"./training/train/processed/spm.model\")\n",
    "\n",
    "bos_id = sp.bos_id()   # 1\n",
    "eos_id = sp.eos_id()   # 2\n",
    "\n",
    "# 📁 디렉토리 설정\n",
    "DATA_DIR = \"./training/train/augmented_keypoint\"\n",
    "SAVE_DIR = \"./training/train/processed\"\n",
    "PART_SIZE = 10_000\n",
    "\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# 📄 JSON 파일 목록\n",
    "file_list = sorted([\n",
    "    os.path.join(DATA_DIR, f)\n",
    "    for f in os.listdir(DATA_DIR)\n",
    "    if f.endswith(\".json\")\n",
    "])\n",
    "\n",
    "# 📦 저장 리스트 초기화\n",
    "y_list = []\n",
    "part_idx = 0\n",
    "\n",
    "# 🔁 파일별 처리\n",
    "for i, file_path in enumerate(tqdm(file_list, desc=\"🌤️ Encoding masked_text to y.npy\")):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    masked_text = data.get(\"masked_text\", \"\").strip()\n",
    "    if not masked_text:\n",
    "        continue\n",
    "\n",
    "    # SentencePiece로 인코딩 (BOS/EOS 포함)\n",
    "    y_ids = [bos_id] + sp.encode(masked_text, out_type=int) + [eos_id]\n",
    "    y_list.append(y_ids)\n",
    "\n",
    "    # PART 단위 저장\n",
    "    if len(y_list) == PART_SIZE or i == len(file_list) - 1:\n",
    "        np.save(os.path.join(SAVE_DIR, f\"y_part_{part_idx}.npy\"), np.array(y_list, dtype=object))\n",
    "        print(f\"✅ Saved y_part_{part_idx}.npy → {len(y_list)} sequences\")\n",
    "        y_list = []\n",
    "        part_idx += 1\n",
    "\n",
    "print(\"\\n🎉 All masked_text → y numpy 변환 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2a9c7d41-c5e5-4826-93ed-7950aeb6aba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔄 Processing Validation Set: 100%|██████████| 408/408 [00:09<00:00, 40.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved x_part_0.npy → 408 samples\n",
      "✅ Saved y_part_0.npy → 408 samples\n",
      "\n",
      "🎉 Validation set 변환 및 저장 완료 (masked_text 기준, variable-length 허용)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Processing Validation set \n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import sentencepiece as spm\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 🔧 경로 설정\n",
    "VAL_DATA_DIR = \"/teamspace/studios/this_studio/training/val/norm_keypoint\"\n",
    "SAVE_DIR = \"/teamspace/studios/this_studio/training/val/processed\"\n",
    "SPM_MODEL = \"/teamspace/studios/this_studio/training/train/processed/spm.model\"\n",
    "PART_SIZE = 10_000\n",
    "\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# 🔁 SentencePiece tokenizer 로드\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load(SPM_MODEL)\n",
    "\n",
    "bos_id = sp.bos_id()  # 1\n",
    "eos_id = sp.eos_id()  # 2\n",
    "\n",
    "# 📄 JSON 파일 목록 정렬\n",
    "file_list = sorted([\n",
    "    os.path.join(VAL_DATA_DIR, f)\n",
    "    for f in os.listdir(VAL_DATA_DIR)\n",
    "    if f.endswith(\".json\")\n",
    "])\n",
    "total_files = len(file_list)\n",
    "\n",
    "# 📦 저장용 리스트 초기화\n",
    "x_list, y_list, file_id_list = [], [], []\n",
    "part_idx = 0\n",
    "\n",
    "for i, file_path in enumerate(tqdm(file_list, desc=\"🔄 Processing Validation Set\")):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # 1️⃣ masked_text 추출\n",
    "    masked_text = data.get(\"masked_text\", \"\").strip()\n",
    "    if not masked_text:\n",
    "        continue\n",
    "\n",
    "    # 2️⃣ keypoint 추출\n",
    "    frames = data.get(\"frames\", [])\n",
    "    if len(frames) < 1:\n",
    "        continue\n",
    "\n",
    "    keypoints = []\n",
    "    for frame in frames:\n",
    "        pose = frame.get(\"pose\", [])\n",
    "        hand_l = frame.get(\"hand_left\", [])\n",
    "        hand_r = frame.get(\"hand_right\", [])\n",
    "        keypoint = pose + hand_l + hand_r\n",
    "        if len(keypoint) != 108:\n",
    "            break\n",
    "        keypoints.append(keypoint)\n",
    "\n",
    "    if len(keypoints) < 1:\n",
    "        continue\n",
    "\n",
    "    # 3️⃣ 변환 및 저장\n",
    "    x_list.append(np.array(keypoints, dtype=np.float32))  # variable-length\n",
    "    y_ids = [bos_id] + sp.encode(masked_text, out_type=int) + [eos_id]\n",
    "    y_list.append(y_ids)\n",
    "    file_id = os.path.basename(file_path).replace(\".json\", \"\")\n",
    "    file_id_list.append(file_id)\n",
    "\n",
    "    # 🔽 저장 조건\n",
    "    if len(x_list) == PART_SIZE or i == total_files - 1:\n",
    "        np.save(os.path.join(SAVE_DIR, f\"x_part_{part_idx}.npy\"), np.array(x_list, dtype=object))\n",
    "        np.save(os.path.join(SAVE_DIR, f\"y_part_{part_idx}.npy\"), np.array(y_list, dtype=object))\n",
    "        np.save(os.path.join(SAVE_DIR, f\"file_id_part_{part_idx}.npy\"), np.array(file_id_list))\n",
    "\n",
    "        print(f\"✅ Saved x_part_{part_idx}.npy → {len(x_list)} samples\")\n",
    "        print(f\"✅ Saved y_part_{part_idx}.npy → {len(y_list)} samples\")\n",
    "\n",
    "        # 초기화\n",
    "        x_list, y_list, file_id_list = [], [], []\n",
    "        part_idx += 1\n",
    "\n",
    "print(\"\\n🎉 Validation set 변환 및 저장 완료 (masked_text 기준, variable-length 허용)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "62287123-ddf0-4c88-b7df-1a26d13f21ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "PAD_ID = 3  # ✅ 패딩 토큰은 항상 3으로 고정\n",
    "\n",
    "# -----------------------------\n",
    "# 1. SLTDataset (Train Dataset)\n",
    "# -----------------------------\n",
    "class SLTDataset(Dataset):\n",
    "    def __init__(self, x_dir, y_dir, part_ids):\n",
    "        self.x_paths = [os.path.join(x_dir, f\"X_part_{i}.npy\") for i in part_ids]\n",
    "        self.y_paths = [os.path.join(y_dir, f\"y_part_{i}.npy\") for i in part_ids]  # ✅ 소문자 y로 변경\n",
    "\n",
    "        self.X = []\n",
    "        self.y = []\n",
    "\n",
    "        for x_path, y_path in zip(self.x_paths, self.y_paths):\n",
    "            self.X.extend(np.load(x_path, allow_pickle=True))\n",
    "            self.y.extend(np.load(y_path, allow_pickle=True))\n",
    "\n",
    "        assert len(self.X) == len(self.y), \"X and y size mismatch\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.tensor(self.X[idx], dtype=torch.float32)  # (T, 108)\n",
    "        y = torch.tensor(self.y[idx], dtype=torch.long)     # (L,)\n",
    "        return x, y\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Collate Function\n",
    "# -----------------------------\n",
    "def collate_fn(batch, pad_id=PAD_ID, max_len=100):\n",
    "    xs, ys = zip(*batch)\n",
    "\n",
    "    # 🧩 x padding\n",
    "    max_x_len = min(max([x.shape[0] for x in xs]), max_len)\n",
    "    padded_xs = []\n",
    "    for x in xs:\n",
    "        if x.shape[0] >= max_x_len:\n",
    "            padded_xs.append(x[:max_x_len])\n",
    "        else:\n",
    "            pad = torch.zeros(max_x_len - x.shape[0], x.shape[1])\n",
    "            padded_xs.append(torch.cat([x, pad], dim=0))\n",
    "    xs = torch.stack(padded_xs)  # (B, T, 108)\n",
    "\n",
    "    # 🧩 y padding\n",
    "    max_y_len = max([len(y) for y in ys])\n",
    "    ys = [F.pad(y, (0, max_y_len - len(y)), value=pad_id) for y in ys]\n",
    "    ys = torch.stack(ys)\n",
    "\n",
    "    return xs, ys\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Train DataLoader\n",
    "# -----------------------------\n",
    "X_DIR = \"/teamspace/studios/this_studio/training/train/processed\"\n",
    "Y_DIR = X_DIR\n",
    "PART_IDS = list(range(16))\n",
    "\n",
    "train_dataset = SLTDataset(X_DIR, Y_DIR, PART_IDS)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 4. SLTValDataset (Validation)\n",
    "# -----------------------------\n",
    "class SLTValDataset(Dataset):\n",
    "    def __init__(self, data_dir):\n",
    "        self.X_paths = sorted([os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.startswith(\"X_part_\")])\n",
    "        self.y_paths = sorted([os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.startswith(\"y_part_\")])  # ✅ 소문자 y\n",
    "\n",
    "        self.X = []\n",
    "        self.y = []\n",
    "\n",
    "        for x_path, y_path in zip(self.X_paths, self.y_paths):\n",
    "            self.X.extend(np.load(x_path, allow_pickle=True))\n",
    "            self.y.extend(np.load(y_path, allow_pickle=True))\n",
    "\n",
    "        assert len(self.X) == len(self.y), \"X and y size mismatch in validation set\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.tensor(self.X[idx], dtype=torch.float32)  # (T, 108)\n",
    "        y = torch.tensor(self.y[idx], dtype=torch.long)     # (L,)\n",
    "        return x, y\n",
    "\n",
    "\n",
    "def get_validation_loader(val_dir, batch_size=64, num_workers=2):\n",
    "    val_dataset = SLTValDataset(val_dir)\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "    return val_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "635cbf99-3133-441a-80f3-647f38dc9b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# -------------------------\n",
    "# 1. Attention 모듈\n",
    "# -------------------------\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, encoder_hidden_dim, decoder_hidden_dim):\n",
    "        super().__init__()\n",
    "        self.attn = nn.Linear(encoder_hidden_dim + decoder_hidden_dim, decoder_hidden_dim)\n",
    "        self.v = nn.Linear(decoder_hidden_dim, 1, bias=False)\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        # hidden: (B, dec_hidden)\n",
    "        # encoder_outputs: (B, src_len, enc_hidden_dim)\n",
    "        src_len = encoder_outputs.size(1)\n",
    "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)  # (B, src_len, dec_hidden)\n",
    "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim=2)))  # (B, src_len, dec_hidden)\n",
    "        attention = self.v(energy).squeeze(2)  # (B, src_len)\n",
    "        return F.softmax(attention, dim=1)\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# 2. Encoder (BiGRU)\n",
    "# -------------------------\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim=108, hidden_dim=256):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.GRU(input_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "\n",
    "    def forward(self, src):\n",
    "        # src: (B, T, input_dim)\n",
    "        outputs, hidden = self.rnn(src)  # outputs: (B, T, 2*H), hidden: (2, B, H)\n",
    "        return outputs, hidden\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# 3. Decoder (GRU + Attention)\n",
    "# -------------------------\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim=256, enc_hidden_dim=256, dec_hidden_dim=256):\n",
    "        super().__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        self.attention = Attention(enc_hidden_dim * 2, dec_hidden_dim)\n",
    "        self.rnn = nn.GRU(emb_dim + enc_hidden_dim * 2, dec_hidden_dim, batch_first=True)\n",
    "        self.fc_out = nn.Linear(emb_dim + enc_hidden_dim * 2 + dec_hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        # input: (B,)\n",
    "        # hidden: (1, B, dec_hidden)\n",
    "        # encoder_outputs: (B, src_len, enc_hidden*2)\n",
    "        input = input.unsqueeze(1)  # (B, 1)\n",
    "        embedded = self.embedding(input)  # (B, 1, emb_dim)\n",
    "\n",
    "        attn_weights = self.attention(hidden.squeeze(0), encoder_outputs)  # (B, src_len)\n",
    "        attn_weights = attn_weights.unsqueeze(1)  # (B, 1, src_len)\n",
    "        context = torch.bmm(attn_weights, encoder_outputs)  # (B, 1, enc_hidden*2)\n",
    "\n",
    "        rnn_input = torch.cat((embedded, context), dim=2)  # (B, 1, emb_dim + ctx)\n",
    "        output, hidden = self.rnn(rnn_input, hidden)  # output: (B, 1, dec_hidden)\n",
    "\n",
    "        concat = torch.cat((output, context, embedded), dim=2)  # (B, 1, total_dim)\n",
    "        prediction = self.fc_out(concat.squeeze(1))  # (B, output_dim)\n",
    "\n",
    "        return prediction, hidden, attn_weights.squeeze(1)\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# 4. Seq2Seq (통합 모듈)\n",
    "# -------------------------\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device, pad_id=3):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        self.pad_id = pad_id\n",
    "\n",
    "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
    "        # src: (B, T, 108), trg: (B, L)\n",
    "        batch_size = src.size(0)\n",
    "        trg_len = trg.size(1)\n",
    "        output_dim = self.decoder.output_dim\n",
    "\n",
    "        # 🧱 Output tensor 초기화\n",
    "        outputs = torch.zeros(batch_size, trg_len, output_dim).to(self.device)\n",
    "\n",
    "        # 🔁 Encoder\n",
    "        encoder_outputs, hidden = self.encoder(src)  # hidden: (2, B, H)\n",
    "        hidden = torch.tanh(hidden[0] + hidden[1]).unsqueeze(0)  # (1, B, H)\n",
    "\n",
    "        # 🔁 Decoder 시작 - 첫 input은 BOS 토큰\n",
    "        input = trg[:, 0]  # (B,)\n",
    "\n",
    "        for t in range(1, trg_len):\n",
    "            output, hidden, _ = self.decoder(input, hidden, encoder_outputs)  # output: (B, vocab)\n",
    "            outputs[:, t] = output  # t 위치에 output 저장\n",
    "\n",
    "            teacher_force = torch.rand(1).item() < teacher_forcing_ratio\n",
    "            top1 = output.argmax(1)  # (B,)\n",
    "\n",
    "            input = trg[:, t] if teacher_force else top1\n",
    "\n",
    "        return outputs  # (B, L, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ce83d49-1dd0-4be1-9d6c-7c74acabaec0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: evaluate in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (0.4.4)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from evaluate) (3.6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from evaluate) (1.26.4)\n",
      "Requirement already satisfied: dill in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from evaluate) (2.1.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from evaluate) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from evaluate) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from evaluate) (0.33.1)\n",
      "Requirement already satisfied: packaging in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from evaluate) (24.2)\n",
      "Requirement already satisfied: filelock in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.18.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (20.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (3.12.12)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from multidict<7.0,>=4.5->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (4.14.0)\n",
      "Requirement already satisfied: idna>=2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (3.10)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2025.4.26)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "184733e6-a1ba-4e7c-99d3-d3304904aa1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /teamspace/studios/this_studio/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /teamspace/studios/this_studio/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /teamspace/studios/this_studio/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Model_1\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import evaluate\n",
    "\n",
    "# ---------------------------\n",
    "# 1. 평가 지표 로드\n",
    "# ---------------------------\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "meteor = evaluate.load(\"meteor\")\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "\n",
    "# ---------------------------\n",
    "# 2. 디코딩 함수\n",
    "# ---------------------------\n",
    "def decode_sequence(tokenizer, sequences, eos_id=2):\n",
    "    decoded = []\n",
    "    for seq in sequences:\n",
    "        tokens = []\n",
    "        for tok in seq:\n",
    "            if tok == eos_id:\n",
    "                break\n",
    "            tokens.append(tok)\n",
    "        sentence = tokenizer.decode(tokens)\n",
    "        decoded.append(sentence.replace(\"▁\", \" \").strip())\n",
    "    return decoded\n",
    "\n",
    "# ---------------------------\n",
    "# 3. 평가 지표 계산\n",
    "# ---------------------------\n",
    "def compute_metrics(preds, refs, tokenizer, eos_id=2):\n",
    "    decoded_preds = decode_sequence(tokenizer, preds, eos_id)\n",
    "    decoded_refs = decode_sequence(tokenizer, refs, eos_id)\n",
    "    return {\n",
    "        \"BLEU\": bleu.compute(predictions=decoded_preds, references=[[r] for r in decoded_refs])[\"bleu\"],\n",
    "        \"METEOR\": meteor.compute(predictions=decoded_preds, references=decoded_refs)[\"meteor\"],\n",
    "        \"ROUGE\": rouge.compute(predictions=decoded_preds, references=decoded_refs)[\"rougeL\"]\n",
    "    }\n",
    "\n",
    "# ---------------------------\n",
    "# 4. 체크포인트 저장\n",
    "# ---------------------------\n",
    "def save_checkpoint(model, optimizer, epoch, val_bleu, val_meteor, val_loss, path):\n",
    "    checkpoint = {\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        \"epoch\": epoch,\n",
    "        \"val_bleu\": val_bleu,\n",
    "        \"val_meteor\": val_meteor,\n",
    "        \"val_loss\": val_loss\n",
    "    }\n",
    "    torch.save(checkpoint, path)\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# 5. 학습 루프 with EOS/BOS + 샘플 출력\n",
    "# ---------------------------\n",
    "def train_with_early_stopping(\n",
    "    model, train_loader, val_loader, tokenizer,\n",
    "    optimizer, criterion, device,\n",
    "    num_epochs=30,\n",
    "    teacher_forcing_ratio=0.5,\n",
    "    clip=1.0,\n",
    "    pad_id=0,\n",
    "    eos_id=2,\n",
    "    save_path=\"best_model.pt\",\n",
    "    early_stopping_patience=5,\n",
    "    checkpoint_dir=\"checkpoints\"\n",
    "):\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    best_bleu = -1\n",
    "    patience = 0\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        pbar = tqdm(train_loader, desc=f\"[Epoch {epoch}] Training\")\n",
    "\n",
    "        for X, y in pbar:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            decoder_input = y[:, :-1]\n",
    "            target = y[:, 1:]\n",
    "\n",
    "            output = model(X, decoder_input, teacher_forcing_ratio=teacher_forcing_ratio)\n",
    "            output = output.reshape(-1, output.shape[-1])\n",
    "            target = target.reshape(-1)\n",
    "\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            pbar.set_postfix(train_loss=epoch_loss / (pbar.n + 1))\n",
    "\n",
    "        # -----------------------\n",
    "        # Train Sample 출력\n",
    "        # -----------------------\n",
    "        model.eval()\n",
    "        train_preds, train_refs = [], []\n",
    "        with torch.no_grad():\n",
    "            for X_train, y_train in train_loader:\n",
    "                X_train, y_train = X_train.to(device), y_train.to(device)\n",
    "                output = model(X_train, y_train[:, :-1], teacher_forcing_ratio=0.0)\n",
    "                output_tokens = output.argmax(-1)\n",
    "                train_preds = decode_sequence(tokenizer, output_tokens[:5].tolist(), eos_id)\n",
    "                train_refs = decode_sequence(tokenizer, y_train[:5].tolist(), eos_id)\n",
    "                break  # 첫 batch만\n",
    "\n",
    "        print(\"\\n🟦 [Train Samples]\")\n",
    "        for i in range(len(train_preds)):\n",
    "            print(f\"🔹 [Pred] {train_preds[i]}\")\n",
    "            print(f\"🔸 [True] {train_refs[i]}\")\n",
    "            print()\n",
    "\n",
    "        # -----------------------\n",
    "        # Validation\n",
    "        # -----------------------\n",
    "        val_loss = 0\n",
    "        preds, refs = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for X_val, y_val in val_loader:\n",
    "                X_val, y_val = X_val.to(device), y_val.to(device)\n",
    "                decoder_input = y_val[:, :-1]\n",
    "                target = y_val[:, 1:]\n",
    "\n",
    "                output = model(X_val, decoder_input, teacher_forcing_ratio=0.0)\n",
    "                output_tokens = output.argmax(-1)\n",
    "\n",
    "                preds.extend(output_tokens.tolist())\n",
    "                refs.extend(y_val.tolist())\n",
    "\n",
    "                output = output.reshape(-1, output.shape[-1])\n",
    "                target = target.reshape(-1)\n",
    "                val_loss += criterion(output, target).item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        metrics = compute_metrics(preds, refs, tokenizer, eos_id)\n",
    "        val_bleu = metrics[\"BLEU\"]\n",
    "        val_preds = decode_sequence(tokenizer, preds[:5], eos_id)\n",
    "        val_refs = decode_sequence(tokenizer, refs[:5], eos_id)\n",
    "\n",
    "        print(\"\\n🟩 [Validation Samples]\")\n",
    "        for i in range(len(val_preds)):\n",
    "            print(f\"🔹 [Pred] {val_preds[i]}\")\n",
    "            print(f\"🔸 [True] {val_refs[i]}\")\n",
    "            print()\n",
    "\n",
    "        print(f\"[Epoch {epoch}] Val Loss: {val_loss:.4f} | BLEU: {val_bleu:.4f} | METEOR: {metrics['METEOR']:.4f} | ROUGE: {metrics['ROUGE']:.4f}\")\n",
    "        # ⬅️ 1. 현재 epoch checkpoint 저장 (일반)\n",
    "        ckpt_path = os.path.join(checkpoint_dir, f\"checkpoint_epoch{epoch}.pt\")\n",
    "        save_checkpoint(\n",
    "            model,\n",
    "            optimizer,\n",
    "            epoch,\n",
    "            val_bleu,\n",
    "            metrics[\"METEOR\"],\n",
    "            val_loss,\n",
    "            ckpt_path  # ✅ 여기에 저장!\n",
    "        )\n",
    "        \n",
    "        # ⬅️ 2. BLEU 기준 best model 저장\n",
    "        if val_bleu > best_bleu:\n",
    "            best_bleu = val_bleu\n",
    "            patience = 0\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            save_checkpoint(\n",
    "                model,\n",
    "                optimizer,\n",
    "                epoch,\n",
    "                val_bleu,\n",
    "                metrics[\"METEOR\"],\n",
    "                val_loss,\n",
    "                os.path.join(checkpoint_dir, \"best_checkpoint.pt\")  # ✅ 여기에만 best 저장\n",
    "            )\n",
    "            print(f\"✅ Best model saved at epoch {epoch} (BLEU={val_bleu:.4f})\")\n",
    "        else:\n",
    "            patience += 1\n",
    "            if patience >= early_stopping_patience:\n",
    "                print(f\"🛑 Early stopping triggered. Best BLEU: {best_bleu:.4f}\")\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d59b65d6-76a3-4edf-85d6-ecdeb43210df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /teamspace/studios/this_studio/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /teamspace/studios/this_studio/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /teamspace/studios/this_studio/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Model_2\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import evaluate\n",
    "\n",
    "# ---------------------------\n",
    "# 1. 평가 지표 로드 (HuggingFace Evaluate)\n",
    "# ---------------------------\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "meteor = evaluate.load(\"meteor\")\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# 2. 토큰 시퀀스를 자연어로 복원\n",
    "# (배치 디코딩용, eos_id 기준으로 잘라냄)\n",
    "# ---------------------------\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def top_k_top_p_filtering(logits, top_k=0, top_p=1.0, filter_value=-float(\"Inf\")):\n",
    "    \"\"\"\n",
    "    Filter a distribution of logits using top-k and/or nucleus (top-p) filtering.\n",
    "    \"\"\"\n",
    "    logits = logits.clone()\n",
    "\n",
    "    # Top-k filtering\n",
    "    if top_k > 0:\n",
    "        top_k = min(top_k, logits.size(-1))  # Safety check\n",
    "        indices_to_remove = logits < torch.topk(logits, top_k)[0][..., -1, None]\n",
    "        logits[indices_to_remove] = filter_value\n",
    "\n",
    "    # Top-p (nucleus) filtering\n",
    "    if top_p < 1.0:\n",
    "        sorted_logits, sorted_indices = torch.sort(logits, descending=True)\n",
    "        cumulative_probs = torch.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\n",
    "\n",
    "        # Remove tokens with cumulative prob > top_p\n",
    "        sorted_indices_to_remove = cumulative_probs > top_p\n",
    "        # Shift right to keep at least one token\n",
    "        sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n",
    "        sorted_indices_to_remove[..., 0] = 0\n",
    "\n",
    "        indices_to_remove = sorted_indices[sorted_indices_to_remove]\n",
    "        logits[indices_to_remove] = filter_value\n",
    "\n",
    "    return logits\n",
    "\n",
    "def decode_sequence(\n",
    "    model,\n",
    "    input_tensor,\n",
    "    tokenizer,\n",
    "    device,\n",
    "    max_len=100,\n",
    "    eos_id=2,\n",
    "    repetition_penalty=1.2,\n",
    "    top_k=5,\n",
    "    top_p=0.9\n",
    "):\n",
    "    \"\"\"\n",
    "    Sampling-based decoding using top-k, top-p, and repetition penalty.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    input_tensor = input_tensor.unsqueeze(0).to(device)  # (1, T, D)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        encoder_outputs, hidden = model.encoder(input_tensor)\n",
    "        hidden = torch.tanh(hidden[0] + hidden[1]).unsqueeze(0)  # (1, 1, H)\n",
    "\n",
    "        input_token = torch.tensor([tokenizer.bos_id()], device=device)  # (1,)\n",
    "        decoded = []\n",
    "        used_tokens = set()\n",
    "\n",
    "        for _ in range(max_len):\n",
    "            output, hidden, _ = model.decoder(input_token, hidden, encoder_outputs)  # output: (1, vocab)\n",
    "            output = output.squeeze(0)  # (vocab,)\n",
    "\n",
    "            # Apply repetition penalty\n",
    "            for token_id in used_tokens:\n",
    "                if output[token_id] < 0:\n",
    "                    output[token_id] *= repetition_penalty\n",
    "                else:\n",
    "                    output[token_id] /= repetition_penalty\n",
    "\n",
    "            # Sampling with top-k and/or top-p\n",
    "            filtered_logits = top_k_top_p_filtering(output, top_k=top_k, top_p=top_p)\n",
    "            probs = F.softmax(filtered_logits, dim=-1)\n",
    "            top1 = torch.multinomial(probs, num_samples=1).item()\n",
    "\n",
    "            if top1 == eos_id:\n",
    "                break\n",
    "\n",
    "            decoded.append(top1)\n",
    "            used_tokens.add(top1)\n",
    "            input_token = torch.tensor([top1], device=device)\n",
    "\n",
    "    return tokenizer.decode(decoded).replace(\"▁\", \" \").strip()\n",
    "\n",
    "\n",
    "def decode_tokens(tokenizer, sequences, eos_id=2, pad_id=3):\n",
    "    \"\"\"\n",
    "    sequences: List of token ids (List[List[int]])\n",
    "    Returns: List of decoded strings\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for seq in sequences:\n",
    "        tokens = []\n",
    "        for t in seq:\n",
    "            if t == eos_id or t == pad_id:\n",
    "                break\n",
    "            tokens.append(t)\n",
    "        results.append(tokenizer.decode(tokens).replace(\"▁\", \" \").strip())\n",
    "    return results\n",
    "\n",
    "# ---------------------------\n",
    "# 3. BLEU, METEOR, ROUGE 계산\n",
    "# ---------------------------\n",
    "def compute_metrics(preds, refs, tokenizer, eos_id=2, pad_id=3):\n",
    "    decoded_preds = decode_tokens(tokenizer, preds, eos_id, pad_id)\n",
    "    decoded_refs = decode_tokens(tokenizer, refs, eos_id, pad_id)\n",
    "\n",
    "    return {\n",
    "        \"BLEU\": bleu.compute(predictions=decoded_preds, references=[[r] for r in decoded_refs])[\"bleu\"],\n",
    "        \"METEOR\": meteor.compute(predictions=decoded_preds, references=decoded_refs)[\"meteor\"],\n",
    "        \"ROUGE\": rouge.compute(predictions=decoded_preds, references=decoded_refs)[\"rougeL\"]\n",
    "    }\n",
    "\n",
    "# ---------------------------\n",
    "# 4. 체크포인트 저장\n",
    "# ---------------------------\n",
    "def save_checkpoint(model, optimizer, epoch, val_bleu, val_meteor, val_loss, path):\n",
    "    checkpoint = {\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        \"epoch\": epoch,\n",
    "        \"val_bleu\": val_bleu,\n",
    "        \"val_meteor\": val_meteor,\n",
    "        \"val_loss\": val_loss\n",
    "    }\n",
    "    torch.save(checkpoint, path)\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# 4. label smoothing 적용\n",
    "# ---------------------------\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LabelSmoothingLoss(nn.Module):\n",
    "    def __init__(self, label_smoothing, tgt_vocab_size, ignore_index=-100):\n",
    "        super().__init__()\n",
    "        self.ignore_index = ignore_index\n",
    "        self.confidence = 1.0 - label_smoothing\n",
    "        self.smoothing = label_smoothing\n",
    "        self.vocab_size = tgt_vocab_size\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        pred = pred.log_softmax(dim=-1)  # (B*T, V)\n",
    "        true_dist = torch.zeros_like(pred)\n",
    "        true_dist.fill_(self.smoothing / (self.vocab_size - 2))\n",
    "        ignore = target == self.ignore_index\n",
    "        target = target.masked_fill(ignore, 0)\n",
    "        true_dist.scatter_(1, target.unsqueeze(1), self.confidence)\n",
    "        true_dist.masked_fill_(ignore.unsqueeze(1), 0.0)\n",
    "        return F.kl_div(pred, true_dist, reduction='batchmean')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_with_early_stopping(\n",
    "    model, train_loader, val_loader, tokenizer,\n",
    "    optimizer, criterion, device,\n",
    "    num_epochs=30,\n",
    "    teacher_forcing_ratio=0.5,\n",
    "    clip=1.0,\n",
    "    pad_id=0,\n",
    "    eos_id=2,\n",
    "    save_path=\"best_model.pt\",\n",
    "    early_stopping_patience=5,\n",
    "    checkpoint_dir=\"checkpoints\"\n",
    "):\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    best_bleu = -1\n",
    "    patience = 0\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        pbar = tqdm(train_loader, desc=f\"[Epoch {epoch}] Training\")\n",
    "\n",
    "        for X, y in pbar:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            decoder_input = y[:, :-1]\n",
    "            target = y[:, 1:]\n",
    "\n",
    "            output = model(X, decoder_input, teacher_forcing_ratio=teacher_forcing_ratio)\n",
    "            output = output.reshape(-1, output.shape[-1])\n",
    "            target = target.reshape(-1)\n",
    "\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            pbar.set_postfix(train_loss=epoch_loss / (pbar.n + 1))\n",
    "\n",
    "        # 🔵 Train 샘플 5개 출력\n",
    "        model.eval()\n",
    "        train_preds, train_refs = [], []\n",
    "        with torch.no_grad():\n",
    "            for X_train, y_train in train_loader:\n",
    "                X_train, y_train = X_train.to(device), y_train.to(device)\n",
    "                out = model(X_train, y_train[:, :-1], teacher_forcing_ratio=0.0)\n",
    "                out_tokens = out.argmax(-1)\n",
    "                train_preds = [decode_sequence(model, x, tokenizer, device, eos_id=eos_id) for x in X_train[:5]]\n",
    "                train_refs = [\n",
    "                    tokenizer.decode([t for t in sent if t != PAD_ID and t != eos_id]).replace(\"▁\", \" \").strip()\n",
    "                    for sent in y_train[:5].tolist()\n",
    "                ]\n",
    "                break\n",
    "\n",
    "        print(\"\\n🟦 [Train Samples]\")\n",
    "        for i in range(len(train_preds)):\n",
    "            print(f\"🔹 [Pred] {train_preds[i]}\")\n",
    "            print(f\"🔸 [True] {train_refs[i]}\")\n",
    "            print()\n",
    "\n",
    "        # 🟢 Validation\n",
    "        val_loss = 0\n",
    "        preds, refs = [], []\n",
    "        with torch.no_grad():\n",
    "            for X_val, y_val in val_loader:\n",
    "                X_val, y_val = X_val.to(device), y_val.to(device)\n",
    "                out = model(X_val, y_val[:, :-1], teacher_forcing_ratio=0.0)\n",
    "                out_tokens = out.argmax(-1)\n",
    "                preds.extend(out_tokens.tolist())\n",
    "                refs.extend(y_val.tolist())\n",
    "\n",
    "                out = out.reshape(-1, out.shape[-1])\n",
    "                target = y_val[:, 1:].reshape(-1)\n",
    "                val_loss += criterion(out, target).item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        metrics = compute_metrics(preds, refs, tokenizer, eos_id)\n",
    "        val_bleu = metrics[\"BLEU\"]\n",
    "        val_preds = [decode_sequence(model, x, tokenizer, device, eos_id=eos_id) for x in X_val[:5]]\n",
    "        val_refs = decode_tokens(tokenizer, refs[:5], eos_id=eos_id, pad_id=pad_id)\n",
    "\n",
    "        print(\"\\n🟩 [Validation Samples]\")\n",
    "        for i in range(len(val_preds)):\n",
    "            print(f\"🔹 [Pred] {val_preds[i]}\")\n",
    "            print(f\"🔸 [True] {val_refs[i]}\")\n",
    "            print()\n",
    "\n",
    "        print(f\"[Epoch {epoch}] Val Loss: {val_loss:.4f} | BLEU: {val_bleu:.4f} | METEOR: {metrics['METEOR']:.4f} | ROUGE: {metrics['ROUGE']:.4f}\")\n",
    "\n",
    "        # ✅ Checkpoint 저장\n",
    "        ckpt_path = os.path.join(checkpoint_dir, f\"checkpoint_epoch{epoch}.pt\")\n",
    "        save_checkpoint(\n",
    "            model,\n",
    "            optimizer,\n",
    "            epoch,\n",
    "            val_bleu,\n",
    "            metrics[\"METEOR\"],\n",
    "            val_loss,\n",
    "            ckpt_path  # ✅ 여기에 저장!\n",
    "        )\n",
    "        \n",
    "        # ⬅️ 2. BLEU 기준 best model 저장\n",
    "        if val_bleu > best_bleu:\n",
    "            best_bleu = val_bleu\n",
    "            patience = 0\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            save_checkpoint(\n",
    "                model,\n",
    "                optimizer,\n",
    "                epoch,\n",
    "                val_bleu,\n",
    "                metrics[\"METEOR\"],\n",
    "                val_loss,\n",
    "                os.path.join(checkpoint_dir, \"best_checkpoint.pt\")  # ✅ 여기에만 best 저장\n",
    "            )\n",
    "            print(f\"✅ Best model saved at epoch {epoch} (BLEU={val_bleu:.4f})\")\n",
    "        else:\n",
    "            patience += 1\n",
    "            if patience >= early_stopping_patience:\n",
    "                print(f\"🛑 Early stopping triggered. Best BLEU: {best_bleu:.4f}\")\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aad0fbb9-cbac-490a-abad-53f64a31faa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Using CPU\n",
      "✅ Seq2Seq model initialized and moved to cpu\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 1000  # ✅ vocab 사이즈 확장\n",
    "\n",
    "import torch\n",
    "\n",
    "# -------------------------\n",
    "# 0. 디바이스 설정\n",
    "# -------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if device.type == \"cuda\":\n",
    "    print(\"✅ Using device:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"⚠️ Using CPU\")\n",
    "\n",
    "# -------------------------\n",
    "# 1. 하이퍼파라미터 정의\n",
    "# -------------------------\n",
    "INPUT_DIM = 108\n",
    "ENC_HIDDEN_DIM = 256\n",
    "DEC_HIDDEN_DIM = 256\n",
    "EMB_DIM = 256\n",
    "VOCAB_SIZE = vocab_size      # ✅ 최신 SentencePiece vocab size 반영\n",
    "\n",
    "PAD_ID = 3              # ✅ pad_id 설정 (unk=0, bos=1, eos=2, pad=3)\n",
    "\n",
    "# -------------------------\n",
    "# 2. 모델 정의\n",
    "# -------------------------\n",
    "encoder = Encoder(input_dim=INPUT_DIM, hidden_dim=ENC_HIDDEN_DIM)\n",
    "decoder = Decoder(\n",
    "    output_dim=VOCAB_SIZE,\n",
    "    emb_dim=EMB_DIM,\n",
    "    enc_hidden_dim=ENC_HIDDEN_DIM,\n",
    "    dec_hidden_dim=DEC_HIDDEN_DIM\n",
    ")\n",
    "\n",
    "model = Seq2Seq(encoder, decoder, device).to(device)\n",
    "print(\"✅ Seq2Seq model initialized and moved to\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "30fce4fd-a5b0-484e-a2b0-b29ea64f8926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 토크나이저 불러오기\n",
    "import sentencepiece as spm\n",
    "from tqdm import tqdm  # ✅ 추천 방식\n",
    "import torch.nn as nn  # 필요시 상단에 추가\n",
    "\n",
    "spm_tokenizer = spm.SentencePieceProcessor()\n",
    "spm_tokenizer.load(\"/teamspace/studios/this_studio/training/train/processed/spm.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f517e64b-08cb-4569-b4a7-a24ae970c0ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Using device: NVIDIA L40S\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Training: 100%|██████████| 2487/2487 [02:27<00:00, 16.84it/s, train_loss=0.836]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🟦 [Train Samples]\n",
      "🔹 [Pred] <시간> <지역> <건물> 화재 발생, 인근주민은 안전한 대피 바람.\n",
      "🔸 [True] 오늘 <시간> <지역> <건물> 화재 발생, 인근주민은 안전한 곳으로 대피 바람.\n",
      "\n",
      "🔹 [Pred] <시간> <지역> <지역> 소재 오피스텔 화재발생으로 주변은 교통 우회하시기 바랍니다.\n",
      "🔸 [True] 오늘 <시간> <지역> <지역> 소재 오피스텔 화재발생으로 주변 교통은 혼잡하오니 우회하시기 바랍니다.\n",
      "\n",
      "🔹 [Pred] <시간> <지역> <건물> 롯데리아  화재 발생. 주민은 인근 안전한 곳으로 대피하시기 바랍니다.\n",
      "🔸 [True] 오늘 <시간> <지역> <건물> 롯데리아 <건물> 화재 발생. 인근 주민은 안전한 곳으로 대피하시기 바랍니다.\n",
      "\n",
      "🔹 [Pred] <시간>경 <지역> <주소> 삼성화재 <건물> 화재로 연기 발생. 주민은 안전사고 안전에 유의 바랍니다\n",
      "🔸 [True] 오늘 <시간>경 <지역> <주소> 삼성화재 <건물> 화재로 연기 발생. 인근 주민은 안전에 유의 바랍니다.\n",
      "\n",
      "🔹 [Pred] <시간> <도로>가 화재로 인해 통제중이오니 인근 차량 주민은 주시기 주시기 바랍니다.\n",
      "🔸 [True] 오늘 <시간> <도로>가 화재로 인해 차량 통제중이오니 인근 차량은 우회하여 주시기 바랍니다.\n",
      "\n",
      "\n",
      "🟩 [Validation Samples]\n",
      "🔹 [Pred] <시간> <역>에 화재, 발생, 주민은 닫아주시고 닫아주시고 안전사고에 유의 바랍니다\n",
      "🔸 [True] 5.23. <시간> <지역> <건물> <건물> 지하주차장 화재로 인해 차량통제 중임을 알려드립니다.\n",
      "\n",
      "🔹 [Pred] <시간> <지역> <주소> <건물> 화재 발생.. 기기 바랍니다 바랍니다 우회하여 바랍니다.\n",
      "🔸 [True] 5.23. <시간> <지역> <건물> <건물> 지하주차장 화재로 인해 차량통제 중임을 알려드립니다.\n",
      "\n",
      "🔹 [Pred] <시간> <역> 인근 <건물> 화재 발생, 인근 주민은 닫아주시고 안전사고에 유의 바랍니다\n",
      "🔸 [True] 5.23. <시간> <지역> <건물> <건물> 지하주차장 화재로 인해 차량통제 중임을 알려드립니다.\n",
      "\n",
      "🔹 [Pred] <주소> 차량통제<건물> 화재 발생으로 주민은 안전한 곳으로 안전한 대피하시기 바랍니다.\n",
      "🔸 [True] 오늘 <시간> 반월공단 내 대림비앤코 화재로 인해 차량통행 불가하오니 우회하여 주시기 바랍니다.\n",
      "\n",
      "🔹 [Pred] <시간> <지역> <건물> 화재로  고 <도로>가 통제 발생하였으니 발생하였으니 우회하여 바랍니다.\n",
      "🔸 [True] 오늘 <시간> 반월공단 내 대림비앤코 화재로 인해 차량통행 불가하오니 우회하여 주시기 바랍니다.\n",
      "\n",
      "[Epoch 1] Val Loss: 3.4670 | BLEU: 0.2032 | METEOR: 0.3541 | ROUGE: 0.0000\n",
      "✅ Best model saved at epoch 1 (BLEU=0.2032)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 2] Training: 100%|██████████| 2487/2487 [02:18<00:00, 18.02it/s, train_loss=0.342]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🟦 [Train Samples]\n",
      "🔹 [Pred] <시간> <지역> <주소> SM 오피스텔 화재 발생. 인근 안전에 바랍니다\n",
      "🔸 [True] 오늘 <시간> <지역> <주소> SM 오피스텔 <건물> 화재 발생. 안전에 유의 바랍니다\n",
      "\n",
      "🔹 [Pred] 현재 <산> 일대 대형화재발생, <도로>를 시민들께서는 를 바랍니다.\n",
      "🔸 [True] 오늘 현재 <산> 일대 대형화재발생, <산> 인근 시민들께서는 <도로>를 이용하시기 바랍니다.\n",
      "\n",
      "🔹 [Pred] <시간>경 <지역> <산>가산길 <주소> 화재발생, 인근 주민은 안전에 유의하기 바랍니다.\n",
      "🔸 [True] 오늘 <시간>경 <지역> <산>가산길 <주소> 화재발생, 인근 주민은 안전에 유의하기 바랍니다.\n",
      "\n",
      "🔹 [Pred] <시간> <지역> <지역> <건물> 상가 화재 발생. 인근 주민은 안전사고 발생에 유의 바랍니다\n",
      "🔸 [True] 오늘 <시간> <지역> <지역> <건물> 상가 화재 발생. 인근 주민은 안전사고 발생에 유의 바랍니다.\n",
      "\n",
      "🔹 [Pred] <시간> <지역> <주소> 화재 발생. 인근 주민은 안전에 유의 바랍니다.\n",
      "🔸 [True] 오늘 <시간> <지역> <주소> 화재 발생. 인근 주민은 안전사고에 유의 바랍니다.\n",
      "\n",
      "\n",
      "🟩 [Validation Samples]\n",
      "🔹 [Pred] <시간> <역> 화재 발생, 인근 주민은 창문을 닫아주시고 안전사고에 유의 바랍니다.\n",
      "🔸 [True] 5.23. <시간> <지역> <건물> <건물> 지하주차장 화재로 인해 차량통제 중임을 알려드립니다.\n",
      "\n",
      "🔹 [Pred] <시간> <지역> <지역> <건물> 인근에서 발생..  주민들은 발생에 유의 바랍니다.\n",
      "🔸 [True] 5.23. <시간> <지역> <건물> <건물> 지하주차장 화재로 인해 차량통제 중임을 알려드립니다.\n",
      "\n",
      "🔹 [Pred] <시간> <역> 인근 <건물> 화재발생, 인근 주민은 닫아주시고 안전에 바랍니다.\n",
      "🔸 [True] 5.23. <시간> <지역> <건물> <건물> 지하주차장 화재로 인해 차량통제 중임을 알려드립니다.\n",
      "\n",
      "🔹 [Pred] <시간> <주소> 대형화재 발생, 인근 주민은 안전한 곳으로 대피하시기 바랍니다.\n",
      "🔸 [True] 오늘 <시간> 반월공단 내 대림비앤코 화재로 인해 차량통행 불가하오니 우회하여 주시기 바랍니다.\n",
      "\n",
      "🔹 [Pred] <시간>경<지역> <지역> <건물> 화재로, 주민들은 주민들은 발생에 유의 바랍니다.\n",
      "🔸 [True] 오늘 <시간> 반월공단 내 대림비앤코 화재로 인해 차량통행 불가하오니 우회하여 주시기 바랍니다.\n",
      "\n",
      "[Epoch 2] Val Loss: 3.6630 | BLEU: 0.2268 | METEOR: 0.3920 | ROUGE: 0.0000\n",
      "✅ Best model saved at epoch 2 (BLEU=0.2268)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 3] Training: 100%|██████████| 2487/2487 [02:15<00:00, 18.35it/s, train_loss=0.278]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🟦 [Train Samples]\n",
      "🔹 [Pred] <시간> <지역> <주소> 화재 발생. 이 지역을 우회하여 주시고 인근 주민은 안전사고 발생에 유의 바랍니다.\n",
      "🔸 [True] 오늘 <시간> <지역> <주소> 화재 발생. 이 지역을 우회하여 주시고 인근 주민은 안전사고 발생에 유의 바랍니다.\n",
      "\n",
      "🔹 [Pred] <지역> 내 대형화재 발생, 인근 지역 주민께서는 유의 바랍니다\n",
      "🔸 [True] 현재 <지역> 내 대형화재 발생, 인근 지역 주민께서는 안전에 유의 바랍니다\n",
      "\n",
      "🔹 [Pred] <시간> <지역> 삼환아르누보 <건물> 화재 발생. 이 지역을 우회하여 주시고 인근 주민은 안전사고 발생에 유의 바랍니다.\n",
      "🔸 [True] 오늘 <시간> <지역> 삼환아르누보 <건물> 화재 발생. 이 지역을 우회하여 주시고 인근 주민은 안전사고 발생에 유의 바랍니다.\n",
      "\n",
      "🔹 [Pred] <시간> <지역> <주소> 송유관공사 화재 발생. 인근 주민은 안전한 곳으로 대피하시기 바랍니다.\n",
      "🔸 [True] 오늘 <시간> <지역> <주소> 송유관공사 화재 발생. 인근 주민은 안전한 곳으로 대피하시기 바랍니다.\n",
      "\n",
      "🔹 [Pred] <시간> <지역> <주소> <건물> 화재발생. 인근 주민은 안전사고에 유의 바랍니다.\n",
      "🔸 [True] 오늘 <시간> <지역> <주소> <건물> 화재발생. 인근 주민은 안전사고에 유의 바랍니다.\n",
      "\n",
      "\n",
      "🟩 [Validation Samples]\n",
      "🔹 [Pred] <시간> 화재 발생으로 인근, 주민은에 계신분 신속 발생에 유의 바랍니다.\n",
      "🔸 [True] 5.23. <시간> <지역> <건물> <건물> 지하주차장 화재로 인해 차량통제 중임을 알려드립니다.\n",
      "\n",
      "🔹 [Pred] <시간> <지역> <지역> <건물>. 발생. 통행이기 위 있으니, 바랍니다.\n",
      "🔸 [True] 5.23. <시간> <지역> <건물> <건물> 지하주차장 화재로 인해 차량통제 중임을 알려드립니다.\n",
      "\n",
      "🔹 [Pred] <시간> <도로> 화재 발생, 화재전동을 화재, 인근 주민은 안전사고에 유의 바랍니다.\n",
      "🔸 [True] 5.23. <시간> <지역> <건물> <건물> 지하주차장 화재로 인해 차량통제 중임을 알려드립니다.\n",
      "\n",
      "🔹 [Pred] <시간> <도로> 화재 발생 주민은 인근 주민은 안전한 곳으로.\n",
      "🔸 [True] 오늘 <시간> 반월공단 내 대림비앤코 화재로 인해 차량통행 불가하오니 우회하여 주시기 바랍니다.\n",
      "\n",
      "🔹 [Pred] <시간>경 <지역> <건물> 화재로, 교통이 발생하였으니 안전사고 유의 바랍니다.\n",
      "🔸 [True] 오늘 <시간> 반월공단 내 대림비앤코 화재로 인해 차량통행 불가하오니 우회하여 주시기 바랍니다.\n",
      "\n",
      "[Epoch 3] Val Loss: 3.7028 | BLEU: 0.2413 | METEOR: 0.4095 | ROUGE: 0.0000\n",
      "✅ Best model saved at epoch 3 (BLEU=0.2413)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 4] Training: 100%|██████████| 2487/2487 [02:16<00:00, 18.28it/s, train_loss=0.271]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🟦 [Train Samples]\n",
      "🔹 [Pred] <시간> 하양마을 인근에서 화재 발생, 인근 주민은 안전한 곳으로 대피바랍니다\n",
      "🔸 [True] 오늘 <시간> 현재 하양마을 인근에서 화재 사고발생, 인근 주민은 안전한 곳으로 대피바랍니다.\n",
      "\n",
      "🔹 [Pred] 점→석포 <도로> <지역> 화재 사고 처리가  ⁇  되어 교통통제구간을 해제하오니 참고하시기 바랍니다.\n",
      "🔸 [True] 동점→석포 <도로> <지역> 화재 사고 처리가 <지역> 되어 교통통제구간을 해제하오니 참고하시기 바랍니다.\n",
      "\n",
      "🔹 [Pred] <시간> <지역> 계양마을 인근에서 발생한 화재 잔화정리로 연기가 많이 나고 있으니 주민은 대피바랍니다.\n",
      "🔸 [True] 오늘 <시간> <지역> 계양마을 인근에서 발생한 화재 잔화정리로 연기가 많이 나고 있으니 인근 주민은 대피바랍니다.\n",
      "\n",
      "🔹 [Pred] <시간> <지역> <지역> <주소>에 발생한 화재 진압중. 인근 주민은 안전사고 발생에 유의 바랍니다.\n",
      "🔸 [True] 오늘 <시간> <지역> <지역> <주소>에 발생한 화재 진압중. 인근 주민은 안전사고 발생에 유의 바랍니다.\n",
      "\n",
      "🔹 [Pred] <시간> <지역> <주소>에서 화재사고 발생. <산> 및 주변상황 예주시팜에 유의 바랍니다\n",
      "🔸 [True] 오늘 <시간> <지역> <주소>에서 화재사고 발생. <산> 및 주변상황 예의주시로 안전사고 발생에 유의 바랍니다\n",
      "\n",
      "\n",
      "🟩 [Validation Samples]\n",
      "🔹 [Pred] <시간> <주소> 화재발생, 인근 건물 화재 발생 차량통제 인명 발생에 유의 바랍니다\n",
      "🔸 [True] 5.23. <시간> <지역> <건물> <건물> 지하주차장 화재로 인해 차량통제 중임을 알려드립니다.\n",
      "\n",
      "🔹 [Pred] <시간> <지역> <지역> <건물>. 발생. 지역을나는 우회하여 주시기 바랍니다\n",
      "🔸 [True] 5.23. <시간> <지역> <건물> <건물> 지하주차장 화재로 인해 차량통제 중임을 알려드립니다.\n",
      "\n",
      "🔹 [Pred] <시간> <산> 인근 1 건물화재, 화재. 주민은 주민은 등 안전에 유의 바랍니다.\n",
      "🔸 [True] 5.23. <시간> <지역> <건물> <건물> 지하주차장 화재로 인해 차량통제 중임을 알려드립니다.\n",
      "\n",
      "🔹 [Pred] <시간> <주소> 화재 발생, 인근 주민은 안전한 곳으로 대피하여 주시기 바랍니다\n",
      "🔸 [True] 오늘 <시간> 반월공단 내 대림비앤코 화재로 인해 차량통행 불가하오니 우회하여 주시기 바랍니다.\n",
      "\n",
      "🔹 [Pred] <시간>경 <지역>   에서 발생하였으니, 주민들은 발생한 우회하여 주시기 바랍니다.\n",
      "🔸 [True] 오늘 <시간> 반월공단 내 대림비앤코 화재로 인해 차량통행 불가하오니 우회하여 주시기 바랍니다.\n",
      "\n",
      "[Epoch 4] Val Loss: 3.6291 | BLEU: 0.2529 | METEOR: 0.4156 | ROUGE: 0.0000\n",
      "✅ Best model saved at epoch 4 (BLEU=0.2529)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 5] Training: 100%|██████████| 2487/2487 [02:15<00:00, 18.40it/s, train_loss=0.255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🟦 [Train Samples]\n",
      "🔹 [Pred] <시간> <지역><지역><주소> <주소> 대형화재발생으로 인근 주민은 안전에 유의 바랍니다.\n",
      "🔸 [True] 오늘 <시간> <지역> <주소> <주소> 대형화재발생으로 인근 주민은 안전에 유의하기 바랍니다.\n",
      "\n",
      "🔹 [Pred] <지역> <주소> 충정교  <건물> 화재 발생, 이 지역을 우회하여 주시고 주민은 안전사고 발생에 유의 바랍니다.\n",
      "🔸 [True] 현재 <지역> <주소> 충정교 인근 <건물> 화재 발생, 이 지역을 우회하여 주시고 인근 주민은 안전사고 발생에 유의 바랍니다.\n",
      "\n",
      "🔹 [Pred] <시간> <지역> <주소> <건물> <건물> 화재가 발생하였으니 인근 주민은 안전한 곳으로 바랍니다.\n",
      "🔸 [True] 오늘 <시간> <지역> <주소> <건물> <건물> 화재가 발생하였으니 인근 주민은 안전한 곳으로 대피 바랍니다.\n",
      "\n",
      "🔹 [Pred] <시간> <지역> 대형화재 발생. 인근 주민은 외출을 자제하는 등 안전사고에 유의 바랍니다\n",
      "🔸 [True] 오늘 <시간> <지역> 대형화재 발생. 인근 주민은 외출을 자제하는 등 안전사고에 유의 바랍니다\n",
      "\n",
      "🔹 [Pred] <시간> <역> 인근에서 발생한 화재 잔화정리로 연기가 발생되고 있으니 인근 주민께서는 유의 바랍니다.\n",
      "🔸 [True] 오늘 <시간> <역> 인근에서 발생한 화재 잔화정리로 연기가 발생되고 있으니 인근 주민께서는 유의 바랍니다.\n",
      "\n",
      "\n",
      "🟩 [Validation Samples]\n",
      "🔹 [Pred] <시간> <지역> 인근 화재발생, 인근 주민들께서는에 계신 창문을 등 안전에 유의.\n",
      "🔸 [True] 5.23. <시간> <지역> <건물> <건물> 지하주차장 화재로 인해 차량통제 중임을 알려드립니다.\n",
      "\n",
      "🔹 [Pred] <시간> <지역> 달동지 화재 발생. 이 지역을 우회하여 주시고, 바랍니다.\n",
      "🔸 [True] 5.23. <시간> <지역> <건물> <건물> 지하주차장 화재로 인해 차량통제 중임을 알려드립니다.\n",
      "\n",
      "🔹 [Pred] <시간> 발생한<지역> 1번출구사 부근84 화재<건물>, 발생 인근에 유의 유의 유의 바랍니다\n",
      "🔸 [True] 5.23. <시간> <지역> <건물> <건물> 지하주차장 화재로 인해 차량통제 중임을 알려드립니다.\n",
      "\n",
      "🔹 [Pred] <시간> <주소> 화재 발생, 인근 주민은 안전한 곳으로 대피하여 바랍니다.\n",
      "🔸 [True] 오늘 <시간> 반월공단 내 대림비앤코 화재로 인해 차량통행 불가하오니 우회하여 주시기 바랍니다.\n",
      "\n",
      "🔹 [Pred] <시간>경 <지역> <건물>에서 화재가 발생하였으니 인근 주민은 우회하여 바랍니다.\n",
      "🔸 [True] 오늘 <시간> 반월공단 내 대림비앤코 화재로 인해 차량통행 불가하오니 우회하여 주시기 바랍니다.\n",
      "\n",
      "[Epoch 5] Val Loss: 3.7314 | BLEU: 0.2443 | METEOR: 0.4167 | ROUGE: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 6] Training: 100%|██████████| 2487/2487 [02:15<00:00, 18.30it/s, train_loss=0.252]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🟦 [Train Samples]\n",
      "🔹 [Pred] <시간> <지역> <지역> <건물> 화재 발생 인근 주민은 안전사고 유의 유의 바랍니다\n",
      "🔸 [True] 오늘 <시간> <지역> <지역> <건물> 화재 발생, 인근 주민은 안전사고 발생에 유의 바랍니다\n",
      "\n",
      "🔹 [Pred] <시간> 반월공단 인근에서 발생한 화재 사고 수습으로 <도로> 혼잡하오니 바랍니다.\n",
      "🔸 [True] 오늘 <시간> 반월공단 인근에서 발생한 화재 사고 수습으로 <도로> 혼잡하오니 우회하시기 바랍니다.\n",
      "\n",
      "🔹 [Pred] <시간> <지역> <지역> <지역> <주소> <건물> 화재발생, 화재, 인근 주민은 안전에 유의 바랍니다.\n",
      "🔸 [True] 오늘 <시간> <지역> <지역> <지역> <주소> <건물> 화재 발생, 인근 주민은 안전에 유의 바랍니다.\n",
      "\n",
      "🔹 [Pred] 월 26일 <시간> <지역><도로> 발생으로 <도로>가 혼잡하오니, 우회하여 주시기 바랍니다\n",
      "🔸 [True] 7월 26일 <시간> <지역> <도로> 화재 발생으로 양방향 차량통제 하오니, 우회하여 주시기 바랍니다.\n",
      "\n",
      "🔹 [Pred] <시간>현재 <지역> <학교> 뒷편 <건물> 화재 발생 연기, 인근 주민은 안전에 유의 바랍니다\n",
      "🔸 [True] 오늘 <시간>경 <지역> <학교> 뒷편 <건물> 화재로 인근 주민은 안전사고 발생에 유의 바랍니다\n",
      "\n",
      "\n",
      "🟩 [Validation Samples]\n",
      "🔹 [Pred] <시간> <역>에 발생, 주민들께서는월9일 유의 바랍니다\n",
      "🔸 [True] 5.23. <시간> <지역> <건물> <건물> 지하주차장 화재로 인해 차량통제 중임을 알려드립니다.\n",
      "\n",
      "🔹 [Pred] <시간> <지역> <도로> 화재 발생, 인근 주민은 지역을 이용 주시기 바랍니다.\n",
      "🔸 [True] 5.23. <시간> <지역> <건물> <건물> 지하주차장 화재로 인해 차량통제 중임을 알려드립니다.\n",
      "\n",
      "🔹 [Pred] <시간> <지역> 롯데리아<역>, 화재 발생한에 유의.\n",
      "🔸 [True] 5.23. <시간> <지역> <건물> <건물> 지하주차장 화재로 인해 차량통제 중임을 알려드립니다.\n",
      "\n",
      "🔹 [Pred] <시간> <건물> 화재 발생. 인근 주민은 곳으로 안전한 대피하시기 바랍니다.\n",
      "🔸 [True] 오늘 <시간> 반월공단 내 대림비앤코 화재로 인해 차량통행 불가하오니 우회하여 주시기 바랍니다.\n",
      "\n",
      "🔹 [Pred] <시간> <지역><지역><건물> <도로> 화재. 주민은 주민들은 곳으로에서 바랍니다 바랍니다\n",
      "🔸 [True] 오늘 <시간> 반월공단 내 대림비앤코 화재로 인해 차량통행 불가하오니 우회하여 주시기 바랍니다.\n",
      "\n",
      "[Epoch 6] Val Loss: 3.6404 | BLEU: 0.2270 | METEOR: 0.3926 | ROUGE: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 7] Training: 100%|██████████| 2487/2487 [02:14<00:00, 18.50it/s, train_loss=0.241]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🟦 [Train Samples]\n",
      "🔹 [Pred] <시간> <지역> <건물> 화재 발생으로 연기 다수 발생. 인근 주민은 비상상황 발생에 유의 바랍니다.\n",
      "🔸 [True] 오늘 <시간> <지역> <건물> 화재 발생으로 연기 다수 발생. 인근 주민은 비상상황 발생에 유의 바랍니다.\n",
      "\n",
      "🔹 [Pred] <시간>부터 <지역> <지역> 부영3차 화재 발생, 인근 주민은 안전한 곳으로 대피하시기 바랍니다.\n",
      "🔸 [True] 오늘 <시간>부터 <지역> <지역> 부영3차 화재 발생, 인근 주민은 안전한 곳으로 대피하시기 바랍니다.\n",
      "\n",
      "🔹 [Pred] <시간> <지역> <건물>에서 화재 발생, 인근 주민은 안전에 유의 바랍니다.\n",
      "🔸 [True] 오늘 <시간> <지역> <건물>에서 화재 발생, 인근 주민은 안전에 유의 바랍니다.\n",
      "\n",
      "🔹 [Pred] <시간> <지역> <지역> <주소> 화재 발생. 주변으로 확산될 우려가 있으니 인근 주민은 안전한 곳으로 대피하시기 바랍니다.\n",
      "🔸 [True] 오늘 <시간> <지역> <지역> <주소> 화재 발생. 주변으로 확산될 우려가 있으니 인근 주민은 안전한 곳으로 대피하시기 바랍니다.\n",
      "\n",
      "🔹 [Pred] <시간> <도로> 화재 발생으로 <도로>가 혼잡하오니 차량을 우회하여 주시기 바랍니다.\n",
      "🔸 [True] 오늘 <시간> <도로> 화재 발생으로 <도로>가 혼잡하오니 차량을 우회하여 주시기 바랍니다.\n",
      "\n",
      "\n",
      "🟩 [Validation Samples]\n",
      "🔹 [Pred] <시간> <역> 화재 발생. 인근 주민은 차량 닫아주시고 안전사고에 유의 바랍니다.\n",
      "🔸 [True] 5.23. <시간> <지역> <건물> <건물> 지하주차장 화재로 인해 차량통제 중임을 알려드립니다.\n",
      "\n",
      "🔹 [Pred] <시간> <지역> <도로> 화재로 화재발생. 인근 주민은메뜰<주소> 주시기 바랍니다.\n",
      "🔸 [True] 5.23. <시간> <지역> <건물> <건물> 지하주차장 화재로 인해 차량통제 중임을 알려드립니다.\n",
      "\n",
      "🔹 [Pred] <시간>일<시간> <역> 인근 화재발생 서대문에 발생. 인명 발생에 유의 바랍니다.\n",
      "🔸 [True] 5.23. <시간> <지역> <건물> <건물> 지하주차장 화재로 인해 차량통제 중임을 알려드립니다.\n",
      "\n",
      "🔹 [Pred] <시간> <건물> 화재 발생. 인근 주민은 안전한 곳으로 대피하시기 바랍니다.\n",
      "🔸 [True] 오늘 <시간> 반월공단 내 대림비앤코 화재로 인해 차량통행 불가하오니 우회하여 주시기 바랍니다.\n",
      "\n",
      "🔹 [Pred] <시간>경<지역><지역><지역><건물> 화재로 인해서에서 발생하였으니 우회하여 인근 주민은 유의 바랍니다.\n",
      "🔸 [True] 오늘 <시간> 반월공단 내 대림비앤코 화재로 인해 차량통행 불가하오니 우회하여 주시기 바랍니다.\n",
      "\n",
      "[Epoch 7] Val Loss: 3.8326 | BLEU: 0.2608 | METEOR: 0.4440 | ROUGE: 0.0000\n",
      "✅ Best model saved at epoch 7 (BLEU=0.2608)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 8] Training: 100%|██████████| 2487/2487 [02:15<00:00, 18.31it/s, train_loss=0.257]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🟦 [Train Samples]\n",
      "🔹 [Pred] <시간> <지역> <지역> <주소> 화재 발생, 인근 주민은 안전사고 발생에 유의바랍니다.\n",
      "🔸 [True] 오늘 <시간> <지역> <지역> <주소> 화재 발생, 인근 주민은 안전사고 발생에 유의바랍니다.\n",
      "\n",
      "🔹 [Pred] <시간>경 <도로>에 화재가 발생하였으니 인근 주민께서는 안전에 유의 바랍니다\n",
      "🔸 [True] 오늘 <시간>경 <도로>에 화재가 발생하였으니 인근 주민께서는 안전에 유의 바랍니다\n",
      "\n",
      "🔹 [Pred] <시간> <지역> <지역> <주소> <건물> 화재 발생. 인근 주민은 안전한 곳으로 대피하는 등 안전에 유의 바랍니다.\n",
      "🔸 [True] 오늘 <시간> <지역> <지역> <주소> <건물> 화재 발생. 인근 주민은 안전한 곳으로 대피하는 등 안전에 유의 바랍니다.\n",
      "\n",
      "🔹 [Pred] <시간> <지역> <건물>에서 화재 발생, 인근 주민은 안전에 유의 바랍니다.\n",
      "🔸 [True] 오늘 <시간> <지역> <건물>에서 화재 발생, 인근 주민은 안전에 유의 바랍니다.\n",
      "\n",
      "🔹 [Pred] <시간> <지역> <지역> <주소> 인근 상가, <건물>, 농경지 등 화재발생 유의 바랍니다.\n",
      "🔸 [True] 오늘 <시간> <지역> <지역> <주소> 인근 상가, <건물>, 농경지 등 화재발생 유의 바랍니다.\n",
      "\n",
      "\n",
      "🟩 [Validation Samples]\n",
      "🔹 [Pred] <시간> <역> 인근 화재 발생, 인근 주민은 창문을 닫아주시고 안전사고에 유의 바랍니다\n",
      "🔸 [True] 5.23. <시간> <지역> <건물> <건물> 지하주차장 화재로 인해 차량통제 중임을 알려드립니다.\n",
      "\n",
      "🔹 [Pred] <시간> <지역> <도로> 화재발생.에서 발생하였으니 남 우회하여 주시기 바랍니다.\n",
      "🔸 [True] 5.23. <시간> <지역> <건물> <건물> 지하주차장 화재로 인해 차량통제 중임을 알려드립니다.\n",
      "\n",
      "🔹 [Pred] <시간>K통신구 화재발생, 인근 주민은에 공사장<학교> 고 안전에 바랍니다\n",
      "🔸 [True] 5.23. <시간> <지역> <건물> <건물> 지하주차장 화재로 인해 차량통제 중임을 알려드립니다.\n",
      "\n",
      "🔹 [Pred] <시간> <건물> 화재 발생 인근 주민은 주민은 곳으로 곳으로 대피하여 바랍니다.\n",
      "🔸 [True] 오늘 <시간> 반월공단 내 대림비앤코 화재로 인해 차량통행 불가하오니 우회하여 주시기 바랍니다.\n",
      "\n",
      "🔹 [Pred] <시간>경 <지역> <건물> 화재로 화재발생,  주민은 안전에 유의 바랍니다.\n",
      "🔸 [True] 오늘 <시간> 반월공단 내 대림비앤코 화재로 인해 차량통행 불가하오니 우회하여 주시기 바랍니다.\n",
      "\n",
      "[Epoch 8] Val Loss: 3.7164 | BLEU: 0.2590 | METEOR: 0.4371 | ROUGE: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 9] Training: 100%|██████████| 2487/2487 [02:13<00:00, 18.63it/s, train_loss=0.247]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🟦 [Train Samples]\n",
      "🔹 [Pred] <시간>경 <지역> <주소> 화재 발생, 인근 주민은 안전사고 발생에 유의 바랍니다\n",
      "🔸 [True] 오늘 <시간>경 <지역> <주소> 화재 발생, 인근 주민은 안전사고 발생에 유의 바랍니다.\n",
      "\n",
      "🔹 [Pred] <시간>경 <지역> <주소> 삼성화재 세종지점 화재 발생, 주민은 주민은 안전에 주의바람.\n",
      "🔸 [True] 오늘 <시간>경 <지역> <주소> 삼성화재 세종지점 화재 발생, 인근 주민은 안전에 유의하세요.\n",
      "\n",
      "🔹 [Pred] <시간>경 발생한<지역><지역> 인천교매매단지 상가화재에서 인근주민은 안전에 유의\n",
      "🔸 [True] 오늘 <시간>경 발생한 <지역> 인천교매매단지 상가화재에서 인근주민은 안전에 유의 바랍니다\n",
      "\n",
      "🔹 [Pred] 월04일 <시간> <지역> <주소> 광진케이블 공장 화재 발생, 인근 주민은 안전사고에 유의 하세요\n",
      "🔸 [True] 4월04일 <시간> <지역> <주소> 광진케이블 공장 화재 발생, 인근 주민은 안전사고에 유의 하세요\n",
      "\n",
      "🔹 [Pred] <시간> <지역> <산> 인근에서<주소> 화재 인근에서 발생한 수습으로 <도로>가 혼잡하오니 우회바랍니다\n",
      "🔸 [True] 오늘 <시간> <지역> <산><주소> <주소> 인근에서 발생한 화재 수습으로 <도로>가 혼잡하오니 우회바랍니다.\n",
      "\n",
      "\n",
      "🟩 [Validation Samples]\n",
      "🔹 [Pred] <시간> 청 8번지 발생 차량 화재 발생 인근 인근 안전사고에 닫아주시고 유의 바랍니다.\n",
      "🔸 [True] 5.23. <시간> <지역> <건물> <건물> 지하주차장 화재로 인해 차량통제 중임을 알려드립니다.\n",
      "\n",
      "🔹 [Pred] <시간> <지역> <도로> 화재로 발생. 인근 주민은 신속히 이동하시기 바랍니다.\n",
      "🔸 [True] 5.23. <시간> <지역> <건물> <건물> 지하주차장 화재로 인해 차량통제 중임을 알려드립니다.\n",
      "\n",
      "🔹 [Pred] <시간> 반여농산물시장 대형화재 발생 인근,<건물> 화재발생 유의 바랍니다\n",
      "🔸 [True] 5.23. <시간> <지역> <건물> <건물> 지하주차장 화재로 인해 차량통제 중임을 알려드립니다.\n",
      "\n",
      "🔹 [Pred] <시간> <주소> 대형화재 발생, 인근 주민은 안전한 곳으로 대피하여 주시기 바랍니다.\n",
      "🔸 [True] 오늘 <시간> 반월공단 내 대림비앤코 화재로 인해 차량통행 불가하오니 우회하여 주시기 바랍니다.\n",
      "\n",
      "🔹 [Pred] <시간>경 <지역> <건물> 화재로 위험을 <주소>, 인근 유의에서 발생하였으니 바랍니다.\n",
      "🔸 [True] 오늘 <시간> 반월공단 내 대림비앤코 화재로 인해 차량통행 불가하오니 우회하여 주시기 바랍니다.\n",
      "\n",
      "[Epoch 9] Val Loss: 3.5896 | BLEU: 0.2275 | METEOR: 0.4032 | ROUGE: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 10] Training: 100%|██████████| 2487/2487 [02:16<00:00, 18.23it/s, train_loss=0.236]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🟦 [Train Samples]\n",
      "🔹 [Pred] <시간> <지역> <지역> <주소> 화재 발생. 이 지역을 우회하여 주시고 인근 주민은 안전사고 발생에 유의 바랍니다.\n",
      "🔸 [True] 오늘 <시간> <지역> <지역> <주소> 화재 발생. 이 지역을 우회하여 주시고 인근 주민은 안전사고 발생에 유의 바랍니다.\n",
      "\n",
      "🔹 [Pred] <시간> <지역> <지역> <건물> 화재 발생. 인근 주민은 안전한 곳으로 대피하기 바랍니다.\n",
      "🔸 [True] 1.28 <시간> <지역> <지역> <건물> 화재 발생. 인근 주민은 안전한 곳으로 대피하기 바랍니다.\n",
      "\n",
      "🔹 [Pred] <시간> <지역> <지역> <지역> <주소> 공장 화재 발생, 인근 주민은 대피하시고, 차량은 우회 바랍니다.\n",
      "🔸 [True] 오늘 <시간> <지역> <지역> <지역> <주소> 공장 화재 발생, 인근 주민은 대피하시고, 차량은 우회 바랍니다.\n",
      "\n",
      "🔹 [Pred] . 오늘 <시간> <지역> 선박 화재 발생. 인근 주민은 안전한 곳으로 이동해 주시기 바랍니다.\n",
      "🔸 [True] 안전안내. 오늘 <시간> <지역> 선박 화재 발생. 인근 주민은 안전한 곳으로 이동해 주시기 바랍니다.\n",
      "\n",
      "🔹 [Pred] <시간> <지역> <지역> <주소> 인근 상가 화재 발생. 인근 주민은 창문을 닫아 주시기 바랍니다.\n",
      "🔸 [True] 오늘 <시간> <지역> <지역> <주소> 인근 상가 화재 발생. 인근 주민은 창문을 닫아 주시기 바랍니다.\n",
      "\n",
      "\n",
      "🟩 [Validation Samples]\n",
      "🔹 [Pred] <시간> <도로> 화재발생 발생, 인근 주민은 발생한 등산 안전에 유의 바랍니다.\n",
      "🔸 [True] 5.23. <시간> <지역> <건물> <건물> 지하주차장 화재로 인해 차량통제 중임을 알려드립니다.\n",
      "\n",
      "🔹 [Pred] <시간> <지역> <건물> 화재 발생. 인근 확산될 우려가 있으니 우회하시기 바랍니다.\n",
      "🔸 [True] 5.23. <시간> <지역> <건물> <건물> 지하주차장 화재로 인해 차량통제 중임을 알려드립니다.\n",
      "\n",
      "🔹 [Pred] <시간> <지역> 인근 화재발생, 인근<건물> 주민들은 안전에 유의 바랍니다.\n",
      "🔸 [True] 5.23. <시간> <지역> <건물> <건물> 지하주차장 화재로 인해 차량통제 중임을 알려드립니다.\n",
      "\n",
      "🔹 [Pred] <시간>  화재발생8 화재 인근 주민은 화재, 일원 유의바랍니다 주민들은 대피하시기 바랍니다.\n",
      "🔸 [True] 오늘 <시간> 반월공단 내 대림비앤코 화재로 인해 차량통행 불가하오니 우회하여 주시기 바랍니다.\n",
      "\n",
      "🔹 [Pred] <시간>경 <지역> <건물> 화재로 우회바랍니다, 인근 주민은 안전에 유의 바랍니다.\n",
      "🔸 [True] 오늘 <시간> 반월공단 내 대림비앤코 화재로 인해 차량통행 불가하오니 우회하여 주시기 바랍니다.\n",
      "\n",
      "[Epoch 10] Val Loss: 3.7541 | BLEU: 0.2772 | METEOR: 0.4584 | ROUGE: 0.0000\n",
      "✅ Best model saved at epoch 10 (BLEU=0.2772)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 16] Training: 100%|██████████| 2487/2487 [02:15<00:00, 18.35it/s, train_loss=0.258]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🟦 [Train Samples]\n",
      "🔹 [Pred] <시간> <지역> <지역> 물류창고 공사장 화재 다량의 연기가 발생. 인근 주민은 대피 바랍니다.\n",
      "🔸 [True] 오늘 <시간> <지역> <지역> 물류창고 공사장 화재로 다량의 연기가 발생. 인근 주민은 대피 바랍니다.\n",
      "\n",
      "🔹 [Pred] <시간> <지역> 광장동에서 <건물> 화재 발생. 인근 주민은 안전에 유의하세요!\n",
      "🔸 [True] 오늘 <시간> <지역> 광장동에서 <건물> 화재 발생. 인근 주민은 안전에 유의하세요!\n",
      "\n",
      "🔹 [Pred] <시간> <지역> 염포부두 선박화재 발생. 주민들께서는 화재로 발생하지않도록 주의바랍니다.\n",
      "🔸 [True] 오늘 <시간> <지역> 염포부두 선박화재 발생. 주민들께서는 화재연기로 인한 피해가 발생하지 않도록 주의바랍니다.\n",
      "\n",
      "🔹 [Pred] <지역> 선박화재 현장 수습으로 다량의 연기가 발생하고있으니 인근 주민은 대피하여 주시기 바랍니다.\n",
      "🔸 [True] 현재 <지역> 선박화재 현장 수습으로 다량의 연기가 발생하고있으니 인근 주민은 대피하여 주시기 바랍니다.\n",
      "\n",
      "🔹 [Pred] <시간> <지역> 봉길마을 <주소> 인근에서 화재 발생으로 인근 주민은 안전사고에 유의 바랍니다.\n",
      "🔸 [True] 오늘 <시간> <지역> 봉길마을 <주소> 인근에서 화재 발생으로 인근 주민은 안전사고에 유의 바랍니다.\n",
      "\n",
      "\n",
      "🟩 [Validation Samples]\n",
      "🔹 [Pred] <시간> <도로> 화재 발생. 인근 주민은 발생한 닫아주시고 등 안전에 바랍니다.\n",
      "🔸 [True] 5.23. <시간> <지역> <건물> <건물> 지하주차장 화재로 인해 차량통제 중임을 알려드립니다.\n",
      "\n",
      "🔹 [Pred] <시간> <지역> <지역> <건물> 화재 발생. 이 지역을 우회하여 주시고 주시기 바랍니다.\n",
      "🔸 [True] 5.23. <시간> <지역> <건물> <건물> 지하주차장 화재로 인해 차량통제 중임을 알려드립니다.\n",
      "\n",
      "🔹 [Pred] <시간> <지역> 선박 화재 발생. 인근 주민은 안전에 발생에 유의 바랍니다\n",
      "🔸 [True] 5.23. <시간> <지역> <건물> <건물> 지하주차장 화재로 인해 차량통제 중임을 알려드립니다.\n",
      "\n",
      "🔹 [Pred] <시간> <건물> 화재 발생. 인근 주민은 안전한 곳으로 대피하시기 바랍니다.\n",
      "🔸 [True] 오늘 <시간> 반월공단 내 대림비앤코 화재로 인해 차량통행 불가하오니 우회하여 주시기 바랍니다.\n",
      "\n",
      "🔹 [Pred] <시간>경 <지역> <산>의 화재발생에 발생, 주민들은 창문을 닫아 주시기 바랍니다.\n",
      "🔸 [True] 오늘 <시간> 반월공단 내 대림비앤코 화재로 인해 차량통행 불가하오니 우회하여 주시기 바랍니다.\n",
      "\n",
      "[Epoch 16] Val Loss: 3.7174 | BLEU: 0.2736 | METEOR: 0.4552 | ROUGE: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 17] Training: 100%|██████████| 2487/2487 [02:13<00:00, 18.63it/s, train_loss=0.226]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🟦 [Train Samples]\n",
      "🔹 [Pred] <시간> <산> <지역> <주소> 화재 발생, 인근 주민은 안전에 유의 바랍니다.\n",
      "🔸 [True] 오늘 <시간> <산> <지역> <주소> 화재 발생, 인근 주민은 안전에 유의 바랍니다.\n",
      "\n",
      "🔹 [Pred] <시간> <지역> <건물> <건물> 화재 발생, 인근 주민은 안전에 유의하시길 바랍니다.\n",
      "🔸 [True] 오늘 <시간> <지역> <건물> <건물> 화재 발생, 인근 주민은 안전에 유의하시길 바랍니다.\n",
      "\n",
      "🔹 [Pred] <시간> <지역> 계양마을 인근에서 발생한 화재 잔화정리로 연기가 많이 나고 있으니 인근 주민은 대피바랍니다.\n",
      "🔸 [True] 오늘 <시간> <지역> 계양마을 인근에서 발생한 화재 잔화정리로 연기가 많이 나고 있으니 인근 주민은 대피바랍니다.\n",
      "\n",
      "🔹 [Pred] <시간>경 <지역> <주소> <건물> 화재 발생, 인근 주민은 안전에 유의 바랍니다\n",
      "🔸 [True] 오늘 <시간>경 <지역> <주소> <건물> 화재 발생, 인근 주민은 안전에 유의 바랍니다\n",
      "\n",
      "🔹 [Pred] <시간> 반월공단 내 대림비앤코 화재로 검은연기 발생. 인근 시민은 안전사고 발생에 유의 바랍니다\n",
      "🔸 [True] 오늘 <시간> 반월공단 내 대림비앤코 화재로 검은연기 발생. 인근 시민은 안전사고 발생에 유의 바랍니다\n",
      "\n",
      "\n",
      "🟩 [Validation Samples]\n",
      "🔹 [Pred] <시간> <도로> 화재 발생, 인근 주민은 안전에 유의 바랍니다.\n",
      "🔸 [True] 5.23. <시간> <지역> <건물> <건물> 지하주차장 화재로 인해 차량통제 중임을 알려드립니다.\n",
      "\n",
      "🔹 [Pred] <시간> <지역> <지역> <건물> 화재 발생. 이 주민은 우회하여 주시기 바랍니다.\n",
      "🔸 [True] 5.23. <시간> <지역> <건물> <건물> 지하주차장 화재로 인해 차량통제 중임을 알려드립니다.\n",
      "\n",
      "🔹 [Pred] <시간> <지역> 인근 화재 발생. 인근 주민은 안전에 유의 바랍니다.\n",
      "🔸 [True] 5.23. <시간> <지역> <건물> <건물> 지하주차장 화재로 인해 차량통제 중임을 알려드립니다.\n",
      "\n",
      "🔹 [Pred] <시간> <건물> 화재 발생으로 인근 주민은 안전한 곳으로 대피하여 주시기 바랍니다.\n",
      "🔸 [True] 오늘 <시간> 반월공단 내 대림비앤코 화재로 인해 차량통행 불가하오니 우회하여 주시기 바랍니다.\n",
      "\n",
      "🔹 [Pred] <시간>경 <지역> <지역> <도로> 화재 발생 인근 주민은 우회하여 롯데리아 유의 바랍니다\n",
      "🔸 [True] 오늘 <시간> 반월공단 내 대림비앤코 화재로 인해 차량통행 불가하오니 우회하여 주시기 바랍니다.\n",
      "\n",
      "[Epoch 17] Val Loss: 3.7682 | BLEU: 0.2936 | METEOR: 0.4689 | ROUGE: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 18] Training: 100%|██████████| 2487/2487 [02:15<00:00, 18.32it/s, train_loss=0.264]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🟦 [Train Samples]\n",
      "🔹 [Pred] <시간> <지역> <주소> <건물> 화재 발생. 인근 주민은 안전사고에 유의 바랍니다.\n",
      "🔸 [True] 오늘 <시간> <지역> <주소> <건물> 화재 발생. 인근 주민은 안전사고에 유의 바랍니다.\n",
      "\n",
      "🔹 [Pred] <시간> <주소>역 1번출구 인근 전주폐차장에서 화재 발생으로 주변 교통이 혼잡하오니 퇴근길 안전에  ⁇ 히 유의 바랍니다\n",
      "🔸 [True] 오늘 <시간> <주소>역 1번출구 인근 전주폐차장에서 화재 발생으로 주변 교통이 혼잡하오니 퇴근길 안전에  ⁇ 히 유의 바랍니다\n",
      "\n",
      "🔹 [Pred] <시간> <지역> <지역> <건물> 상가 화재 발생. 인근 주민은 안전사고 발생에 유의 바랍니다.\n",
      "🔸 [True] 오늘 <시간> <지역> <지역> <건물> 상가 화재 발생. 인근 주민은 안전사고 발생에 유의 바랍니다.\n",
      "\n",
      "🔹 [Pred] <시간> <지역> <지역> 모토고개 <주소> 재활용공장 화재 발생으로 인근 주민들은 안전사고 발생에 유의 바랍니다.\n",
      "🔸 [True] 오늘 <시간> <지역> <지역> 모토고개 <주소> 재활용공장 화재 발생으로 인근 주민들은 안전사고 발생에 유의 바랍니다.\n",
      "\n",
      "🔹 [Pred] <시간> <지역> 봉강저수지 <도로> 화재 발생. 인근 주민은 안전사고에 유의 바랍니다\n",
      "🔸 [True] <시간> <지역> 봉강저수지 <도로> 화재 발생. 인근 주민은 안전사고에 유의 바랍니다\n",
      "\n",
      "\n",
      "🟩 [Validation Samples]\n",
      "🔹 [Pred] <시간> <역> 화재 발생, 인근 주민은 안전에 발생에 유의 바랍니다\n",
      "🔸 [True] 5.23. <시간> <지역> <건물> <건물> 지하주차장 화재로 인해 차량통제 중임을 알려드립니다.\n",
      "\n",
      "🔹 [Pred] <시간> <지역> <지역> <건물> 화재 발생. 이<도로> 이용하여 주시기 바랍니다.\n",
      "🔸 [True] 5.23. <시간> <지역> <건물> <건물> 지하주차장 화재로 인해 차량통제 중임을 알려드립니다.\n",
      "\n",
      "🔹 [Pred] <시간> 발생한<역>K통신구 화재 잔화정리로, 인근 주민은 안전에 유의 바랍니다\n",
      "🔸 [True] 5.23. <시간> <지역> <건물> <건물> 지하주차장 화재로 인해 차량통제 중임을 알려드립니다.\n",
      "\n",
      "🔹 [Pred] <시간> <주소> 화재 발생, 인근 주민은 안전한 곳으로 대피하여 주시기 바랍니다.\n",
      "🔸 [True] 오늘 <시간> 반월공단 내 대림비앤코 화재로 인해 차량통행 불가하오니 우회하여 주시기 바랍니다.\n",
      "\n",
      "🔹 [Pred] <시간>경,<지역> <건물> <학교>에서  공사장 안전유의마을 유의 바랍니다\n",
      "🔸 [True] 오늘 <시간> 반월공단 내 대림비앤코 화재로 인해 차량통행 불가하오니 우회하여 주시기 바랍니다.\n",
      "\n",
      "[Epoch 18] Val Loss: 3.7349 | BLEU: 0.2759 | METEOR: 0.4557 | ROUGE: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 19] Training: 100%|██████████| 2487/2487 [02:15<00:00, 18.35it/s, train_loss=0.25] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🟦 [Train Samples]\n",
      "🔹 [Pred] <시간> 구 화장터 화재로 인해 범어로 일대 교통이 정체되고 있으니 우회하여 주시기 바랍니다\n",
      "🔸 [True] 오늘 <시간> 구 화장터 화재로 인해 범어로 일대 교통이 정체되고 있으니 우회하여 주시기 바랍니다.\n",
      "\n",
      "🔹 [Pred] <시간> 발생한 <지역> 공장화재 사고 수습으로 수습으로<도로>혼잡하 안전사고에 바랍니다 유의\n",
      "🔸 [True] 오늘 <시간> 발생한 <지역> <지역> 공장화재 사고 수습으로 <도로>혼잡하니 안전사고에 유의 바랍니다\n",
      "\n",
      "🔹 [Pred] <시간>현재 <역> 인근 <건물> 화재 발생, 인근 주민은 안전한 곳으로 대피하시기 바랍니다.\n",
      "🔸 [True] <시간>현재 <역> 인근 <건물> 화재 발생, 인근 주민은 안전한 곳으로 대피하시기 바랍니다.\n",
      "\n",
      "🔹 [Pred] <시간> 동광교 공사장 공사장 화재로 발생. 인근 주민들은 안전에 유의 바랍니다\n",
      "🔸 [True] 오늘<시간> 동광교 인근 공사장 화재로 다량의 연기가 발생. 인근 주민은 안전에 유의 바랍니다.\n",
      "\n",
      "🔹 [Pred] <지역> 대화공단내 대형화재 발생, 출근길 교통혼잡이 예상되오니 대중교통을 이용하시기 바랍니다.\n",
      "🔸 [True] 현재 <지역> 대화공단내 대형화재 발생, 출근길 교통혼잡이 예상되오니 대중교통을 이용하시기 바랍니다.\n",
      "\n",
      "\n",
      "🟩 [Validation Samples]\n",
      "🔹 [Pred] <시간> <역>에 화재, 인근 주민은 창문을 닫아주시고 안전에 유의 바랍니다.\n",
      "🔸 [True] 5.23. <시간> <지역> <건물> <건물> 지하주차장 화재로 인해 차량통제 중임을 알려드립니다.\n",
      "\n",
      "🔹 [Pred] <시간> <지역> <지역> 화재 발생. 이 지역을 우회하여 주시고 롯데리아 주민은 유의 바랍니다.\n",
      "🔸 [True] 5.23. <시간> <지역> <건물> <건물> 지하주차장 화재로 인해 차량통제 중임을 알려드립니다.\n",
      "\n",
      "🔹 [Pred] <시간> <지역>K통신구에 발생하였으니, 주민들께서는 창문을 안전에 바랍니다..\n",
      "🔸 [True] 5.23. <시간> <지역> <건물> <건물> 지하주차장 화재로 인해 차량통제 중임을 알려드립니다.\n",
      "\n",
      "🔹 [Pred] <시간> <주소> 화재 발생으로 인근 주민은 안전한 곳으로 대피하여 화재가 대피하시기 바랍니다.\n",
      "🔸 [True] 오늘 <시간> 반월공단 내 대림비앤코 화재로 인해 차량통행 불가하오니 우회하여 주시기 바랍니다.\n",
      "\n",
      "🔹 [Pred] <시간>경 <지역> <산>에서 발생, 인근 주민들은 창문을 닫아주시고 우회바랍니다.\n",
      "🔸 [True] 오늘 <시간> 반월공단 내 대림비앤코 화재로 인해 차량통행 불가하오니 우회하여 주시기 바랍니다.\n",
      "\n",
      "[Epoch 19] Val Loss: 3.6319 | BLEU: 0.2500 | METEOR: 0.4239 | ROUGE: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 20] Training: 100%|██████████| 2487/2487 [02:14<00:00, 18.49it/s, train_loss=0.244]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🟦 [Train Samples]\n",
      "🔹 [Pred] <지역> 658번지 인근 <건물> 화재가 발생하였으니 남산로 일대 차량통행을 자제하시기 바랍니다.\n",
      "🔸 [True] 현재 <지역> 658번지 인근 <건물> 화재가 발생하였으니 남산로 일대 차량통행을 자제하시기 바랍니다.\n",
      "\n",
      "🔹 [Pred] <시간> <지역> <주소> 화재 발생. 인근 주민은 대피 및 차량운행을 자제하기 바랍니다\n",
      "🔸 [True] 오늘 <시간> <지역> <주소> 화재 발생. 인근 주민은 대피 및 차량운행을 자제하기 바랍니다.\n",
      "\n",
      "🔹 [Pred] .24 <시간> <지역> <지역> 56번길 화재 발생. 인근 주민은 안전한 곳으로 대피하여 주시기 바랍니다.\n",
      "🔸 [True] 4.24 <시간> <지역> <지역> 56번길 화재 발생. 인근 주민은 안전한 곳으로 대피하여 주시기 바랍니다.\n",
      "\n",
      "🔹 [Pred] <시간> <지역> <도로> 양구리구간 화재 발생, 인근 주민은 안전한 곳으로 대피 바랍니다.\n",
      "🔸 [True] 오늘 <시간> <지역> <도로> 양구리구간 화재 발생, 인근 주민은 안전한 곳으로 대피 바랍니다.\n",
      "\n",
      "🔹 [Pred] .29 <시간> 부로 <지역> <주소> 화재 발생, 인근 주민은 안전한 곳으로 대피 바람\n",
      "🔸 [True] 7.29 <시간> 부로 <지역> <주소> 화재 발생, 인근 주민은 안전한 곳으로 대피 바람\n",
      "\n",
      "\n",
      "🟩 [Validation Samples]\n",
      "🔹 [Pred] <시간> 발생한<역>에 화재 발생 발생 인근 주민은 안전에 유의 바랍니다.\n",
      "🔸 [True] 5.23. <시간> <지역> <건물> <건물> 지하주차장 화재로 인해 차량통제 중임을 알려드립니다.\n",
      "\n",
      "🔹 [Pred] <시간> <지역> <주소> 화재 발생. 인근 주민은<역> 지역을 우회하여 주시기 바랍니다.\n",
      "🔸 [True] 5.23. <시간> <지역> <건물> <건물> 지하주차장 화재로 인해 차량통제 중임을 알려드립니다.\n",
      "\n",
      "🔹 [Pred] <시간> <역>에 화재가 발생하였으니, 인근 주민은 안전에 유의 바랍니다\n",
      "🔸 [True] 5.23. <시간> <지역> <건물> <건물> 지하주차장 화재로 인해 차량통제 중임을 알려드립니다.\n",
      "\n",
      "🔹 [Pred] <시간> <주소> <건물> 화재 발생, 인근 주민은 안전한 곳으로 대피하여 주시기 바랍니다.\n",
      "🔸 [True] 오늘 <시간> 반월공단 내 대림비앤코 화재로 인해 차량통행 불가하오니 우회하여 주시기 바랍니다.\n",
      "\n",
      "🔹 [Pred] <시간> <지역> <건물> <건물> 화재 발생, 인근 주민들은 안전에 유의 바랍니다.\n",
      "🔸 [True] 오늘 <시간> 반월공단 내 대림비앤코 화재로 인해 차량통행 불가하오니 우회하여 주시기 바랍니다.\n",
      "\n",
      "[Epoch 20] Val Loss: 3.8131 | BLEU: 0.2902 | METEOR: 0.4685 | ROUGE: 0.0016\n",
      "🛑 Early stopping triggered. Best BLEU: 0.3073\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if device.type == \"cuda\":\n",
    "    print(\"✅ Using device:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"⚠️ Using CPU\")\n",
    "\n",
    "PAD_ID = 3  # ✅ 반드시 vocab과 일치해야 함\n",
    "\n",
    "train_with_early_stopping(\n",
    "    model=model.to(device),\n",
    "    train_loader=train_loader,\n",
    "    val_loader=get_validation_loader(\"/teamspace/studios/this_studio/training/val/processed\"),\n",
    "    tokenizer=spm_tokenizer,\n",
    "    optimizer=torch.optim.Adam(model.parameters(), lr=1e-3),\n",
    "    criterion = LabelSmoothingLoss(label_smoothing=0.1, tgt_vocab_size=spm_tokenizer.vocab_size(), ignore_index=PAD_ID),\n",
    "    # criterion = nn.CrossEntropyLoss(ignore_index=PAD_ID),\n",
    "    device=device,\n",
    "    num_epochs=30,\n",
    "    teacher_forcing_ratio=0.5,\n",
    "    clip=1.0,\n",
    "    save_path=\"best_model.pt\",\n",
    "    early_stopping_patience=5,\n",
    "    checkpoint_dir=\"checkpoints\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4af0908b-adba-406f-b58a-5468a3c47b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁주시기', '▁바랍니다']\n",
      "['▁양해', '▁바랍니다']\n",
      "['▁화재', '▁발생으로', '▁인해']\n"
     ]
    }
   ],
   "source": [
    "# Tokenization 예\n",
    "\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load(\"training/train/processed/spm.model\")\n",
    "\n",
    "print(sp.encode(\"주시기 바랍니다\", out_type=str))\n",
    "print(sp.encode(\"양해 바랍니다\", out_type=str))\n",
    "print(sp.encode(\"화재 발생으로 인해\", out_type=str))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "452f5d51-5008-49a2-8541-d7db5c0de1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "def evaluate_validation_set(model, val_loader, tokenizer, device, eos_id=2, pad_id=3):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_refs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_val, y_val in tqdm(val_loader, desc=\"Evaluating\"):\n",
    "            X_val, y_val = X_val.to(device), y_val.to(device)\n",
    "\n",
    "            # 🔹 디코딩된 예측 (sampling 기반)\n",
    "            preds = [decode_sequence(model, x, tokenizer, device, eos_id=eos_id) for x in X_val]\n",
    "\n",
    "            # 🔹 정답 시퀀스를 디코딩 (token → string)\n",
    "            refs = decode_tokens(tokenizer, y_val.tolist(), eos_id=eos_id, pad_id=pad_id)\n",
    "\n",
    "            all_preds.extend(preds)\n",
    "            all_refs.extend(refs)\n",
    "\n",
    "    # 🔹 결과 정리\n",
    "    return pd.DataFrame({\n",
    "        \"prediction\": all_preds,\n",
    "        \"reference\": all_refs\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7a3272c7-b6f5-4151-8099-3e000c524108",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'evaluate_validation_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m val_loader \u001b[38;5;241m=\u001b[39m get_validation_loader(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/teamspace/studios/this_studio/training/val/processed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# 3. 평가 및 디코딩\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m df_result \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_validation_set\u001b[49m(model, val_loader, spm_tokenizer, device)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# 5. 저장 (선택)\u001b[39;00m\n\u001b[1;32m     16\u001b[0m df_result\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_predictions.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8-sig\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'evaluate_validation_set' is not defined"
     ]
    }
   ],
   "source": [
    "# 1. 모델 로드 \n",
    "model = Seq2Seq(encoder, decoder, device).to(device)\n",
    "\n",
    "checkpoint = torch.load(\"checkpoints/best_checkpoint.pt\", map_location=device, weights_only=False)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# 2. Validation loader 준비 (이미 했다면 생략)\n",
    "val_loader = get_validation_loader(\"/teamspace/studios/this_studio/training/val/processed\")\n",
    "\n",
    "# 3. 평가 및 디코딩\n",
    "df_result = evaluate_validation_set(model, val_loader, spm_tokenizer, device)\n",
    "\n",
    "# 5. 저장 (선택)\n",
    "df_result.to_csv(\"val_predictions.csv\", index=False, encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb040936-58ad-4687-99ec-b5e652a92441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_checkpoint.pt     checkpoint_epoch16.pt  checkpoint_epoch23.pt\n",
      "checkpoint_epoch1.pt   checkpoint_epoch17.pt  checkpoint_epoch3.pt\n",
      "checkpoint_epoch10.pt  checkpoint_epoch18.pt  checkpoint_epoch4.pt\n",
      "checkpoint_epoch11.pt  checkpoint_epoch19.pt  checkpoint_epoch5.pt\n",
      "checkpoint_epoch12.pt  checkpoint_epoch2.pt   checkpoint_epoch6.pt\n",
      "checkpoint_epoch13.pt  checkpoint_epoch20.pt  checkpoint_epoch7.pt\n",
      "checkpoint_epoch14.pt  checkpoint_epoch21.pt  checkpoint_epoch8.pt\n",
      "checkpoint_epoch15.pt  checkpoint_epoch22.pt  checkpoint_epoch9.pt\n"
     ]
    }
   ],
   "source": [
    "!ls checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1dfa7577-6e34-4d28-9be4-a44cb35f00b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ checkpoints 폴더 안 모든 파일이 삭제되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# Checkpoint 비워주기\n",
    "\n",
    "import glob\n",
    "checkpoint_dir = \"checkpoints\"\n",
    "\n",
    "# 해당 폴더 안의 모든 파일 삭제\n",
    "files = glob.glob(os.path.join(checkpoint_dir, \"*\"))\n",
    "for f in files:\n",
    "    os.remove(f)\n",
    "\n",
    "print(f\"✅ {checkpoint_dir} 폴더 안 모든 파일이 삭제되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9cf692c5-015b-457f-9585-e2f821a3346d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "def restore_slots(masked_text: str, slot_values: dict) -> str:\n",
    "    restored = masked_text\n",
    "    for slot, value in slot_values.items():\n",
    "        restored = restored.replace(slot, value)\n",
    "    return restored\n",
    "\n",
    "def restore_pred_and_ref_with_file_ids(pred_csv_path: str, json_dir: str, file_id_npy_path: str):\n",
    "    # 1. Load prediction DataFrame\n",
    "    df = pd.read_csv(pred_csv_path)\n",
    "\n",
    "    # 2. Load file IDs from .npy\n",
    "    file_ids = np.load(file_id_npy_path)\n",
    "\n",
    "    # 3. Iterate and restore both prediction and reference\n",
    "    restored_preds = []\n",
    "    restored_refs = []\n",
    "\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        file_id = file_ids[idx]\n",
    "        json_path = Path(json_dir) / f\"{file_id}.json\"\n",
    "\n",
    "        if json_path.exists():\n",
    "            with open(json_path, encoding=\"utf-8\") as f:\n",
    "                data = json.load(f)\n",
    "            slot_values = data.get(\"slot_values\", {})\n",
    "        else:\n",
    "            slot_values = {}\n",
    "\n",
    "        pred_restored = restore_slots(row[\"prediction\"], slot_values)\n",
    "        ref_restored = restore_slots(row[\"reference\"], slot_values)\n",
    "\n",
    "        restored_preds.append(pred_restored)\n",
    "        restored_refs.append(ref_restored)\n",
    "\n",
    "    # 4. Add new columns to DataFrame\n",
    "    df[\"restored_prediction\"] = restored_preds\n",
    "    df[\"restored_reference\"] = restored_refs\n",
    "    df[\"file_id\"] = file_ids  # ID까지 붙여주면 디버깅 편함\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc237284-c3d7-4086-80b4-9cef8aee1cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 408/408 [00:08<00:00, 48.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              file_id  \\\n",
      "0  NIA_SL_G2_FIRE000004_1_KU02_F_norm   \n",
      "1  NIA_SL_G2_FIRE000004_2_KU02_F_norm   \n",
      "2  NIA_SL_G2_FIRE000004_3_KU02_F_norm   \n",
      "3  NIA_SL_G2_FIRE000020_1_KU02_F_norm   \n",
      "4  NIA_SL_G2_FIRE000020_2_KU02_F_norm   \n",
      "\n",
      "                                          prediction  \\\n",
      "0  <도로>  대피하시기 주민들께서는 지역을 대피하기<도로> 화재 발생으로 인근에 분들...   \n",
      "1                  <지역> <도로>에서 발생으로 일부 차량통제,으로 바랍니다.   \n",
      "2            <지역> <주소> 화재 발생으로 인근 주민은<도로>의지하오니 바랍니다.   \n",
      "3              <시간> <지역> <건물> 화재발생, 인근 에 안전에 유의 바랍니다   \n",
      "4     <시간> <지역> <주소>에서 화재발생, 인근<건물> 주민들은 안전에 유의 바랍니다   \n",
      "\n",
      "                                           reference  \\\n",
      "0  5.23. <시간> <지역> <건물> <건물> 지하주차장 화재로 인해 차량통제 중임...   \n",
      "1  5.23. <시간> <지역> <건물> <건물> 지하주차장 화재로 인해 차량통제 중임...   \n",
      "2  5.23. <시간> <지역> <건물> <건물> 지하주차장 화재로 인해 차량통제 중임...   \n",
      "3  오늘 <시간> 반월공단 내 대림비앤코 화재로 인해 차량통행 불가하오니 우회하여 주시...   \n",
      "4  오늘 <시간> 반월공단 내 대림비앤코 화재로 인해 차량통행 불가하오니 우회하여 주시...   \n",
      "\n",
      "                                 restored_prediction  \\\n",
      "0  <도로>  대피하시기 주민들께서는 지역을 대피하기<도로> 화재 발생으로 인근에 분들...   \n",
      "1                   군포시 <도로>에서 발생으로 일부 차량통제,으로 바랍니다.   \n",
      "2             군포시 <주소> 화재 발생으로 인근 주민은<도로>의지하오니 바랍니다.   \n",
      "3             14:40 <지역> <건물> 화재발생, 인근 에 안전에 유의 바랍니다   \n",
      "4    14:40 <지역> <주소>에서 화재발생, 인근<건물> 주민들은 안전에 유의 바랍니다   \n",
      "\n",
      "                                  restored_reference  \n",
      "0  5.23. 09:50 군포시 롯데리아건물 롯데리아건물 지하주차장 화재로 인해 차량통...  \n",
      "1  5.23. 09:50 군포시 롯데리아건물 롯데리아건물 지하주차장 화재로 인해 차량통...  \n",
      "2  5.23. 09:50 군포시 롯데리아건물 롯데리아건물 지하주차장 화재로 인해 차량통...  \n",
      "3  오늘 14:40 반월공단 내 대림비앤코 화재로 인해 차량통행 불가하오니 우회하여 주...  \n",
      "4  오늘 14:40 반월공단 내 대림비앤코 화재로 인해 차량통행 불가하오니 우회하여 주...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_restored = restore_pred_and_ref_with_file_ids(\n",
    "    pred_csv_path=\"val_predictions.csv\",\n",
    "    json_dir=\"training/val/norm_keypoint\",\n",
    "    file_id_npy_path=\"training/val/processed/file_id_part_0.npy\"\n",
    ")\n",
    "\n",
    "# 미리보기\n",
    "print(df_restored[[\"file_id\", \"prediction\", \"reference\", \"restored_prediction\", \"restored_reference\"]].head())\n",
    "\n",
    "# 저장\n",
    "df_restored.to_csv(\"val_predictions_restored.csv\", index=False, encoding=\"utf-8-sig\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c486e0c1-e317-44e0-b789-ee075e0b9b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1751285248.457784   11380 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1751285248.474995   11382 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1751285248.487133   11377 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1751285248.523309   11379 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    }
   ],
   "source": [
    "# 시연 \n",
    "# keypoint 추출\n",
    "\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# MediaPipe pose 초기화\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(static_image_mode=False)\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(static_image_mode=False)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "def extract_keypoints_from_video(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    all_keypoints = []\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # BGR → RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Pose 추출\n",
    "        pose_result = pose.process(image)\n",
    "        hand_result = hands.process(image)\n",
    "\n",
    "        keypoints = []\n",
    "\n",
    "        # Pose keypoints\n",
    "        if pose_result.pose_landmarks:\n",
    "            for lm in pose_result.pose_landmarks.landmark:\n",
    "                keypoints.extend([lm.x, lm.y, lm.visibility])\n",
    "        else:\n",
    "            keypoints.extend([0.0, 0.0, 0.0] * 33)\n",
    "\n",
    "        # Hands keypoints (왼손 + 오른손)\n",
    "        for hand_landmarks in [hand_result.left_hand_landmarks, hand_result.right_hand_landmarks]:\n",
    "            if hand_landmarks:\n",
    "                for lm in hand_landmarks.landmark:\n",
    "                    keypoints.extend([lm.x, lm.y, lm.visibility])\n",
    "            else:\n",
    "                keypoints.extend([0.0, 0.0, 0.0] * 21)\n",
    "\n",
    "        # 총 keypoint 수 확인 (33 + 21 + 21 = 75개 → 75 x 3 = 225차원)\n",
    "        all_keypoints.append(keypoints)\n",
    "\n",
    "    cap.release()\n",
    "    return np.array(all_keypoints)  # shape: (T, 225)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fff8114e-ef8a-4b62-9f69-e98d7a164eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📌 MediaPipe 처리 중:   0%|          | 0/707 [00:00<?, ?it/s]W0000 00:00:1751286223.754911   14048 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1751286223.773966   14044 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1751286223.777339   14048 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1751286223.813469   14044 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "📌 MediaPipe 처리 중: 100%|██████████| 707/707 [00:29<00:00, 23.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶ 최종 shape: (707, 108)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 🎯 유지할 pose index\n",
    "POSE_KEEP_IDX = [0, 1, 2, 3, 4, 5, 6, 7, 15, 16, 17, 18]\n",
    "\n",
    "def extract_video_frames(video_path, fps=30):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    original_fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_interval = int(original_fps // fps) if original_fps > fps else 1\n",
    "\n",
    "    frames = []\n",
    "    count = 0\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        if count % frame_interval == 0:\n",
    "            frames.append(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        count += 1\n",
    "    cap.release()\n",
    "    return frames\n",
    "\n",
    "def extract_filtered_keypoints(frames):\n",
    "    mp_pose = mp.solutions.pose\n",
    "    mp_hands = mp.solutions.hands\n",
    "\n",
    "    pose = mp_pose.Pose(static_image_mode=False)\n",
    "    hands = mp_hands.Hands(static_image_mode=False, max_num_hands=2)\n",
    "\n",
    "    results = []\n",
    "    for frame in tqdm(frames, desc=\"📌 MediaPipe 처리 중\"):\n",
    "        frame_kpts = []\n",
    "\n",
    "        # 🔹 Pose keypoints\n",
    "        pose_result = pose.process(frame)\n",
    "        if pose_result.pose_landmarks:\n",
    "            pose_kpts = pose_result.pose_landmarks.landmark\n",
    "            for idx in POSE_KEEP_IDX:\n",
    "                lm = pose_kpts[idx]\n",
    "                frame_kpts.extend([lm.x, lm.y])\n",
    "        else:\n",
    "            frame_kpts.extend([0.0, 0.0] * len(POSE_KEEP_IDX))\n",
    "\n",
    "        # 🔹 Hands keypoints\n",
    "        hand_result = hands.process(frame)\n",
    "        left_hand = [0.0, 0.0] * 21\n",
    "        right_hand = [0.0, 0.0] * 21\n",
    "\n",
    "        if hand_result.multi_hand_landmarks and hand_result.multi_handedness:\n",
    "            for i, hand_landmarks in enumerate(hand_result.multi_hand_landmarks):\n",
    "                label = hand_result.multi_handedness[i].classification[0].label\n",
    "                coords = [coord for lm in hand_landmarks.landmark for coord in (lm.x, lm.y)]\n",
    "                if label == \"Left\":\n",
    "                    left_hand = coords\n",
    "                elif label == \"Right\":\n",
    "                    right_hand = coords\n",
    "\n",
    "        frame_kpts.extend(left_hand)\n",
    "        frame_kpts.extend(right_hand)\n",
    "        results.append(frame_kpts)\n",
    "\n",
    "    return np.array(results)  # shape: (T, 108)\n",
    "\n",
    "# ✅ 실행 예시\n",
    "video_path = \"video.mp4\"\n",
    "\n",
    "frames = extract_video_frames(video_path, fps=30)\n",
    "kpt_108 = extract_filtered_keypoints(frames)\n",
    "\n",
    "print(\"▶ 최종 shape:\", kpt_108.shape)  # (T, 108)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4ea66c3a-07eb-48a1-9c42-03d0fc9acefd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶ 정규화된 shape: (707, 108)\n"
     ]
    }
   ],
   "source": [
    "# Size 복원 후 정규화 \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def normalize_mediapipe_keypoints(kpt_108: np.ndarray, stat_path: str,\n",
    "                                   image_width=1280, image_height=720) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Normalize MediaPipe keypoints using OpenPose-based statistics.\n",
    "    \n",
    "    Args:\n",
    "        kpt_108 (np.ndarray): Keypoints of shape (T, 108) with (x, y) in range [0, 1]\n",
    "        stat_path (str): Path to 'norm_stat.npz' from training\n",
    "        image_width (int): Width of original video frames\n",
    "        image_height (int): Height of original video frames\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: Normalized keypoints of shape (T, 108)\n",
    "    \"\"\"\n",
    "    # 1. 좌표 복원 (0~1 → 픽셀)\n",
    "    kpt = np.copy(kpt_108)\n",
    "    kpt[:, 0::2] *= image_width   # x 좌표\n",
    "    kpt[:, 1::2] *= image_height  # y 좌표\n",
    "\n",
    "    # 2. 통계 불러오기\n",
    "    stats = np.load(stat_path)\n",
    "    pose_mu = stats[\"pose_mu\"]\n",
    "    pose_sd = stats[\"pose_sd\"]\n",
    "    left_min = stats[\"left_min\"]\n",
    "    left_max = stats[\"left_max\"]\n",
    "    right_min = stats[\"right_min\"]\n",
    "    right_max = stats[\"right_max\"]\n",
    "\n",
    "    # 3. 분할\n",
    "    pose = kpt[:, :24]\n",
    "    left = kpt[:, 24:66]\n",
    "    right = kpt[:, 66:]\n",
    "\n",
    "    # 4. 정규화\n",
    "    norm_pose = (pose - pose_mu) / (pose_sd + 1e-8)\n",
    "    norm_left = (left - left_min) / (left_max - left_min + 1e-8) - 0.5\n",
    "    norm_right = (right - right_min) / (right_max - right_min + 1e-8) - 0.5\n",
    "\n",
    "    # 5. 합치기\n",
    "    norm_kpt = np.concatenate([norm_pose, norm_left, norm_right], axis=-1)\n",
    "    return norm_kpt\n",
    "\n",
    "norm_kpt = normalize_mediapipe_keypoints(kpt_108, stat_path=\"training/norm_stat.npz\")\n",
    "print(\"▶ 정규화된 shape:\", norm_kpt.shape)  # (T, 108)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "541ded9c-9eb2-4c65-831e-cb06032f110b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Pose 평균과 표준편차\n",
      "Mean: [-11.16571178   1.61261149 -12.24069937  -5.13413468  -4.6927129\n",
      "  -4.9362072   -1.33633479  -4.47444851  -2.59699363  -1.37483823\n",
      " -21.97698555  -4.95795615 -13.19388483  -5.35643645  -6.284303\n",
      "  -1.91416178  -5.98963323   6.05604604 -15.13240997   5.09070572\n",
      "  -3.08469361   5.56407687 -10.08432758   4.61333059]\n",
      "Std:  [0.19218931 0.06411243 0.18897083 0.0786324  0.13019507 0.07248655\n",
      " 0.06903451 0.02829407 0.06687626 0.01036941 0.21694626 0.0653447\n",
      " 0.10574796 0.02625473 0.05032789 0.00819363 1.37046651 1.27776483\n",
      " 1.44009533 0.94750438 1.15802779 1.67799417 1.16173833 1.25872799]\n",
      "\n",
      "✅ Left hand 범위\n",
      "Min: -0.5 Max: 0.061749881855847955\n",
      "\n",
      "✅ Right hand 범위\n",
      "Min: -0.5 Max: 0.20890637965029302\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Pose (앞쪽 24차원): 12개 keypoint × 2 = 24\n",
    "pose = norm_kpt[:, :24]\n",
    "# Left hand (중간 42차원): 21개 keypoint × 2 = 42\n",
    "left = norm_kpt[:, 24:66]\n",
    "# Right hand (뒤쪽 42차원)\n",
    "right = norm_kpt[:, 66:]\n",
    "\n",
    "print(\"✅ Pose 평균과 표준편차\")\n",
    "print(\"Mean:\", pose.mean(axis=0))\n",
    "print(\"Std: \", pose.std(axis=0))\n",
    "\n",
    "print(\"\\n✅ Left hand 범위\")\n",
    "print(\"Min:\", left.min(), \"Max:\", left.max())\n",
    "\n",
    "print(\"\\n✅ Right hand 범위\")\n",
    "print(\"Min:\", right.min(), \"Max:\", right.max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e468c11c-5287-4340-864f-845e83106617",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def predict_from_keypoint(model, keypoint_seq, tokenizer, device, eos_id=2, max_len=100):\n",
    "    model.eval()\n",
    "\n",
    "    # 1. numpy → torch tensor 변환: (T, 108) → (1, T, 108)\n",
    "    x = torch.tensor(keypoint_seq, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "\n",
    "    # 2. Decoder 시작 토큰: BOS\n",
    "    bos_id = tokenizer.bos_id()\n",
    "    decoder_input = torch.tensor([[bos_id]], dtype=torch.long).to(device)\n",
    "\n",
    "    preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_len):\n",
    "            # 3. 모델 forward\n",
    "            output = model(x, decoder_input, teacher_forcing_ratio=0.0)\n",
    "\n",
    "            # 4. 가장 마지막 토큰의 확률 → 예측 token id\n",
    "            next_token = output[:, -1, :].argmax(dim=-1).item()\n",
    "\n",
    "            # 5. EOS 토큰이면 종료\n",
    "            if next_token == eos_id:\n",
    "                break\n",
    "\n",
    "            preds.append(next_token)\n",
    "\n",
    "            # 6. decoder input 업데이트\n",
    "            next_token_tensor = torch.tensor([[next_token]], dtype=torch.long).to(device)\n",
    "            decoder_input = torch.cat([decoder_input, next_token_tensor], dim=1)\n",
    "\n",
    "    # 7. 토큰 ID → 문장 복원\n",
    "    return tokenizer.decode(preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d3a13344-f1cd-4da7-8397-64ae9ba4693c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (rnn): GRU(108, 256, batch_first=True, bidirectional=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(1000, 256)\n",
       "    (attention): Attention(\n",
       "      (attn): Linear(in_features=768, out_features=256, bias=True)\n",
       "      (v): Linear(in_features=256, out_features=1, bias=False)\n",
       "    )\n",
       "    (rnn): GRU(768, 256, batch_first=True)\n",
       "    (fc_out): Linear(in_features=1024, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. 모델 로드 \n",
    "model = Seq2Seq(encoder, decoder, device).to(device)\n",
    "\n",
    "checkpoint = torch.load(\"checkpoints/best_checkpoint.pt\", map_location=device, weights_only=False)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e71a8ca0-741e-4829-9f02-ba322583608a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 예측 결과:  ⁇ <시간> 발생으로<도로><도로><도로> 발생으로 발생으로<도로><도로> 일대가 일대가 대피 일대 대피 발생으로 대피 일대가 일대가 일대가 일대가 일대가 일대가 일대가 일대가 일대가 일대가 일대가 일대가 일대가 일대가 일대가 일대가 일대가 일대가 일대가 일대가 일대가 일대가 일대가 일대가 일대가 일대가 일대가 일대가 일대가 일대가 일대가 일대가 일대가 일대가 일대가 일대가 일대가 일대가 일대가 일대가 일대\n"
     ]
    }
   ],
   "source": [
    "# 예측\n",
    "output_text = predict_from_keypoint(model, norm_kpt, spm_tokenizer, device)\n",
    "print(\"🔍 예측 결과:\", output_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "77b12bae-4387-444a-9b84-49475955b426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 값 중 0의 비율: 14.47%\n"
     ]
    }
   ],
   "source": [
    "# 추출이 잘 안됨\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Convert the first few frames to a DataFrame for easier inspection\n",
    "df = pd.DataFrame(kpt_108)  # Show first 5 frames\n",
    "\n",
    "total_elements = df.size\n",
    "\n",
    "# 0의 개수\n",
    "zero_count = (df < 0.1).sum().sum()\n",
    "\n",
    "# 비율 계산 (%)\n",
    "zero_ratio = (zero_count / total_elements) * 100\n",
    "\n",
    "print(f\"총 값 중 0의 비율: {zero_ratio:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
