{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0837caa9-7d67-444a-acfa-d0e8d41b8df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import xmltodict\n",
    "from glob import glob\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0493c99d-d20f-4879-b212-5971526a4335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xml íŒŒì¼ì˜ í‚¤í¬ì¸íŠ¸, json íŒŒì¼ì˜ ë¼ë²¨ì„ í•©ì³ merged_keypoint ìƒì„±\n",
    "\n",
    "# ğŸ“ ê²½ë¡œ ì„¤ì • (Lightning ê¸°ì¤€)\n",
    "base_xml_root = 'training/keypoint/tact_keypoints/FIRE'\n",
    "base_json_root = 'training/keypoint/tact_morpheme/FIRE'\n",
    "save_dir = 'training/merged_keypoint'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# ìƒì²´ & ì† ì¤‘ì‹¬ keypoint ì¸ë±ìŠ¤\n",
    "POSE_KEEP_IDX = [0, 1, 2, 3, 4, 5, 6, 7, 15, 16, 17, 18]\n",
    "\n",
    "# 2D pose keypoint í•„í„°ë§\n",
    "def filter_pose_keypoints(points):\n",
    "    keypoints = [list(map(float, p.split(','))) for p in points]\n",
    "    return [coord for idx in POSE_KEEP_IDX if idx < len(keypoints) for coord in keypoints[idx][:2]]\n",
    "\n",
    "# hand keypoint í•„í„°ë§\n",
    "def filter_hand_keypoints(points):\n",
    "    keypoints = [list(map(float, p.split(','))) for p in points]\n",
    "    return [coord for kpt in keypoints for coord in kpt[:2]]\n",
    "\n",
    "# ë‹¨ì¼ ìƒ˜í”Œ ë³‘í•© í•¨ìˆ˜\n",
    "def merge_single_sample_from_path(xml_path, json_path):\n",
    "    try:\n",
    "        with open(xml_path, 'r', encoding='utf-8') as f:\n",
    "            xml_data = xmltodict.parse(f.read())\n",
    "    except Exception:\n",
    "        print(f\"[ì˜¤ë¥˜] XML íŒŒì‹± ì‹¤íŒ¨: {xml_path}\")\n",
    "        return False\n",
    "\n",
    "    frames_dict = {}\n",
    "    for track in xml_data[\"annotations\"][\"track\"]:\n",
    "        label = track[\"@label\"]\n",
    "        if label == \"face_keypoints_2d\":\n",
    "            continue\n",
    "        for key in track:\n",
    "            if key not in [\"@id\", \"@label\"]:\n",
    "                entries = track[key] if isinstance(track[key], list) else [track[key]]\n",
    "                for entry in entries:\n",
    "                    idx_f = int(entry[\"@frame\"])\n",
    "                    points = [p for p in entry[\"@points\"].split(';') if p.strip()]\n",
    "                    filtered_points = (\n",
    "                        filter_pose_keypoints(points) if label == \"pose_keypoints_2d\"\n",
    "                        else filter_hand_keypoints(points)\n",
    "                    )\n",
    "                    frames_dict.setdefault(idx_f, {})[label] = filtered_points\n",
    "\n",
    "    try:\n",
    "        with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            js = json.load(f)\n",
    "        korean_text = js.get(\"korean_text\", \"\")\n",
    "        signer_id = js.get(\"translator\", {}).get(\"id\", None)\n",
    "    except Exception:\n",
    "        print(f\"[ì˜¤ë¥˜] JSON íŒŒì‹± ì‹¤íŒ¨: {json_path}\")\n",
    "        return False\n",
    "\n",
    "    base = os.path.splitext(os.path.basename(xml_path))[0]\n",
    "    result = {\n",
    "        \"index\": base,\n",
    "        \"id\": signer_id,\n",
    "        \"korean_text\": korean_text,\n",
    "        \"frames\": []\n",
    "    }\n",
    "\n",
    "    prev_frame_vec = None\n",
    "    for idx_f in sorted(frames_dict):\n",
    "        frame_info = frames_dict[idx_f]\n",
    "        frame_vec = frame_info.get(\"pose_keypoints_2d\", []) + \\\n",
    "                    frame_info.get(\"hand_left_keypoints_2d\", []) + \\\n",
    "                    frame_info.get(\"hand_right_keypoints_2d\", [])\n",
    "        if prev_frame_vec is not None and frame_vec == prev_frame_vec:\n",
    "            continue\n",
    "        prev_frame_vec = frame_vec\n",
    "        result[\"frames\"].append({\n",
    "            \"frame_idx\": idx_f,\n",
    "            \"pose\": frame_info.get(\"pose_keypoints_2d\", []),\n",
    "            \"hand_left\": frame_info.get(\"hand_left_keypoints_2d\", []),\n",
    "            \"hand_right\": frame_info.get(\"hand_right_keypoints_2d\", [])\n",
    "        })\n",
    "\n",
    "    save_path = os.path.join(save_dir, f\"{base}.json\")\n",
    "    with open(save_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(result, f, ensure_ascii=False, indent=2)\n",
    "    return True\n",
    "\n",
    "# ì „ì²´ xml/json ë³‘í•©\n",
    "xml_paths = glob(os.path.join(base_xml_root, \"**\", \"*.xml\"), recursive=True)\n",
    "\n",
    "success, fail = 0, 0\n",
    "for xml_path in tqdm(xml_paths, desc=\"ë³‘í•© ì§„í–‰ ì¤‘\"):\n",
    "    base_name = os.path.basename(xml_path)\n",
    "    json_name = base_name.replace(\"_F.xml\", \".json\")\n",
    "    relative_dir = os.path.relpath(os.path.dirname(xml_path), base_xml_root)\n",
    "    json_path = os.path.join(base_json_root, relative_dir, json_name)\n",
    "\n",
    "    if os.path.exists(json_path):\n",
    "        ok = merge_single_sample_from_path(xml_path, json_path)\n",
    "        success += int(ok)\n",
    "        fail += int(not ok)\n",
    "    else:\n",
    "        print(f\"â— ëŒ€ì‘ JSON ì—†ìŒ: {json_path}\")\n",
    "        fail += 1\n",
    "\n",
    "print(f\"\\nâœ… ë³‘í•© ì™„ë£Œ: {success}ê°œ, ì‹¤íŒ¨: {fail}ê°œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e301f90-2d67-4d98-ad8f-5903c52129cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xml, json ê°„ mapping í™•ì¸\n",
    "\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "# XML / JSON ê²½ë¡œ\n",
    "xml_root = 'training/keypoint/tact_keypoints/FIRE'\n",
    "json_root = 'training/keypoint/tact_morpheme/FIRE'\n",
    "\n",
    "# ì¶”ì¶œ í•¨ìˆ˜\n",
    "def extract_key_from_filename(path, suffix_to_strip):\n",
    "    base = os.path.basename(path)\n",
    "    key = base.replace(suffix_to_strip, '')  # ì˜ˆ: '_F.xml' ë˜ëŠ” '.json'\n",
    "    return key\n",
    "\n",
    "# ëª©ë¡ ìˆ˜ì§‘\n",
    "xml_paths = glob(os.path.join(xml_root, \"**\", \"*.xml\"), recursive=True)\n",
    "json_paths = glob(os.path.join(json_root, \"**\", \"*.json\"), recursive=True)\n",
    "\n",
    "xml_keys = set(extract_key_from_filename(p, '_F.xml') for p in xml_paths)\n",
    "json_keys = set(extract_key_from_filename(p, '.json') for p in json_paths)\n",
    "\n",
    "# êµì§‘í•©, ì°¨ì§‘í•© í™•ì¸\n",
    "only_in_xml = sorted(xml_keys - json_keys)\n",
    "only_in_json = sorted(json_keys - xml_keys)\n",
    "matched = sorted(xml_keys & json_keys)\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(f\"ğŸ“Š ì´ XML íŒŒì¼: {len(xml_keys)}\")\n",
    "print(f\"ğŸ“Š ì´ JSON íŒŒì¼: {len(json_keys)}\")\n",
    "print(f\"âœ… ë§¤ì¹­ëœ íŒŒì¼ ìˆ˜: {len(matched)}\")\n",
    "print(f\"â— XMLë§Œ ìˆê³  JSON ì—†ëŠ” íŒŒì¼ ìˆ˜: {len(only_in_xml)}\")\n",
    "print(f\"â— JSONë§Œ ìˆê³  XML ì—†ëŠ” íŒŒì¼ ìˆ˜: {len(only_in_json)}\")\n",
    "\n",
    "# ìƒ˜í”Œ ì¶œë ¥\n",
    "if only_in_xml:\n",
    "    print(\"\\nğŸ“ XMLë§Œ ìˆëŠ” íŒŒì¼ ì˜ˆì‹œ:\", only_in_xml[:5])\n",
    "if only_in_json:\n",
    "    print(\"\\nğŸ“ JSONë§Œ ìˆëŠ” íŒŒì¼ ì˜ˆì‹œ:\", only_in_json[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73c9ef9e-ae2c-4093-98a2-7c367cf84aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-level keys: ['index', 'id', 'korean_text', 'frames', 'masked_korean_text', 'slot_values']\n",
      "Sample index: NIA_SL_G2_FIRE000003_1_TW03_F\n",
      "Signer ID: None\n",
      "Korean text: ì•ˆì „ì•ˆë‚´. ì˜¤ëŠ˜ 02:00 ë°˜ì›”ê³µë‹¨ ë‚´ í™”ì¬ ë°œìƒ, ì—°ê¸°í™•ì‚°ì— ì£¼ì˜í•˜ì„¸ìš”\n",
      "Total frames: 415\n",
      "First frame example:\n",
      " {'frame_idx': 0, 'pose': [-0.5705703748867382, -1.293855761361989, -0.9978378664332288, 0.38877772926518217, -1.333126966363792, 0.4141644645741816, -0.19592469723364872, 1.0743982394172575, -0.6269272316283744, 1.9253424647875002, 0.09971286732763626, 0.22130937010234883, -0.8861206474747211, 0.9415592908037219, 0.06099393017401008, 1.0303200784063804, -0.4102040536331944, -1.2634992735993633, -0.4574661803063296, -1.1997975506862708, -0.3532081551955483, -0.9235349309592826, -0.25358581902873323, -1.2418483940684855], 'hand_left': [0.2562509398573034, 0.3781380067836563, 0.23828920569760192, 0.40224842894696955, 0.22913406363610123, 0.44531825872919373, 0.2135864074856869, 0.44406526391357304, 0.19717924048813995, 0.44449387108595795, 0.24385194006458566, 0.4596639511103904, 0.22975386654987107, 0.4600255993604093, 0.21231373800168685, 0.4582818651957242, 0.19865914827591602, 0.4560792817378445, 0.25383824536837674, 0.45897034771122835, 0.23038244194588509, 0.45953865213113276, 0.21477481874862436, 0.45976629160559046, 0.201800457440641, 0.4592198245556409, 0.2586831669577556, 0.45316991902811665, 0.2371309259259502, 0.45892582865818843, 0.22050660981460501, 0.45854368931108214, 0.2099147517841472, 0.45748645471091476, 0.2642908083443215, 0.4450552791221709, 0.24543862012703532, 0.45543876826205765, 0.23247872368318667, 0.4486923302875042, 0.22184827967642695, 0.44704570252366216], 'hand_right': [0.14375497084605948, 0.44750585655239195, 0.1555338799840088, 0.44579148453283735, 0.16317196174918336, 0.44285070744575983, 0.1574357692015892, 0.4413579328379571, 0.15384940875471154, 0.4403444392577244, 0.12699279995173895, 0.4411215880799888, 0.1177980432372735, 0.4426679462481511, 0.11278776176583405, 0.43969133881136513, 0.10776411623746829, 0.43337171082307324, 0.10889238941956325, 0.4420328662150086, 0.10299058379960091, 0.4464366163340865, 0.09843604211579782, 0.44211075689581525, 0.09610042072438185, 0.4390355870492948, 0.09771126760101845, 0.4448349328885265, 0.0935771995821214, 0.445990715941349, 0.09085309744582182, 0.43857860351819633, 0.09153391854425363, 0.4363044982612567, 0.09025260993756046, 0.44391056088495195, 0.0843549945601495, 0.44432322916558564, 0.08490383109037491, 0.43974216321087634, 0.08418686905471828, 0.4366570304636118]}\n",
      "\n",
      " Frame 1 pose keypoints vector length: 24 (expected 24)\n"
     ]
    }
   ],
   "source": [
    "# Merged_keypoint íŒŒì¼ í™•ì¸\n",
    "\n",
    "# ì‹¤ì œ ë³‘í•©ëœ JSON ê²½ë¡œë¡œ ìˆ˜ì •\n",
    "sample_path = 'training/train/norm_keypoint/NIA_SL_G2_FIRE000003_1_TW03_F_norm.json'\n",
    "\n",
    "# JSON íŒŒì¼ ì—´ê¸°\n",
    "with open(sample_path, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# ë³‘í•©ëœ êµ¬ì¡° ì •ë³´ ì¶œë ¥\n",
    "print(\"Top-level keys:\", list(data.keys()))\n",
    "print(\"Sample index:\", data['index'])\n",
    "print(\"Signer ID:\", data.get('id'))\n",
    "print(\"Korean text:\", data['korean_text'])\n",
    "print(\"Total frames:\", len(data['frames']))\n",
    "print(\"First frame example:\\n\", data['frames'][0])\n",
    "\n",
    "# í‚¤í¬ì¸íŠ¸ í™•ì¸ (ì˜ˆ: pose = 12 keypoints Ã— (x, y) = 24ì°¨ì›)\n",
    "pose_len = len(data['frames'][1]['pose'])\n",
    "print(f\"\\n Frame 1 pose keypoints vector length: {pose_len} (expected 24)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef02c6ab-dcba-4f32-93b2-9a6ff878a748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì´ ë¬¸ì¥ ID ìˆ˜: 1828\n"
     ]
    }
   ],
   "source": [
    "# ë¬¸ì¥ ìˆ˜ ì„¸ê¸°\n",
    "\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "DATA_DIR = \"/teamspace/studios/this_studio/training/merged_keypoint\"\n",
    "file_list = [f for f in os.listdir(DATA_DIR) if f.endswith(\".json\")]\n",
    "\n",
    "sentence_to_files = defaultdict(list)\n",
    "\n",
    "for fname in file_list:\n",
    "    # ì˜ˆ: NIA_SL_G2_FIRE000004_1_KU02_F.json\n",
    "    parts = fname.split(\"_\")\n",
    "    if len(parts) >= 4:\n",
    "        sentence_id = parts[3]  # FIRE000004\n",
    "        sentence_to_files[sentence_id].append(fname)\n",
    "\n",
    "print(\"ì´ ë¬¸ì¥ ID ìˆ˜:\", len(sentence_to_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c44521d-9099-4fe8-a93d-24a6fe75435d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1828/1828 [00:20<00:00, 90.94it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë¶„ë¦¬ ì™„ë£Œ! ì´ ë¬¸ì¥ ìˆ˜: 1828 / Validation ë¬¸ì¥ ìˆ˜: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Train, val split\n",
    "\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ê²½ë¡œ ì„¤ì •\n",
    "SOURCE_DIR = \"/teamspace/studios/this_studio/training/merged_keypoint\"\n",
    "TRAIN_DIR = \"/teamspace/studios/this_studio/training/train/merged_keypoint\"\n",
    "VAL_DIR = \"/teamspace/studios/this_studio/training/val/merged_keypoint\"\n",
    "\n",
    "os.makedirs(TRAIN_DIR, exist_ok=True)\n",
    "os.makedirs(VAL_DIR, exist_ok=True)\n",
    "\n",
    "# ëª¨ë“  json íŒŒì¼ ìˆ˜ì§‘\n",
    "all_files = [f for f in os.listdir(SOURCE_DIR) if f.endswith(\".json\")]\n",
    "\n",
    "# ë¬¸ì¥ ID ì¶”ì¶œ (ì˜ˆ: NIA_SL_G2_FIRE000004_1_KU02_F.json â†’ FIRE000004)\n",
    "sentence_to_files = dict()\n",
    "for fname in all_files:\n",
    "    parts = fname.split(\"_\")\n",
    "    if len(parts) >= 4:\n",
    "        sentence_id = parts[3]  # ì˜¬ë°”ë¥¸ ë¬¸ì¥ ID\n",
    "        sentence_to_files.setdefault(sentence_id, []).append(fname)\n",
    "\n",
    "# ë¬¸ì¥ ID ì¤‘ì—ì„œ 200ê°œ ëœë¤ ì„ íƒ (ê²€ì¦ìš©)\n",
    "all_sentence_ids = list(sentence_to_files.keys())\n",
    "val_sentence_ids = set(random.sample(all_sentence_ids, 200))\n",
    "\n",
    "# íŒŒì¼ ë¶„ë°°\n",
    "for sid, fnames in tqdm(sentence_to_files.items(), desc=\"Copying files\"):\n",
    "    target_dir = VAL_DIR if sid in val_sentence_ids else TRAIN_DIR\n",
    "    for fname in fnames:\n",
    "        src = os.path.join(SOURCE_DIR, fname)\n",
    "        dst = os.path.join(target_dir, fname)\n",
    "        shutil.copy2(src, dst)\n",
    "\n",
    "print(f\"âœ… ë¶„ë¦¬ ì™„ë£Œ! ì´ ë¬¸ì¥ ìˆ˜: {len(all_sentence_ids)} / Validation ë¬¸ì¥ ìˆ˜: {len(val_sentence_ids)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2eb3b0b6-8270-4258-ae70-ab547b8cf974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ Train JSON íŒŒì¼ ìˆ˜: 3183\n",
      "ğŸ“‚ Validation JSON íŒŒì¼ ìˆ˜: 408\n"
     ]
    }
   ],
   "source": [
    "# Train, Val íŒŒì¼ ìˆ˜ í™•ì¸\n",
    "\n",
    "import os\n",
    "\n",
    "TRAIN_DIR = \"/teamspace/studios/this_studio/training/train/merged_keypoint\"\n",
    "VAL_DIR = \"/teamspace/studios/this_studio/training/val/merged_keypoint\"\n",
    "\n",
    "num_train = len([f for f in os.listdir(TRAIN_DIR) if f.endswith(\".json\")])\n",
    "num_val = len([f for f in os.listdir(VAL_DIR) if f.endswith(\".json\")])\n",
    "\n",
    "print(f\"ğŸ“‚ Train JSON íŒŒì¼ ìˆ˜: {num_train}\")\n",
    "print(f\"ğŸ“‚ Validation JSON íŒŒì¼ ìˆ˜: {num_val}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d32dc50d-5170-4c89-ba70-787b61cd698b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ” Collecting train keypoints: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3183/3183 [00:41<00:00, 77.32it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Train ê¸°ë°˜ ì •ê·œí™” í†µê³„ ì €ì¥ ì™„ë£Œ â†’ /teamspace/studios/this_studio/training/norm_stat.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸŒ€ Normalizing â†’ /teamspace/studios/this_studio/training/train/norm_keypoint: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3183/3183 [14:25<00:00,  3.68it/s]\n",
      "ğŸŒ€ Normalizing â†’ /teamspace/studios/this_studio/training/val/norm_keypoint: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 408/408 [01:52<00:00,  3.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Train & Validation ì •ê·œí™” ì™„ë£Œ!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Train, Val ê°ê° normalization ì ìš© \n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ê²½ë¡œ ì„¤ì •\n",
    "TRAIN_SRC = \"/teamspace/studios/this_studio/training/train/merged_keypoint\"\n",
    "VAL_SRC = \"/teamspace/studios/this_studio/training/val/merged_keypoint\"\n",
    "TRAIN_DST = \"/teamspace/studios/this_studio/training/train/norm_keypoint\"\n",
    "VAL_DST = \"/teamspace/studios/this_studio/training/val/norm_keypoint\"\n",
    "STAT_PATH = \"/teamspace/studios/this_studio/training/norm_stat.npz\"\n",
    "\n",
    "# ë””ë ‰í† ë¦¬ ìƒì„±\n",
    "os.makedirs(TRAIN_DST, exist_ok=True)\n",
    "os.makedirs(VAL_DST, exist_ok=True)\n",
    "\n",
    "### 1. í†µê³„ ê³„ì‚°ìš© ë°ì´í„° ìˆ˜ì§‘ (Train ê¸°ì¤€)\n",
    "pose_all, left_all, right_all = [], [], []\n",
    "\n",
    "train_files = sorted(glob(os.path.join(TRAIN_SRC, \"*.json\")))\n",
    "for file in tqdm(train_files, desc=\"ğŸ” Collecting train keypoints\"):\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    for frame in data['frames']:\n",
    "        if frame.get('pose'): pose_all.append(frame['pose'])\n",
    "        if frame.get('hand_left'): left_all.append(frame['hand_left'])\n",
    "        if frame.get('hand_right'): right_all.append(frame['hand_right'])\n",
    "\n",
    "pose_all = np.array(pose_all)\n",
    "left_all = np.array(left_all)\n",
    "right_all = np.array(right_all)\n",
    "\n",
    "# í†µê³„ ê³„ì‚° ë° ì €ì¥\n",
    "pose_mu = pose_all.mean(axis=0)\n",
    "pose_sd = pose_all.std(axis=0)\n",
    "left_min = left_all.min(axis=0)\n",
    "left_max = left_all.max(axis=0)\n",
    "right_min = right_all.min(axis=0)\n",
    "right_max = right_all.max(axis=0)\n",
    "\n",
    "np.savez(STAT_PATH, pose_mu=pose_mu, pose_sd=pose_sd,\n",
    "         left_min=left_min, left_max=left_max,\n",
    "         right_min=right_min, right_max=right_max)\n",
    "print(f\"ğŸ“Š Train ê¸°ë°˜ ì •ê·œí™” í†µê³„ ì €ì¥ ì™„ë£Œ â†’ {STAT_PATH}\")\n",
    "\n",
    "### 2. ì •ê·œí™” í•¨ìˆ˜ ì •ì˜\n",
    "def normalize_pose(x, mu, sd):\n",
    "    return (np.array(x) - mu) / (sd + 1e-8)\n",
    "\n",
    "def normalize_hand(x, minv, maxv):\n",
    "    return (np.array(x) - minv) / (maxv - minv + 1e-8) - 0.5\n",
    "\n",
    "### 3. ì •ê·œí™” ì ìš© í•¨ìˆ˜\n",
    "def apply_normalization_and_save(src_files, dst_dir, stats):\n",
    "    for file in tqdm(src_files, desc=f\"ğŸŒ€ Normalizing â†’ {dst_dir}\"):\n",
    "        with open(file, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        for frame in data['frames']:\n",
    "            if frame.get('pose'):\n",
    "                frame['pose'] = list(normalize_pose(frame['pose'], stats['pose_mu'], stats['pose_sd']))\n",
    "            if frame.get('hand_left'):\n",
    "                frame['hand_left'] = list(normalize_hand(frame['hand_left'], stats['left_min'], stats['left_max']))\n",
    "            if frame.get('hand_right'):\n",
    "                frame['hand_right'] = list(normalize_hand(frame['hand_right'], stats['right_min'], stats['right_max']))\n",
    "        fname = os.path.basename(file).replace('.json', '_norm.json')\n",
    "        with open(os.path.join(dst_dir, fname), 'w', encoding='utf-8') as f:\n",
    "            json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "### 4. ì •ê·œí™” ì‹¤í–‰\n",
    "stats = np.load(STAT_PATH)\n",
    "\n",
    "# Train ì •ê·œí™”\n",
    "apply_normalization_and_save(train_files, TRAIN_DST, stats)\n",
    "\n",
    "# Val ì •ê·œí™” (statì€ train ê¸°ì¤€)\n",
    "val_files = sorted(glob(os.path.join(VAL_SRC, \"*.json\")))\n",
    "apply_normalization_and_save(val_files, VAL_DST, stats)\n",
    "\n",
    "print(\"âœ… Train & Validation ì •ê·œí™” ì™„ë£Œ!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a240592-5724-4301-9fc9-9ba5ccbdeed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ” Checking normalized data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3183/3183 [01:35<00:00, 33.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Normalized Pose:\n",
      "  mean: [ 0.  0.  0. -0.  0.]\n",
      "  std:  [1. 1. 1. 1. 1.]\n",
      "\n",
      "âœ… Normalized Hand Left:\n",
      "  min: [-0.5 -0.5 -0.5 -0.5 -0.5]\n",
      "  max: [0.5 0.5 0.5 0.5 0.5]\n",
      "\n",
      "âœ… Normalized Hand Right:\n",
      "  min: [-0.5 -0.5 -0.5 -0.5 -0.5]\n",
      "  max: [0.5 0.5 0.5 0.5 0.5]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ì •ê·œí™”ëœ ë°ì´í„° ê²½ë¡œ\n",
    "NORM_TRAIN_DIR = \"/teamspace/studios/this_studio/training/train/norm_keypoint\"\n",
    "\n",
    "# ëˆ„ì  ì €ì¥\n",
    "pose_all, left_all, right_all = [], [], []\n",
    "\n",
    "# ëª¨ë“  ì •ê·œí™”ëœ train json ì½ê¸°\n",
    "norm_files = sorted(glob(os.path.join(NORM_TRAIN_DIR, \"*.json\")))\n",
    "for file in tqdm(norm_files, desc=\"ğŸ” Checking normalized data\"):\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    for frame in data['frames']:\n",
    "        if frame.get('pose'): pose_all.append(frame['pose'])\n",
    "        if frame.get('hand_left'): left_all.append(frame['hand_left'])\n",
    "        if frame.get('hand_right'): right_all.append(frame['hand_right'])\n",
    "\n",
    "# numpy ë³€í™˜\n",
    "pose_all = np.array(pose_all)\n",
    "left_all = np.array(left_all)\n",
    "right_all = np.array(right_all)\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(\"âœ… Normalized Pose:\")\n",
    "print(\"  mean:\", np.round(pose_all.mean(axis=0)[:5], 4))\n",
    "print(\"  std: \", np.round(pose_all.std(axis=0)[:5], 4))\n",
    "\n",
    "print(\"\\nâœ… Normalized Hand Left:\")\n",
    "print(\"  min:\", np.round(left_all.min(axis=0)[:5], 4))\n",
    "print(\"  max:\", np.round(left_all.max(axis=0)[:5], 4))\n",
    "\n",
    "print(\"\\nâœ… Normalized Hand Right:\")\n",
    "print(\"  min:\", np.round(right_all.min(axis=0)[:5], 4))\n",
    "print(\"  max:\", np.round(right_all.max(axis=0)[:5], 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17e658fc-a702-45a5-ae0f-44297d653e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ” Skip Sampling Augmentation (train only): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3183/3183 [1:05:35<00:00,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… ëª¨ë“  train íŒŒì¼ì—ì„œ augmentation ê²°ê³¼ë¥¼ '/teamspace/studios/this_studio/training/train/augmented_keypoint'ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.\n",
      "ğŸ” ì¤‘ë³µëœ frameì´ í¬í•¨ëœ augmentation ìˆ˜: 288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Data Augmentation via Skip Sampling ì ìš© (ì¤‘ë³µëœ frame ì¶œë ¥)\n",
    "\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import copy\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ì„¤ì •\n",
    "NORM_DIR = \"/teamspace/studios/this_studio/training/train/norm_keypoint\"\n",
    "AUG_DIR = \"/teamspace/studios/this_studio/training/train/augmented_keypoint\"\n",
    "os.makedirs(AUG_DIR, exist_ok=True)\n",
    "\n",
    "AUG_FACTOR = 50\n",
    "N_FRAMES_SAMPLED = 50\n",
    "\n",
    "file_list = sorted(glob(os.path.join(NORM_DIR, \"*_norm.json\")))\n",
    "\n",
    "# ì¤‘ë³µì´ ë°œìƒí•œ augmentation ìˆ˜\n",
    "duplicate_aug_count = 0\n",
    "\n",
    "def safe_sampling_indices(l, n):\n",
    "    z = int(np.floor(l / (n - 1)))\n",
    "    y = int(np.floor((l - z * (n - 1)) / 2))\n",
    "    baseline_idx = [y + z * k for k in range(n)]\n",
    "\n",
    "    # soft clipping\n",
    "    if baseline_idx[-1] >= l:\n",
    "        baseline_idx[-1] = l - 1\n",
    "\n",
    "    return baseline_idx, z\n",
    "\n",
    "for src_path in tqdm(file_list, desc=\"ğŸ” Skip Sampling Augmentation (train only)\"):\n",
    "    basename = os.path.basename(src_path)\n",
    "    file_idx = basename.replace('_norm.json', '')\n",
    "\n",
    "    with open(src_path, 'r', encoding='utf-8') as f:\n",
    "        src_data = json.load(f)\n",
    "\n",
    "    frames = src_data['frames']\n",
    "    l = len(frames)\n",
    "    n = N_FRAMES_SAMPLED\n",
    "\n",
    "    if l < n:\n",
    "        # ê¸¸ì´ ë¶€ì¡± ì‹œ íŒ¨ë”©\n",
    "        indices = list(range(l)) + [l - 1] * (n - l)\n",
    "        sampled_frames = [frames[i] for i in indices]\n",
    "        new_data = copy.deepcopy(src_data)\n",
    "        new_data['frames'] = sampled_frames\n",
    "        for i, frame in enumerate(new_data['frames']):\n",
    "            frame['frame_idx'] = i\n",
    "        save_path = os.path.join(AUG_DIR, f\"augmented_{file_idx}_1.json\")\n",
    "        with open(save_path, 'w', encoding='utf-8') as wf:\n",
    "            json.dump(new_data, wf, ensure_ascii=False, indent=2)\n",
    "    else:\n",
    "        baseline_idx, z = safe_sampling_indices(l, n)\n",
    "\n",
    "        if z == 1:\n",
    "            indices = [min(l - 1, max(0, idx)) for idx in baseline_idx]\n",
    "            sampled_frames = [frames[i] for i in indices]\n",
    "            new_data = copy.deepcopy(src_data)\n",
    "            new_data['frames'] = sampled_frames\n",
    "            for i, frame in enumerate(new_data['frames']):\n",
    "                frame['frame_idx'] = i\n",
    "            save_path = os.path.join(AUG_DIR, f\"augmented_{file_idx}_1.json\")\n",
    "            with open(save_path, 'w', encoding='utf-8') as wf:\n",
    "                json.dump(new_data, wf, ensure_ascii=False, indent=2)\n",
    "        else:\n",
    "            for aug_idx in range(1, AUG_FACTOR + 1):\n",
    "                indices = []\n",
    "                for k in range(n):\n",
    "                    base = baseline_idx[k]\n",
    "                    if base >= l - 1:\n",
    "                        noise = 0\n",
    "                    else:\n",
    "                        noise_max = max(1, l - 1 - base) if k == n - 1 else max(1, z)\n",
    "                        noise = random.randint(0, noise_max - 1)\n",
    "                    idx = min(base + noise, l - 1)\n",
    "                    indices.append(idx)\n",
    "\n",
    "                # âœ… ì¤‘ë³µ ì—¬ë¶€ í™•ì¸\n",
    "                if len(set(indices)) < len(indices):\n",
    "                    duplicate_aug_count += 1\n",
    "\n",
    "                sampled_frames = [frames[i] for i in indices]\n",
    "                new_data = copy.deepcopy(src_data)\n",
    "                new_data['frames'] = sampled_frames\n",
    "                for i, frame in enumerate(new_data['frames']):\n",
    "                    frame['frame_idx'] = i\n",
    "                save_path = os.path.join(AUG_DIR, f\"augmented_{file_idx}_{aug_idx}.json\")\n",
    "                with open(save_path, 'w', encoding='utf-8') as wf:\n",
    "                    json.dump(new_data, wf, ensure_ascii=False, indent=2)\n",
    "\n",
    "# ğŸ”š ìµœì¢… ê²°ê³¼ ì¶œë ¥\n",
    "print(f\"\\nâœ… ëª¨ë“  train íŒŒì¼ì—ì„œ augmentation ê²°ê³¼ë¥¼ '{AUG_DIR}'ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.\")\n",
    "print(f\"ğŸ” ì¤‘ë³µëœ frameì´ í¬í•¨ëœ augmentation ìˆ˜: {duplicate_aug_count:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66528bf6-32dc-465d-adb7-14f4b1c9ad28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“š Korean Text Samples (max 50):\n",
      "\n",
      "01. í™”ì¬ê´€ë ¨, ì¤‘êµ¬ ë¶ì„±ë™ì—ì„œ í™”ì¬ê°€ ë°œìƒí•˜ì—¬ ì§„ì••ì¤‘ì´ë‹ˆ ì¸ê·¼ ì£¼ë¯¼ë“¤ê»˜ì„œëŠ” ì•ˆì „ì— ìœ ì˜í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "02. 7.8 07:37 êµ¬í¬ë™ 516ë²ˆì§€ ì¼ì› ë‹¨ë…ì£¼íƒ í™”ì¬ ë°œìƒìœ¼ë¡œ ì¼ëŒ€ê°€ í˜¼ì¡í•˜ì˜¤ë‹ˆ ì£¼ë¯¼ë“¤ê»˜ì„œëŠ” ì™¸ì¶œì„ ìì œí•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "03. ê¸ˆì¼ 09:30 ê³ ì–‘ì‹œ ì¼ì‚°ì„œêµ¬ ë•ì´ë™ 177-19ë²ˆì§€ ì¸ê·¼ì— í™”ì¬ ë°œìƒ. ì´ ì§€ì—­ì„ ìš°íšŒí•˜ì—¬ ì£¼ì‹œê³  ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „ì‚¬ê³  ë°œìƒì— ìœ ì˜ ë°”ëë‹ˆë‹¤.\n",
      "04. ì˜¤ëŠ˜ 09:17 ëŒ€ì „ì‹œ ë™êµ¬ ìƒì†Œë™ 628-22ë²ˆì§€ ì¸ê·¼ ë‹¨ë…ì£¼íƒ í™”ì¬ ë°œìƒ. ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „í•œ ê³³ìœ¼ë¡œ ëŒ€í”¼í•˜ê³  ì°¨ëŸ‰ì€ ìš°íšŒ ë°”ëë‹ˆë‹¤.\n",
      "05. ì˜¤ëŠ˜ 09:00 ìš°ì¥ì‚° ìŠ¤í¬ì¸ ì„¼í„° í™”ì¬ ë°œìƒ. ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „í•œ ê³³ìœ¼ë¡œ ëŒ€í”¼í•˜ì—¬ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "06. ì˜¤ëŠ˜ 09:30 ë‚¨ì›ì‹œ ì‚¬ë§¤2í„°ë„ ì¸ê·¼ ì „ì£¼íì°¨ì¥ì—ì„œ í™”ì¬ ë°œìƒ, ì¸ê·¼ì£¼ë¯¼ê»˜ì„œëŠ” í™”ì¬ ë“± ì•ˆì „ì— ìœ ì˜í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "07. ì˜¤ëŠ˜ 12:40 ì˜¤í¬ì ë¬¸í˜•ë¦¬ 908-36ë²ˆì§€ ëŒ€í˜•í™”ì¬ ë°œìƒ. ì´ ì§€ì—­ì„ ìš°íšŒí•˜ì—¬ ì£¼ì‹œê³  ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „ì‚¬ê³  ë°œìƒì— ìœ ì˜ ë°”ëë‹ˆë‹¤.\n",
      "08. ë™ì â†’ì„í¬ í–‰ ë„ë¡œ íƒ±í¬ë¡œë¦¬ í™”ì¬ ì‚¬ê³ . íƒ±í¬ë¡œë¦¬ í™”ì¬ë¡œ ì¸í•˜ì—¬ ì „ë©´í†µì œ í•˜ì˜¤ë‹ˆ ìš°íšŒí•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "09. ì˜¤ëŠ˜ 14:50 ë‚¨êµ¬ ëŒ€ëª…ë™ 995-96ë²ˆì§€ ì¸ê·¼ì— í™”ì¬ê°€ ë°œìƒí•˜ì˜€ìœ¼ë‹ˆ, ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „ì‚¬ê³ ì— ì£¼ì˜í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤\n",
      "10. ì˜¤ëŠ˜ ì˜¤í›„ 7ì‹œë¶€í„° ê´‘ëª…ì‹œ ë…¸ì˜¨ì‚¬ë™ ë¹„ë‹í•˜ìš°ìŠ¤ì—ì„œ í™”ì¬ ë°œìƒ, ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „í•œ ê³³ìœ¼ë¡œ ëŒ€í”¼ ë°”ëë‹ˆë‹¤.\n",
      "11. ê¸ˆì¼ 09:02 ê´‘ëª…ì‹œ ë…¸ì˜¨ì‚¬ë™ ì‹ ëŒ€í˜¸ìˆ˜ì‚¬ê±°ë¦¬ ê³ ê°€ë„ë¡œ í™”ì¬ ë°œìƒ, ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „í•œ ê³³ìœ¼ë¡œ ëŒ€í”¼í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "12. ì˜¤ëŠ˜ 07:50 ìƒë™ë©´ ìš°ê³„ë¦¬ 479-88 ì†¡ìœ ê´€ê³µì‚¬ í™”ì¬ ë°œìƒìœ¼ë¡œ ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „ì‚¬ê³ ì— ìœ ì˜í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "13. 04ì‹œ 15ë¶„ê²½ ì˜¤í¬ì ë¬¸í˜•ë¦¬ 312-79ë²ˆì§€ ì˜¤í”¼ìŠ¤í…” í™”ì¬ ë°œìƒ. ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „í•œ ê³³ìœ¼ë¡œ ëŒ€í”¼í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "14. ì˜¤ëŠ˜ 16:20 ì„ë‚¨ë™ 840-21 í™”ì¬ ë°œìƒ. ì£¼ë³€ìœ¼ë¡œ í™•ì‚°ë  ìš°ë ¤ê°€ ìˆìœ¼ë‹ˆ ì¸ê·¼ ì£¼ë¯¼ì€ ëŒ€í”¼ ë°”ëë‹ˆë‹¤.\n",
      "15. ì•ˆì „ì•ˆë‚´.ì˜¤ëŠ˜ 09:34 ì„œìš¸ ì—­ì´Œë©´ ë¡¯ë°ë¦¬ì•„ í™”ì¬ ë°œìƒ, ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „ì— ìœ ì˜í•˜ì„¸ìš”!\n",
      "16. ê¸ˆì¼ 11:30 ê³ ì”ë™ í™”ì¬ ë°œìƒ. ì¸ê·¼ ì£¼ë¯¼ì€ ì™¸ì¶œì„ ìì œí•˜ëŠ” ë“± ì•ˆì „ì‚¬ê³  ë°œìƒì— ìœ ì˜ ë°”ëë‹ˆë‹¤.\n",
      "17. ì˜¤ëŠ˜ 03ì‹œ ì„œìš¸ ê´‘ì§„êµ¬ ê´‘ì¥ì—ì„œ í™”ì¬ê°€ ë°œìƒí•˜ì˜€ìœ¼ë‹ˆ, ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „ì‚¬ê³  ë°œìƒì— ìœ ì˜í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "18. ì˜¤ëŠ˜ 09:43 ê´‘ëª…ë™ 513-28 ë°±ë‘í•œì–‘ì•„íŒŒíŠ¸ í™”ì¬ ë°œìƒ, ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „í•œ ê³³ìœ¼ë¡œ ëŒ€í”¼ë°”ëë‹ˆë‹¤.\n",
      "19. ê¸ˆì¼ 15ì‹œ 10ë¶„ê²½ ë°˜ì—¬ë†ì‚°ë¬¼ì‹œì¥ í™”ì¬ë¡œ ì¸í•´ ì–‘ë™ íƒœí‰êµ ì£¼ë³€ êµí†µì´ ì •ì²´ë˜ì˜¤ë‹ˆ ìš°íšŒí•˜ì—¬ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "20. ì˜¤ëŠ˜ 08:32 í•´ìš´ëŒ€ ìš°ë™ 12-1 ê±´ë¬¼ í™”ì¬ë°œìƒ. ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „í•œ ê³³ìœ¼ë¡œ ëŒ€í”¼í•˜ì—¬ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "21. ì˜¤ëŠ˜ 16ì‹œ 10ë¶„ê²½ ì„ë‚¨ë™ 920-23 ì¸ê·¼ì—ì„œ í™”ì¬ ë°œìƒ, ì¸ê·¼ ì£¼ë¯¼ì€ ì°½ë¬¸ì„ ë‹«ì•„ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "22. ì˜¤ëŠ˜ 12:30 í˜„ì¬ ì‚¬ì²œë©´ ê³µì¥ í™”ì¬ ë°œìƒ. ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „ì‚¬ê³  ë°œìƒì— ìœ ì˜ ë°”ëë‹ˆë‹¤.\n",
      "23. ì£¼ì²œë©´ ì‹ ì›”ë¦¬ ì¸ê·¼ ë„ë¡œ íƒ±í¬ë¡œë¦¬ í™”ì¬ ì‚¬ê³ ë°œìƒìœ¼ë¡œ ì¸ê·¼ ë„ë¡œê°€ í˜¼ì¡í•˜ì˜¤ë‹ˆ ìš°íšŒí•˜ì—¬ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "24. ì˜¤ëŠ˜ 09:20 ê³ ì–‘ì‹œ ì¼ì‚°ì„œêµ¬ ë•ì´ë™ 809-65ë²ˆì§€ ì¼ì‚°ë„ì›ì°½ íì°¨ì¥ì—ì„œ í™”ì¬ ë°œìƒìœ¼ë¡œ ì¼ëŒ€ê°€ í˜¼ì¡í•˜ì˜¤ë‹ˆ ìš°íšŒ ë°”ëë‹ˆë‹¤.\n",
      "25. ì˜¤ëŠ˜ 09:00 ìš´ë³´ì‚°ì—… ê³µì¥ í™”ì¬ ë°œìƒ. ì´ ì§€ì—­ì„ ìš°íšŒí•˜ì—¬ ì£¼ì‹œê³  ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „ì‚¬ê³  ë°œìƒì— ìœ ì˜ ë°”ëë‹ˆë‹¤.\n",
      "26. ì˜¤ëŠ˜ 09:00 ë‹¬ë™ ì‚¼í™˜ì•„ë¥´ëˆ„ë³´ ì•„íŒŒíŠ¸ í™”ì¬ë¡œ ì¸í•œ ì•„íŒŒíŠ¸ë‹¨ì§€ ë‚´ ë„ë¡œí†µì œ ì¤‘ì´ì˜¤ë‹ˆ, ìš°íšŒí•˜ì—¬ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "27. 8ì›” 31ì¼ 6ì‹œ 2ë¶„ ì˜ì™•ì‹œ ê³ ì²œë™ 614-18ë²ˆì§€ í™”ì¬ë°œìƒ, ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „í•œ ê³³ìœ¼ë¡œ ëŒ€í”¼í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "28. ì˜¤ëŠ˜ 09:30 ê´€ì €ë™ 925-80ë²ˆì§€ ê·¼ìƒê±´ë¬¼ í™”ì¬ ë°œìƒ, ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „ì— ì£¼ì˜í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "29. ê¸ˆì¼ 14:10 ì‚¬í•˜êµ¬ ë™ì•„ê³µê³  ì²´ìœ¡ê´€ ê³µì‚¬ì¥ í™”ì¬ë°œìƒìœ¼ë¡œ ì¸ê·¼ ë„ë¡œê°€ í˜¼ì¡í•˜ì˜¤ë‹ˆ ìš°íšŒí•˜ì—¬ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "30. ì˜¤ëŠ˜ 09:00 ê´€ì €ë™ 740-46 ê±´ë¬¼í™”ì¬ ë°œìƒ, ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „ì— ìœ ì˜í•˜ê¸° ë°”ëë‹ˆë‹¤.\n",
      "31. ê¸ˆì¼ 10:30 ìŒì‹ë¬¼ìì›ì‹œì„¤ í™”ì¬ ë°œìƒìœ¼ë¡œ ë‹¤ëŸ‰ì˜ ì—°ê¸° ë°œìƒ, ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „ì— ì£¼ì˜í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "32. ì˜¤ëŠ˜ 09:39 ì˜ì™•ì‹œ ê³ ì²œë™ 675-24 í™”ì¬ ë°œìƒ. ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „ì‚¬ê³  ë°œìƒì— ì£¼ì˜ ë°”ëë‹ˆë‹¤.\n",
      "33. ì˜¤ëŠ˜ 08:26 ê´‘ëª…ë™ 937-30 ê´‘ëª…ì¢…í•©í™”ë ¥ë°œì „ì†Œ í™”ì¬ ë°œìƒ, ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „ì— ìœ ì˜ë°”ëë‹ˆë‹¤.\n",
      "34. ì˜¤ëŠ˜ 09:48 ì„œêµ¬ ë¹„ì‚°ë™ 926-40 í™”ì¬ ë°œìƒ. ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „ì‚¬ê³  ë°œìƒì— ìœ ì˜í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "35. 10.26 12:33 ê´‘ì§„êµ¬ ì—¼í¬ë¶€ë‘ì— ì •ë°•ì¤‘ì¸ ì„ ë°• í™”ì¬ë¡œ ì°¨ëŸ‰í†µí–‰ì„ ì „ë©´í†µì œí•˜ì˜¤ë‹ˆ ìš°íšŒí•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "36. ì˜¤ëŠ˜ 08:40 ê´‘ëª…ì‹œ ë…¸ì˜¨ì‚¬ë™ ë¹„ë‹í•˜ìš°ìŠ¤ í™”ì¬ ë°œìƒ. ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „í•œ ê³³ìœ¼ë¡œ ëŒ€í”¼í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "37. ì˜¤ëŠ˜ 08:00 ì„œêµ¬ ë¹„ì‚°ë™ 971-78ë²ˆì§€ í™”ì¬ ë°œìƒ, ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „ì— ì£¼ì˜í•˜ì„¸ìš”\n",
      "38. ì˜¤ëŠ˜ 02ì‹œ40ë¶„ êµ¬í¬ë™ 516-98ë²ˆì§€ ë‹¨ë…ì£¼íƒ í™”ì¬ ë°œìƒ, ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „ì— ì£¼ì˜ ë°”ëë‹ˆë‹¤.\n",
      "39. ì˜¤ëŠ˜ 09:50 ìƒë™ë©´ ì†Œì¬ ê³ ì”ë™ 902-83ë²ˆì§€ í™”ì¬ ë°œìƒ. ì´ ì§€ì—­ì„ ìš°íšŒí•˜ì—¬ ì£¼ì‹œê³  ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „ì‚¬ê³  ë°œìƒì— ìœ ì˜ ë°”ëë‹ˆë‹¤.\n",
      "40. ì˜¤ëŠ˜ 11ì‹œ 40ë¶„ê²½ ì„œìš¸ ì˜ë“±í¬êµ¬ ë„ë¦¼ë™ì— í™”ì¬ ë°œìƒ. ì¸ê·¼ ì£¼ë¯¼ì€ ì°½ë¬¸ì„ ë‹«ê³  ì°¨ëŸ‰ì€ ìš°íšŒí•˜ê¸° ë°”ëë‹ˆë‹¤.\n",
      "41. ì˜¤ëŠ˜ 09:10 ê°ì „ë™ ê´‘ì¼ì¼€ë¯¸ìŠ¤í‹¸ ë’¤ í™”ì¬ ë°œìƒ, ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „ì‚¬ê³  ë°œìƒì— ìœ ì˜í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "42. ì˜¤ëŠ˜ 04:22 ì„œêµ¬ ë¹„ì‚°ë™ 672-64ë²ˆì§€ ì¸ê·¼ì—ì„œ ë°œìƒí•œ í™”ì¬ë¡œ ì¸ê·¼ ë„ë¡œê°€ í˜¼ì¡í•˜ì˜¤ë‹ˆ ìš°íšŒí•˜ì—¬ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "43. ì˜¤ëŠ˜ 00:00 ê³ ì”ë™ 897-83 ì†¡ìœ ê´€ê³µì‚¬ í™”ì¬ ë°œìƒ. ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „í•œ ê³³ìœ¼ë¡œ ëŒ€í”¼í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "44. ì˜¤ëŠ˜ 15:00 ë‹¬ë™ ë‹¬ë™ì§€ í™”ì¬ ë°œìƒ. ë‹¬ë™ê¸° ì£¼ë³€ ì§€ì—­ì£¼ë¯¼ë“¤ê»˜ì„œëŠ” ì•ˆì „ì— ìœ ì˜í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "45. ê¸ˆì¼ 09:30 ì˜¤í¬ì ë¬¸í˜•ë¦¬ ë°±ë‘í•œì–‘ ì•„íŒŒíŠ¸ í™”ì¬ ë°œìƒ. ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „í•œ ê³³ìœ¼ë¡œ ëŒ€í”¼í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "46. ì˜¤ëŠ˜ 08:53 ì›”ì‚°ë©´ ì›”ì‚°ë¦¬ 719-40 ë°±ë‘í•œì–‘ì•„íŒŒíŠ¸ í™”ì¬ë°œìƒ, ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „ì‚¬ê³  ë°œìƒì— ìœ ì˜ ë°”ëë‹ˆë‹¤.\n",
      "47. 7.26 18:00 ê´‘ëª…ì‹œ ë…¸ì˜¨ì‚¬ë™ ë¹„ë‹í•˜ìš°ìŠ¤ í™”ì¬ ë°œìƒ, ì¸ê·¼ ì£¼ë¯¼ë“¤ì€ ì•ˆì „ì— ì£¼ì˜í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "48. ì˜¤ëŠ˜ 09:00 ë°œìƒí•œ ìš©ì•”ë™ ë¶€ì˜3ì°¨ í™”ì¬ ì§„ì••ìœ¼ë¡œ ì¸ê·¼ ë„ë¡œê°€ í˜¼ì¡í•˜ì˜¤ë‹ˆ ìš°íšŒí•˜ì—¬ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "49. ì˜¤ëŠ˜ 09:00 ì¤‘êµ¬ ì‹ ë‹¹ë™ ë™ëŒ€ë¬¸ì—­ì‚¬ë¬¸í™”ê³µì› ì¸ê·¼ì—ì„œ ëŒ€í˜•í™”ì¬ ë°œìƒ. ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „ì— ì£¼ì˜ ë°”ëë‹ˆë‹¤.\n",
      "50. 05ì‹œ 40ë¶„ë¶€í„° ê´‘ëª…ë™ 593-412ë²ˆì§€ í™”ì¬ ë°œìƒ, ì¸ê·¼ ì£¼ë¯¼ë“¤ì€ ì•ˆì „ì— ìœ ì˜í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# 50ê°œì˜ í”„ë ˆì„ì€ ë„ˆë¬´ ì‘ì€ ê±° ì•„ë‹ê¹Œ? - 100 í”„ë ˆì„ìœ¼ë¡œ ëŠ˜ë¦¬ëŠ” ê²ƒ ê³ ë ¤\n",
    "# í•™ìŠµ ìì²´ê°€ ì–´ë ¤ìš¸ ìˆ˜ ìˆìŒ (ê³ ìœ ëª…ì‚¬ê°€ ë„ˆë¬´ ë§ê³  ë°ì´í„°ê°€ ë¶€ì¡±)\n",
    "\n",
    "import os\n",
    "import json\n",
    "from glob import glob\n",
    "import random\n",
    "\n",
    "# ğŸ”§ ê²½ë¡œ ì„¤ì •: train ê¸°ì¤€\n",
    "MERGED_DIR = \"/teamspace/studios/this_studio/training/train/merged_keypoint\"  # ë˜ëŠ” norm_keypoint\n",
    "file_list = sorted(glob(os.path.join(MERGED_DIR, \"*.json\")))\n",
    "\n",
    "# ğŸ”€ ë¬´ì‘ìœ„ 50ê°œ ìƒ˜í”Œ ì¶”ì¶œ\n",
    "sample_files = random.sample(file_list, 50)\n",
    "\n",
    "# ğŸ” korean_text ì¶”ì¶œ\n",
    "texts = []\n",
    "for path in sample_files:\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "        text = data.get(\"korean_text\", \"\").strip()\n",
    "        if text:  # ë¹ˆ ë¬¸ì¥ ì œì™¸\n",
    "            texts.append(text)\n",
    "\n",
    "# ğŸ“¤ ì¶œë ¥\n",
    "print(\"ğŸ“š Korean Text Samples (max 50):\\n\")\n",
    "for i, t in enumerate(texts, 1):\n",
    "    print(f\"{i:02d}. {t}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ba00785-ce30-4650-ad6b-6bf1b7ef5d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "END_PATTERNS = [\n",
    "    \"ë°”ëë‹ˆë‹¤\", \"ì£¼ì‹­ì‹œì˜¤\", \"ì£¼ì„¸ìš”\", \"ì£¼ì‹œì˜¤\",\n",
    "    \"ê¶Œê³ ë“œë¦½ë‹ˆë‹¤\", \"ì•ˆë‚´ë“œë¦½ë‹ˆë‹¤\", \"ì•Œë ¤ë“œë¦½ë‹ˆë‹¤\",\n",
    "    \"í•˜ì‹­ì‹œì˜¤\", \"í•˜ì‹­ì‹œì˜¤.\", \"í•´ ì£¼ì‹­ì‹œì˜¤\", \"í•´ ì£¼ì„¸ìš”\"\n",
    "]\n",
    "\n",
    "def extract_expanded_endings(json_dir: str, field=\"korean_text\", top_n=50):\n",
    "    from collections import Counter\n",
    "    from pathlib import Path\n",
    "    import json\n",
    "\n",
    "    counter = Counter()\n",
    "\n",
    "    for file in Path(json_dir).glob(\"*.json\"):\n",
    "        with open(file, encoding=\"utf-8\") as f:\n",
    "            text = json.load(f).get(field, \"\").strip()\n",
    "\n",
    "        for n in range(4, 20):  # ìµœëŒ€ 20ê¸€ìê¹Œì§€ ë’¤ì—ì„œ ì˜ë¼ë´„\n",
    "            candidate = text[-n:]\n",
    "            if any(p in candidate for p in END_PATTERNS):\n",
    "                counter[candidate] += 1\n",
    "\n",
    "    return counter.most_common(top_n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88a41332-38d7-4a37-ad82-0db7a430b52b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë°”ëë‹ˆë‹¤.: 2892\n",
      " ë°”ëë‹ˆë‹¤.: 2664\n",
      "ê¸° ë°”ëë‹ˆë‹¤.: 1917\n",
      "ì‹œê¸° ë°”ëë‹ˆë‹¤.: 1832\n",
      "í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.: 1411\n",
      "ì˜í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.: 849\n",
      "ìœ ì˜í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.: 560\n",
      " ìœ ì˜í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.: 560\n",
      "ì— ìœ ì˜í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.: 559\n",
      "ì˜ ë°”ëë‹ˆë‹¤.: 554\n",
      "ìœ ì˜ ë°”ëë‹ˆë‹¤.: 429\n",
      " ìœ ì˜ ë°”ëë‹ˆë‹¤.: 429\n",
      "ì— ìœ ì˜ ë°”ëë‹ˆë‹¤.: 429\n",
      "ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.: 421\n",
      " ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.: 405\n",
      "ìƒì— ìœ ì˜ ë°”ëë‹ˆë‹¤.: 331\n",
      "ë°œìƒì— ìœ ì˜ ë°”ëë‹ˆë‹¤.: 331\n",
      " ë°œìƒì— ìœ ì˜ ë°”ëë‹ˆë‹¤.: 331\n",
      "ê³  ë°œìƒì— ìœ ì˜ ë°”ëë‹ˆë‹¤.: 331\n",
      "ì‚¬ê³  ë°œìƒì— ìœ ì˜ ë°”ëë‹ˆë‹¤.: 331\n",
      "ì „ì‚¬ê³  ë°œìƒì— ìœ ì˜ ë°”ëë‹ˆë‹¤.: 331\n",
      "ì•ˆì „ì‚¬ê³  ë°œìƒì— ìœ ì˜ ë°”ëë‹ˆë‹¤.: 331\n",
      " ì•ˆì „ì‚¬ê³  ë°œìƒì— ìœ ì˜ ë°”ëë‹ˆë‹¤.: 331\n",
      "ì€ ì•ˆì „ì‚¬ê³  ë°œìƒì— ìœ ì˜ ë°”ëë‹ˆë‹¤.: 320\n",
      "í”¼í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.: 314\n",
      "ëŒ€í”¼í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.: 314\n",
      " ëŒ€í”¼í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.: 314\n",
      "ì „ì— ìœ ì˜í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.: 294\n",
      "ì•ˆì „ì— ìœ ì˜í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.: 294\n",
      " ì•ˆì „ì— ìœ ì˜í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.: 291\n",
      "ì£¼ì˜í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.: 289\n",
      " ì£¼ì˜í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.: 289\n",
      "ë¡œ ëŒ€í”¼í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.: 268\n",
      "ì—¬ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.: 264\n",
      "í•˜ì—¬ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.: 264\n",
      "ìœ¼ë¡œ ëŒ€í”¼í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.: 262\n",
      "ê³³ìœ¼ë¡œ ëŒ€í”¼í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.: 253\n",
      " ê³³ìœ¼ë¡œ ëŒ€í”¼í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.: 253\n",
      "í•œ ê³³ìœ¼ë¡œ ëŒ€í”¼í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.: 253\n",
      "ì „í•œ ê³³ìœ¼ë¡œ ëŒ€í”¼í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.: 253\n",
      "ì•ˆì „í•œ ê³³ìœ¼ë¡œ ëŒ€í”¼í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.: 253\n",
      "ì— ì£¼ì˜í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.: 252\n",
      "ìƒì— ìœ ì˜í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.: 203\n",
      "ë°œìƒì— ìœ ì˜í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.: 203\n",
      " ë°œìƒì— ìœ ì˜í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.: 200\n",
      "ê³  ë°œìƒì— ìœ ì˜í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.: 200\n",
      "ì‚¬ê³  ë°œìƒì— ìœ ì˜í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.: 200\n",
      "ì „ì‚¬ê³  ë°œìƒì— ìœ ì˜í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.: 200\n",
      "íšŒí•˜ì—¬ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.: 166\n",
      "ìš°íšŒí•˜ì—¬ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.: 166\n"
     ]
    }
   ],
   "source": [
    "top_endings = extract_expanded_endings(\"training/train/norm_keypoint\")\n",
    "for phrase, count in top_endings:\n",
    "    print(f\"{phrase}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af19321a-6375-4d89-8c32-95ef0c5da4bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 3183 files in: training/train/norm_keypoint\n",
      "Processing 408 files in: training/val/norm_keypoint\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# âœ… ìœ ì˜ ë°”ëë‹ˆë‹¤ë¡œ ì •ê·œí™”\n",
    "NORMALIZATION_DICT = {\n",
    "#    \"ì£¼ì˜í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤\": \"ìœ ì˜ ë°”ëë‹ˆë‹¤\",\n",
    "#    \"ìœ ì˜í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\": \"ìœ ì˜ ë°”ëë‹ˆë‹¤\",\n",
    "#    \"ìœ ì˜í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤\": \"ìœ ì˜ ë°”ëë‹ˆë‹¤\", \n",
    "    \"ì£¼ì˜ ë°”ëë‹ˆë‹¤\": \"ìœ ì˜ ë°”ëë‹ˆë‹¤\"\n",
    "}\n",
    "\n",
    "def normalize_text_fields(data: dict, norm_dict: dict) -> dict:\n",
    "    for key in [\"korean_text\", \"masked_korean_text\"]:\n",
    "        if key in data:\n",
    "            for from_expr, to_expr in norm_dict.items():\n",
    "                data[key] = data[key].replace(from_expr, to_expr)\n",
    "    return data\n",
    "\n",
    "def apply_normalization_to_dir(json_dir: Path):\n",
    "    json_files = list(json_dir.glob(\"*.json\"))\n",
    "    print(f\"Processing {len(json_files)} files in: {json_dir}\")\n",
    "    \n",
    "    for file in json_files:\n",
    "        with open(file, encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        # ì •ê·œí™” ì ìš©\n",
    "        data = normalize_text_fields(data, NORMALIZATION_DICT)\n",
    "\n",
    "        # ë®ì–´ì“°ê¸° ì €ì¥\n",
    "        with open(file, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# âœ… ì ìš© ëŒ€ìƒ ë””ë ‰í† ë¦¬\n",
    "train_dir = Path(\"training/train/norm_keypoint\")\n",
    "val_dir = Path(\"training/val/norm_keypoint\")\n",
    "\n",
    "# ğŸ” ì •ê·œí™” ì‹¤í–‰\n",
    "apply_normalization_to_dir(train_dir)\n",
    "apply_normalization_to_dir(val_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e073fee3-53eb-4331-8b0e-f67f6b9b666a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ Normalizing 'korean_text' in training/train/norm_keypoint: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3183/3183 [04:13<00:00, 12.53it/s]\n",
      "ğŸ“‚ Normalizing 'korean_text' in training/val/norm_keypoint: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 408/408 [00:32<00:00, 12.48it/s]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "def normalize_day_in_json(json_dir: str, field=\"korean_text\"):\n",
    "    files = list(Path(json_dir).glob(\"*.json\"))\n",
    "\n",
    "    for file in tqdm(files, desc=f\"ğŸ“‚ Normalizing '{field}' in {json_dir}\"):\n",
    "        with open(file, encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        if field in data:\n",
    "            original = data[field]\n",
    "            normalized = re.sub(r\"(ê¸ˆì¼|ë‹¹ì¼)\", \"ì˜¤ëŠ˜\", original)\n",
    "            data[field] = normalized\n",
    "\n",
    "        with open(file, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "train_dir = Path(\"training/train/norm_keypoint\")\n",
    "val_dir = Path(\"training/val/norm_keypoint\")\n",
    "\n",
    "normalize_day_in_json(train_dir)\n",
    "normalize_day_in_json(val_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4fc26671-d389-4b8d-adb7-30c9e9113bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ ê²°ê³¼ (in training/train/norm_keypoint):\n",
      "  ğŸ” 'ì£¼ì˜í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤': 0íšŒ\n",
      "  ğŸ” 'ìœ ì˜í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤': 0íšŒ\n",
      "  ğŸ” 'ìœ ì˜í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.': 0íšŒ\n",
      "  ğŸ” 'ì£¼ì˜ ë°”ëë‹ˆë‹¤': 0íšŒ\n",
      "  ğŸ” 'ìœ ì˜ ë°”ëë‹ˆë‹¤': 1437íšŒ\n",
      "ğŸ“‚ ê²°ê³¼ (in training/val/norm_keypoint):\n",
      "  ğŸ” 'ì£¼ì˜í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤': 0íšŒ\n",
      "  ğŸ” 'ìœ ì˜í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤': 0íšŒ\n",
      "  ğŸ” 'ìœ ì˜í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.': 0íšŒ\n",
      "  ğŸ” 'ì£¼ì˜ ë°”ëë‹ˆë‹¤': 0íšŒ\n",
      "  ğŸ” 'ìœ ì˜ ë°”ëë‹ˆë‹¤': 174íšŒ\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "# í™•ì¸í•˜ê³  ì‹¶ì€ í‘œí˜„ë“¤ (ì •ê·œí™” ì „ í‘œí˜„ + ì •ê·œí™” í›„ í‘œí˜„)\n",
    "CHECK_PHRASES = [\n",
    "    \"ì£¼ì˜í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤\",\n",
    "    \"ìœ ì˜í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤\",\n",
    "    \"ìœ ì˜í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\",\n",
    "    \"ì£¼ì˜ ë°”ëë‹ˆë‹¤\",\n",
    "    \"ìœ ì˜ ë°”ëë‹ˆë‹¤\"\n",
    "]\n",
    "\n",
    "def count_phrases_in_dir(json_dir: Path, check_phrases):\n",
    "    counter = Counter()\n",
    "    files = list(json_dir.glob(\"*.json\"))\n",
    "\n",
    "    for file in files:\n",
    "        with open(file, encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        for key in [\"korean_text\", \"masked_korean_text\"]:\n",
    "            text = data.get(key, \"\")\n",
    "            for phrase in check_phrases:\n",
    "                if phrase in text:\n",
    "                    counter[phrase] += 1\n",
    "\n",
    "    print(f\"ğŸ“‚ ê²°ê³¼ (in {json_dir}):\")\n",
    "    for phrase in check_phrases:\n",
    "        print(f\"  ğŸ” '{phrase}': {counter[phrase]}íšŒ\")\n",
    "\n",
    "# âœ… ì‹¤í–‰\n",
    "train_dir = Path(\"training/train/norm_keypoint\")\n",
    "val_dir = Path(\"training/val/norm_keypoint\")\n",
    "\n",
    "count_phrases_in_dir(train_dir, CHECK_PHRASES)\n",
    "count_phrases_in_dir(val_dir, CHECK_PHRASES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b0263c-2391-4f5c-9d74-f9f3c830c9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… ê°€ì¥ ë§ˆì§€ë§‰ì— ë“±ì¥í•˜ëŠ” slot_valueë§Œ ì €ì¥í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ìœ ì§€í•˜ë©°,\n",
    "#    ë™ì‘ì„ ëª…í™•íˆ í•˜ê¸° ìœ„í•´ ë®ì–´ì“°ê¸° ë¡œì§ì„ ëª…ì‹œí•¨ (ê¸°ì¡´ì—ë„ ì´ ë°©ì‹ì´ì—ˆìŒ)\n",
    "\n",
    "import re\n",
    "from typing import Tuple, Dict\n",
    "\n",
    "def grouped_region_mask_korean_text_final(text: str) -> Tuple[str, Dict[str, str]]:\n",
    "    slot_values = {}\n",
    "    REGION_END = r'(?=\\s|[.,ì€ëŠ”ì´ê°€ì˜ì—ì—ì„œì™€]|[0-9]|$)'\n",
    "    JOSA = r\"(ì€|ëŠ”|ì´|ê°€|ì—|ì—ì„œ|ë¡œ|ë¥¼|ê³¼|ì™€|ë„|ê¹Œ|ê¹Œì§€|ë§Œ|ìœ¼ë¡œ|ìš”|ë„)\"\n",
    "    EXCLUDE_PATTERN = r'\\b[ê°€-í£]{1,10}(ì‚¬ê³ |ì¤‘|ë°œìƒ)\\b'\n",
    "    EXCLUDE_FOR_STATION = r'(ì‚¬ê±°ë¦¬|ì‚¼ê±°ë¦¬|ì˜¤ê±°ë¦¬|ë„ë¡œ|ê³ ê°€ë„ë¡œ|ì—­ì‚¬|í•˜ìƒë„ë¡œ|ì§€í•˜ì°¨ë„|ì°¨ë„|ìš°íšŒë„ë¡œ)'\n",
    "\n",
    "    patterns = [\n",
    "        (r'([0-2]?[0-9]:[0-5][0-9])', lambda m: [(\"<ì‹œê°„>\", m.group(1))]),\n",
    "        (r'([0-9]{1,2}ì‹œ\\s?[0-9]{0,2}ë¶„?)', lambda m: [(\"<ì‹œê°„>\", m.group(1))]),\n",
    "        # âœ… ë¨¼ì € ë³µí•© ì§€ì—­ ë‹¨ì–´ (ì‚° ë“¤ì–´ê°„ ì§€ì—­ ë°©ì–´ìš©)\n",
    "        (r'\\b[ê°€-í£]{2,10}(ì‹œ|êµ°|êµ¬|ì„œêµ¬|ë¶êµ¬|ë‚¨êµ¬|ë™êµ¬)\\b', lambda m: [(\"<ì§€ì—­>\", m.group(0))]),\n",
    "    \n",
    "        # âœ… ì‚° (ì˜ˆì™¸ ë‹¨ì–´ ë°©ì–´ í¬í•¨)\n",
    "        (r'(?<!ë¶€ì‚°)(?<!í™•ì‚°)(?<!ë“±ì‚°)(?<!ìš°ì‚°)(?<!íš¡ì‚°)([ê°€-í£]{1,10}ì‚°)(?=\\s|[.,ì€ëŠ”ì´ê°€ì˜ì—ì—ì„œì™€]|[0-9]|$)', \n",
    "         lambda m: [(\"<ì‚°>\", m.group(1))]),\n",
    "        (r'([ê°€-í£0-9]{1,20}(ì‚¬ê±°ë¦¬|ì‚¼ê±°ë¦¬|ì˜¤ê±°ë¦¬|ìœ¡ê±°ë¦¬)?\\s?(ê³ ê°€ë„ë¡œ|í•˜ìƒë„ë¡œ|ì§€í•˜ì°¨ë„|ë„ë¡œ|ì°¨ë„|ìš°íšŒë„ë¡œ))',\n",
    "         lambda m: [(\"<ë„ë¡œ>\", m.group(0))]),\n",
    "        (r'([ê°€-í£]{1,20}(ì‚¬ê±°ë¦¬|ì‚¼ê±°ë¦¬|ì˜¤ê±°ë¦¬|ìœ¡ê±°ë¦¬))',\n",
    "         lambda m: [(\"<ë„ë¡œ>\", m.group(1))]),\n",
    "        (rf'([ê°€-í£]{{1,10}}(ì|ë©´|ë™|ë¦¬))\\s([ê°€-í£]{{1,10}}(ë¦¬)){REGION_END}',\n",
    "         lambda m: [(\"<ì§€ì—­>\", f\"{m.group(1)} {m.group(3)}\")]),\n",
    "        (rf'([ê°€-í£]{{1,10}}(ì‹œ|ë„|êµ°|êµ¬))\\s?([ê°€-í£]{{1,10}}(ë™|ì|ë©´|ë¦¬)){REGION_END}',\n",
    "         lambda m: [(\"<ì§€ì—­>\", f\"{m.group(1)} {m.group(3)}\")]),\n",
    "        (r'\\b([ê°€-í£]{1,10}(ì‹œ|ë„|êµ°|êµ¬|ì|ë©´|ë™|ë¦¬))\\b', lambda m: [(\"<ì§€ì—­>\", m.group(1))]),\n",
    "        (r'([ê°€-í£]{2,10}[0-9]{1,2}ê°€)', lambda m: [(\"<ì£¼ì†Œ>\", m.group(1))]),\n",
    "        (r'([0-9]{1,5}-[0-9]{1,5}(ë²ˆì§€)?)', lambda m: [(\"<ì£¼ì†Œ>\", m.group(1))]),\n",
    "        (r'([ê°€-í£]{1,20}(ë¡œ|ê¸¸)\\s?[0-9]{1,4}(-[0-9]{1,4})?(ë²ˆì§€)?)', lambda m: [(\"<ì£¼ì†Œ>\", m.group(1))]),\n",
    "        (r'([0-9]{1,4}ë™)', lambda m: [(\"<ì£¼ì†Œ>\", m.group(1))]),\n",
    "        (r'([ê°€-í£A-Za-z0-9]{1,30}(ì•„íŒŒíŠ¸|ì˜¤í”¼ìŠ¤í…”|ì£¼íƒ|ê³ ì‹œì›|ë¹Œë”©|ê±´ë¬¼|ë§¨ì…˜|ì—°ë¦½ì£¼íƒ|ì‚¬ì˜¥|í•˜ìš°ìŠ¤|íƒ€ì›Œ|ìƒê°€|ì í¬|íšŒê´€|ì„¼í„°|ëª°|ëª¨ë¸í•˜ìš°ìŠ¤|ì•„ìš¸ë ›|ë°±í™”ì ))(?=\\s|' + JOSA + r'|\\b)',\n",
    "         lambda m: [(\"<ê±´ë¬¼>\", m.group(1))]),\n",
    "        (r'\\b(ê±´ë¬¼|ì•„íŒŒíŠ¸|ë¹Œë”©|ì£¼íƒ|í•˜ìš°ìŠ¤)\\b', lambda m: [(\"<ê±´ë¬¼>\", m.group(1))]),\n",
    "        (r'([ê°€-í£A-Za-z0-9]{1,30}(í˜¸í…”|ëª¨í…”|íœì…˜))', lambda m: [(\"<ìˆ™ë°•ì‹œì„¤>\", m.group(1))]),\n",
    "        (r'([ê°€-í£]{2,20}ê³µì›)', lambda m: [(\"<ê³µì›>\", m.group(1))]),\n",
    "        (r'([ê°€-í£]{2,10}ê³µê³ )', lambda m: [(\"<í•™êµ>\", m.group(1))]),\n",
    "        (rf'\\b(?!ì•ˆì „?ì‚¬ê³ )([ê°€-í£]{{2,10}}ê³ )(?={JOSA})', lambda m: [(\"<í•™êµ>\", m.group(1))]),\n",
    "        (rf'\\b((?!{EXCLUDE_FOR_STATION})[ê°€-í£0-9]{{2,20}}ì—­)(?=\\s|' + JOSA + r'|\\b)',\n",
    "         lambda m: [(\"<ì—­>\", m.group(1))]),\n",
    "        (EXCLUDE_PATTERN, lambda m: [(\"##EXCLUDE##\", m.group(0))]),\n",
    "    ]\n",
    "\n",
    "    matches = []\n",
    "    replaced_spans = []\n",
    "\n",
    "    # âœ… ì›ë³¸ text ê¸°ì¤€ìœ¼ë¡œ ì „ì²´ ë§¤ì¹˜ ìˆ˜ì§‘\n",
    "    for pattern, slot_func in patterns:\n",
    "        for match in re.finditer(pattern, text):\n",
    "            start, end = match.span()\n",
    "            if any(s < end and start < e for s, e in replaced_spans):\n",
    "                continue\n",
    "            for slot, value in slot_func(match):\n",
    "                if slot != \"##EXCLUDE##\":\n",
    "                    matches.append((start, end, slot, value))\n",
    "                    replaced_spans.append((start, end))\n",
    "                    slot_values[slot] = value  # âœ… í•­ìƒ ë§ˆì§€ë§‰ slot_valueë§Œ ì €ì¥ë¨\n",
    "                    break\n",
    "\n",
    "    # âœ… masked_textë¥¼ ë’¤ì—ì„œ ì•ìœ¼ë¡œ ì¹˜í™˜í•˜ì—¬ ì¸ë±ìŠ¤ ë³´ì¡´\n",
    "    masked_text = text\n",
    "    for start, end, slot, _ in sorted(matches, reverse=True):\n",
    "        masked_text = masked_text[:start] + slot + masked_text[end:]\n",
    "\n",
    "    return masked_text, slot_values\n",
    "\n",
    "\n",
    "# âœ… í…ŒìŠ¤íŠ¸\n",
    "text = \"ê¸ˆì¼ 10:10 ê³ ì”ë™ 102-57ë²ˆì§€ ì‚¼ì„±í™”ì¬ ê´‘ì£¼ìƒë¬´ì‚¬ì˜¥ 102-57í˜¸ì— í™”ì¬ ë°œìƒ. ì´ ì§€ì—­ì„ ìš°íšŒí•˜ì—¬ ì£¼ì‹œê³  ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „ì‚¬ê³  ë°œìƒì— ìœ ì˜ ë°”ëë‹ˆë‹¤.\"\n",
    "masked, slots = grouped_region_mask_korean_text_final(text)\n",
    "print(\"ğŸ”¹ Masked Text:\", masked)\n",
    "print(\"ğŸ”‘ Slot Values:\", slots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8522f551-9dd7-40cd-ab45-eea5c2468270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… ë§ˆìŠ¤í‚¹ ì ìš© ë° ì¶œë ¥\n",
    "TARGET_DIR = \"/teamspace/studios/this_studio/training/train/norm_keypoint\"\n",
    "print_limit = 200\n",
    "masked_results = []\n",
    "import re\n",
    "\n",
    "for path in sorted(glob(os.path.join(TARGET_DIR, \"*.json\")))[:print_limit]:\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    korean_text = data.get(\"korean_text\", \"\")\n",
    "    masked_text, slot_values = grouped_region_mask_korean_text_final(korean_text)\n",
    "\n",
    "    # ì €ì¥\n",
    "    data[\"masked_korean_text\"] = masked_text\n",
    "    data[\"slot_values\"] = slot_values\n",
    "    with open(path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    masked_results.append((os.path.basename(path), korean_text, masked_text, slot_values))\n",
    "\n",
    "for i, (fname, orig, masked, slots) in enumerate(masked_results[60:80], 1):\n",
    "    print(f\"ğŸ“ {i:02d}. File: {fname}\")\n",
    "    print(f\"ğŸ”¸ Original: {orig}\")\n",
    "    print(f\"ğŸ”¹ Masked  : {masked}\")\n",
    "    print(f\"ğŸ”‘ Slot Values: {json.dumps(slots, ensure_ascii=False)}\\n{'-'*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cefbee15-7a5d-41b8-ba79-0b1a90d4711e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ Masking in training/train/norm_keypoint: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3183/3183 [04:21<00:00, 12.18it/s]\n",
      "ğŸ“‚ Masking in training/val/norm_keypoint: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 408/408 [00:33<00:00, 12.28it/s]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ğŸ“Œ ë§ˆìŠ¤í‚¹ í•¨ìˆ˜ëŠ” ì´ë¯¸ ì •ì˜ë˜ì—ˆë‹¤ê³  ê°€ì • (grouped_region_mask_korean_text_final)\n",
    "\n",
    "def apply_masking_to_json_dir(json_dir: str, field=\"korean_text\"):\n",
    "    for file in tqdm(list(Path(json_dir).glob(\"*.json\")), desc=f\"ğŸ“‚ Masking in {json_dir}\"):\n",
    "        with open(file, encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        if field in data:\n",
    "            text = data[field].strip()\n",
    "            masked_text, slot_values = grouped_region_mask_korean_text_final(text)\n",
    "            data[\"masked_text\"] = masked_text\n",
    "            data[\"slot_values\"] = slot_values\n",
    "\n",
    "            with open(file, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# âœ… ê²½ë¡œ ì§€ì •\n",
    "train_dir = Path(\"training/train/norm_keypoint\")\n",
    "val_dir = Path(\"training/val/norm_keypoint\")\n",
    "\n",
    "# âœ… ì ìš©\n",
    "apply_masking_to_json_dir(train_dir)\n",
    "apply_masking_to_json_dir(val_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dd54a967-3fdf-49a3-b92a-b69d9b38a658",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ” Skip Sampling Augmentation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3183/3183 [29:31<00:00,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… ëª¨ë“  train íŒŒì¼ì—ì„œ augmentation ê²°ê³¼ë¥¼ '/teamspace/studios/this_studio/training/train/augmented_keypoint'ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.\n",
      "ğŸ” ì¤‘ë³µëœ frameì´ í¬í•¨ëœ augmentation ìˆ˜: 217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Augmentation via Skip Sampling (Masking ì´í›„)\n",
    "\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import copy\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ğŸ“ ë””ë ‰í† ë¦¬ ì„¤ì •\n",
    "NORM_DIR = \"/teamspace/studios/this_studio/training/train/norm_keypoint\"\n",
    "AUG_DIR = \"/teamspace/studios/this_studio/training/train/augmented_keypoint\"\n",
    "os.makedirs(AUG_DIR, exist_ok=True)\n",
    "\n",
    "# ğŸ“Œ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •\n",
    "AUG_FACTOR = 50\n",
    "N_FRAMES_SAMPLED = 100\n",
    "\n",
    "# íŒŒì¼ ëª©ë¡\n",
    "file_list = sorted(glob(os.path.join(NORM_DIR, \"*_norm.json\")))\n",
    "\n",
    "# ì¤‘ë³µ frame ë°œìƒ ìˆ˜ ê¸°ë¡ìš©\n",
    "duplicate_aug_count = 0\n",
    "\n",
    "# ğŸ”§ ê· ì¼ sampling ì¸ë±ìŠ¤ ê³„ì‚° í•¨ìˆ˜\n",
    "def safe_sampling_indices(l, n):\n",
    "    z = int(np.floor(l / (n - 1)))\n",
    "    y = int(np.floor((l - z * (n - 1)) / 2))\n",
    "    baseline_idx = [y + z * k for k in range(n)]\n",
    "\n",
    "    # soft clipping\n",
    "    if baseline_idx[-1] >= l:\n",
    "        baseline_idx[-1] = l - 1\n",
    "\n",
    "    return baseline_idx, z\n",
    "\n",
    "# ğŸ” íŒŒì¼ë³„ augmentation ì ìš©\n",
    "for src_path in tqdm(file_list, desc=\"ğŸ” Skip Sampling Augmentation\"):\n",
    "    basename = os.path.basename(src_path)\n",
    "    file_idx = basename.replace('_norm.json', '')\n",
    "\n",
    "    with open(src_path, 'r', encoding='utf-8') as f:\n",
    "        src_data = json.load(f)\n",
    "\n",
    "    frames = src_data['frames']\n",
    "    l = len(frames)\n",
    "    n = N_FRAMES_SAMPLED\n",
    "\n",
    "    if l < n:\n",
    "        # ğŸ”¸ ê¸¸ì´ ë¶€ì¡± ì‹œ ë³µì œ padding\n",
    "        indices = list(range(l)) + [l - 1] * (n - l)\n",
    "        sampled_frames = [frames[i] for i in indices]\n",
    "\n",
    "        new_data = {\n",
    "            \"id\": src_data[\"id\"],\n",
    "            \"masked_text\": src_data[\"masked_text\"],\n",
    "            \"frames\": sampled_frames,\n",
    "        }\n",
    "        for i, frame in enumerate(new_data[\"frames\"]):\n",
    "            frame[\"frame_idx\"] = i\n",
    "\n",
    "        save_path = os.path.join(AUG_DIR, f\"augmented_{file_idx}_1.json\")\n",
    "        with open(save_path, 'w', encoding='utf-8') as wf:\n",
    "            json.dump(new_data, wf, ensure_ascii=False, indent=2)\n",
    "\n",
    "    else:\n",
    "        baseline_idx, z = safe_sampling_indices(l, n)\n",
    "\n",
    "        if z == 1:\n",
    "            # ğŸ”¸ ê°„ê²©ì´ 1ì´ë©´ ë™ì¼í•œ ê²°ê³¼ë§Œ ë‚˜ì˜¤ë¯€ë¡œ 1ê°œë§Œ ìƒì„±\n",
    "            indices = [min(l - 1, max(0, idx)) for idx in baseline_idx]\n",
    "            sampled_frames = [frames[i] for i in indices]\n",
    "\n",
    "            new_data = {\n",
    "                \"id\": src_data[\"id\"],\n",
    "                \"masked_text\": src_data[\"masked_text\"],\n",
    "                \"frames\": sampled_frames,\n",
    "            }\n",
    "            for i, frame in enumerate(new_data[\"frames\"]):\n",
    "                frame[\"frame_idx\"] = i\n",
    "\n",
    "            save_path = os.path.join(AUG_DIR, f\"augmented_{file_idx}_1.json\")\n",
    "            with open(save_path, 'w', encoding='utf-8') as wf:\n",
    "                json.dump(new_data, wf, ensure_ascii=False, indent=2)\n",
    "\n",
    "        else:\n",
    "            # ğŸ”¸ ë‹¤ì–‘í•œ noise ê¸°ë°˜ augmentation ìƒì„±\n",
    "            for aug_idx in range(1, AUG_FACTOR + 1):\n",
    "                indices = []\n",
    "                for k in range(n):\n",
    "                    base = baseline_idx[k]\n",
    "                    if base >= l - 1:\n",
    "                        noise = 0\n",
    "                    else:\n",
    "                        noise_max = max(1, l - 1 - base) if k == n - 1 else max(1, z)\n",
    "                        noise = random.randint(0, noise_max - 1)\n",
    "                    idx = min(base + noise, l - 1)\n",
    "                    indices.append(idx)\n",
    "\n",
    "                if len(set(indices)) < len(indices):\n",
    "                    duplicate_aug_count += 1\n",
    "\n",
    "                sampled_frames = [frames[i] for i in indices]\n",
    "\n",
    "                new_data = {\n",
    "                    \"id\": src_data[\"id\"],\n",
    "                    \"masked_text\": src_data[\"masked_text\"],\n",
    "                    \"frames\": sampled_frames,\n",
    "                }\n",
    "                for i, frame in enumerate(new_data[\"frames\"]):\n",
    "                    frame[\"frame_idx\"] = i\n",
    "\n",
    "                save_path = os.path.join(AUG_DIR, f\"augmented_{file_idx}_{aug_idx}.json\")\n",
    "                with open(save_path, 'w', encoding='utf-8') as wf:\n",
    "                    json.dump(new_data, wf, ensure_ascii=False, indent=2)\n",
    "\n",
    "# âœ… ìš”ì•½ ì¶œë ¥\n",
    "print(f\"\\nâœ… ëª¨ë“  train íŒŒì¼ì—ì„œ augmentation ê²°ê³¼ë¥¼ '{AUG_DIR}'ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.\")\n",
    "print(f\"ğŸ” ì¤‘ë³µëœ frameì´ í¬í•¨ëœ augmentation ìˆ˜: {duplicate_aug_count:,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "794f5437-a265-4fb8-83b5-c6a325ce12c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ujson\n",
      "  Downloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.3 kB)\n",
      "Downloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
      "Installing collected packages: ujson\n",
      "Successfully installed ujson-5.10.0\n"
     ]
    }
   ],
   "source": [
    "!pip install ujson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "34428e1d-131c-4939-806b-9240920ccab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ì´ íŒŒì¼ ìˆ˜': 159150,\n",
       " 'frame ìˆ˜ê°€ 100ì´ ì•„ë‹Œ íŒŒì¼ ìˆ˜': 0,\n",
       " 'masked_textê°€ ì—†ëŠ” íŒŒì¼ ìˆ˜': 0,\n",
       " 'ì˜ˆì‹œ frame ì˜¤ë¥˜ íŒŒì¼': [],\n",
       " 'ì˜ˆì‹œ masked_text ì˜¤ë¥˜ íŒŒì¼': []}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ì½”ë“œ ìƒíƒœ ì´ˆê¸°í™”ë¡œ ì¬ì‹¤í–‰\n",
    "import os\n",
    "import ujson  # ultra fast JSON parser\n",
    "from glob import glob\n",
    "\n",
    "# ë””ë ‰í† ë¦¬ ì„¤ì •\n",
    "AUG_DIR = \"/teamspace/studios/this_studio/training/train/augmented_keypoint\"\n",
    "\n",
    "# ì²´í¬ìš© ê²°ê³¼ ì €ì¥\n",
    "invalid_frame_counts = []\n",
    "missing_masked_text = []\n",
    "\n",
    "# íŒŒì¼ ëª©ë¡\n",
    "aug_files = glob(os.path.join(AUG_DIR, \"augmented_*.json\"))\n",
    "\n",
    "# ë¹ ë¥¸ ê²€ì‚¬\n",
    "for file_path in aug_files:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = ujson.load(f)\n",
    "\n",
    "    if len(data.get(\"frames\", [])) != 100:\n",
    "        invalid_frame_counts.append(os.path.basename(file_path))\n",
    "\n",
    "    if not data.get(\"masked_text\", \"\").strip():\n",
    "        missing_masked_text.append(os.path.basename(file_path))\n",
    "\n",
    "{\n",
    "    \"ì´ íŒŒì¼ ìˆ˜\": len(aug_files),\n",
    "    \"frame ìˆ˜ê°€ 100ì´ ì•„ë‹Œ íŒŒì¼ ìˆ˜\": len(invalid_frame_counts),\n",
    "    \"masked_textê°€ ì—†ëŠ” íŒŒì¼ ìˆ˜\": len(missing_masked_text),\n",
    "    \"ì˜ˆì‹œ frame ì˜¤ë¥˜ íŒŒì¼\": invalid_frame_counts[:3],\n",
    "    \"ì˜ˆì‹œ masked_text ì˜¤ë¥˜ íŒŒì¼\": missing_masked_text[:3]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "24c08eaf-645c-42cb-bbd4-65da5a5f7e1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Converting JSON to Numpy:   6%|â–‹         | 9988/159150 [00:47<10:24, 238.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved X_part_0.npy â†’ shape (10000, 100, 108)\n",
      "ğŸ“ file_id_part_0.npy â†’ 10000ê°œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Converting JSON to Numpy:  13%|â–ˆâ–        | 19980/159150 [01:35<09:24, 246.38it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved X_part_1.npy â†’ shape (10000, 100, 108)\n",
      "ğŸ“ file_id_part_1.npy â†’ 10000ê°œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Converting JSON to Numpy:  19%|â–ˆâ–‰        | 29999/159150 [02:23<08:37, 249.55it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved X_part_2.npy â†’ shape (10000, 100, 108)\n",
      "ğŸ“ file_id_part_2.npy â†’ 10000ê°œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Converting JSON to Numpy:  25%|â–ˆâ–ˆâ–Œ       | 39992/159150 [03:11<07:27, 266.40it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved X_part_3.npy â†’ shape (10000, 100, 108)\n",
      "ğŸ“ file_id_part_3.npy â†’ 10000ê°œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Converting JSON to Numpy:  31%|â–ˆâ–ˆâ–ˆâ–      | 49997/159150 [04:00<07:47, 233.62it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved X_part_4.npy â†’ shape (10000, 100, 108)\n",
      "ğŸ“ file_id_part_4.npy â†’ 10000ê°œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Converting JSON to Numpy:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 59999/159150 [04:47<07:42, 214.52it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved X_part_5.npy â†’ shape (10000, 100, 108)\n",
      "ğŸ“ file_id_part_5.npy â†’ 10000ê°œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Converting JSON to Numpy:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 69998/159150 [05:36<07:45, 191.67it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved X_part_6.npy â†’ shape (10000, 100, 108)\n",
      "ğŸ“ file_id_part_6.npy â†’ 10000ê°œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Converting JSON to Numpy:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 79991/159150 [06:22<05:33, 237.24it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved X_part_7.npy â†’ shape (10000, 100, 108)\n",
      "ğŸ“ file_id_part_7.npy â†’ 10000ê°œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Converting JSON to Numpy:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 89999/159150 [07:10<04:43, 243.71it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved X_part_8.npy â†’ shape (10000, 100, 108)\n",
      "ğŸ“ file_id_part_8.npy â†’ 10000ê°œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Converting JSON to Numpy:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 99997/159150 [07:58<03:45, 262.62it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved X_part_9.npy â†’ shape (10000, 100, 108)\n",
      "ğŸ“ file_id_part_9.npy â†’ 10000ê°œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Converting JSON to Numpy:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 109977/159150 [08:47<03:08, 260.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved X_part_10.npy â†’ shape (10000, 100, 108)\n",
      "ğŸ“ file_id_part_10.npy â†’ 10000ê°œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Converting JSON to Numpy:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 119985/159150 [09:36<10:24, 62.73it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved X_part_11.npy â†’ shape (10000, 100, 108)\n",
      "ğŸ“ file_id_part_11.npy â†’ 10000ê°œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Converting JSON to Numpy:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 129995/159150 [10:24<01:51, 261.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved X_part_12.npy â†’ shape (10000, 100, 108)\n",
      "ğŸ“ file_id_part_12.npy â†’ 10000ê°œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Converting JSON to Numpy:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 139993/159150 [11:11<01:13, 259.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved X_part_13.npy â†’ shape (10000, 100, 108)\n",
      "ğŸ“ file_id_part_13.npy â†’ 10000ê°œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Converting JSON to Numpy:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 149996/159150 [12:01<00:39, 232.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved X_part_14.npy â†’ shape (10000, 100, 108)\n",
      "ğŸ“ file_id_part_14.npy â†’ 10000ê°œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Converting JSON to Numpy: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 159142/159150 [12:44<00:00, 258.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved X_part_15.npy â†’ shape (9150, 100, 108)\n",
      "ğŸ“ file_id_part_15.npy â†’ 9150ê°œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Converting JSON to Numpy: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 159150/159150 [12:45<00:00, 207.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ‰ All data has been converted and saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# âœ… ê²½ë¡œ ì„¤ì •\n",
    "DATA_DIR = \"./training/train/augmented_keypoint\"\n",
    "SAVE_DIR = \"./training/train/processed\"\n",
    "PART_SIZE = 10_000\n",
    "EXPECTED_FRAME_LEN = 100\n",
    "\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# ğŸ“„ JSON íŒŒì¼ ëª©ë¡\n",
    "file_list = sorted([\n",
    "    os.path.join(DATA_DIR, f)\n",
    "    for f in os.listdir(DATA_DIR)\n",
    "    if f.endswith(\".json\")\n",
    "])\n",
    "total_files = len(file_list)\n",
    "\n",
    "# ğŸ” ë³€í™˜ìš© ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”\n",
    "X_list, text_list, file_id_list = [], [], []\n",
    "part_idx = 0\n",
    "\n",
    "progress = tqdm(file_list, desc=\"ğŸ”„ Converting JSON to Numpy\")\n",
    "\n",
    "for i, file_path in enumerate(progress):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    masked_text = data.get(\"masked_text\", \"\").strip()\n",
    "    if not masked_text:\n",
    "        tqdm.write(f\"âš ï¸ Skipped (no masked_text): {file_path}\")\n",
    "        continue\n",
    "\n",
    "    frames = data.get(\"frames\", [])\n",
    "    if len(frames) != EXPECTED_FRAME_LEN:\n",
    "        tqdm.write(f\"âš ï¸ Skipped (wrong frame length = {len(frames)}): {file_path}\")\n",
    "        continue\n",
    "\n",
    "    keypoints = []\n",
    "    for frame in frames:\n",
    "        pose = frame.get(\"pose\", [])\n",
    "        hand_l = frame.get(\"hand_left\", [])\n",
    "        hand_r = frame.get(\"hand_right\", [])\n",
    "        keypoint = pose + hand_l + hand_r\n",
    "        if len(keypoint) != 108:\n",
    "            tqdm.write(f\"âš ï¸ Skipped (bad keypoint length): {file_path}\")\n",
    "            keypoints = []\n",
    "            break\n",
    "        keypoints.append(keypoint)\n",
    "\n",
    "    if len(keypoints) != EXPECTED_FRAME_LEN:\n",
    "        continue\n",
    "\n",
    "    X_list.append(keypoints)\n",
    "    text_list.append(masked_text)\n",
    "    file_id = os.path.basename(file_path).replace(\".json\", \"\")\n",
    "    file_id_list.append(file_id)\n",
    "\n",
    "    if len(X_list) == PART_SIZE or i == total_files - 1:\n",
    "        X_array = np.array(X_list, dtype=np.float32)\n",
    "        np.save(os.path.join(SAVE_DIR, f\"X_part_{part_idx}.npy\"), X_array)\n",
    "        np.save(os.path.join(SAVE_DIR, f\"file_id_part_{part_idx}.npy\"), np.array(file_id_list))\n",
    "\n",
    "        with open(os.path.join(SAVE_DIR, \"spm_input.txt\"), \"a\", encoding=\"utf-8\") as txt_file:\n",
    "            for line in text_list:\n",
    "                txt_file.write(line.strip() + \"\\n\")\n",
    "\n",
    "        tqdm.write(f\"âœ… Saved X_part_{part_idx}.npy â†’ shape {X_array.shape}\")\n",
    "        tqdm.write(f\"ğŸ“ file_id_part_{part_idx}.npy â†’ {len(file_id_list)}ê°œ\")\n",
    "\n",
    "        X_list, text_list, file_id_list = [], [], []\n",
    "        part_idx += 1\n",
    "\n",
    "tqdm.write(\"\\nğŸ‰ All data has been converted and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "20b72a7b-771f-4283-ba60-3c13c0ec4218",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… SentencePiece tokenizer í•™ìŠµ ì™„ë£Œ!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: ./training/train/processed/spm_input.txt\n",
      "  input_format: \n",
      "  model_prefix: ./training/train/processed/spm\n",
      "  model_type: BPE\n",
      "  vocab_size: 1000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  user_defined_symbols: <ê±´ë¬¼>\n",
      "  user_defined_symbols: <ì§€ì—­>\n",
      "  user_defined_symbols: <ì‹œê°„>\n",
      "  user_defined_symbols: <ë„ë¡œ>\n",
      "  user_defined_symbols: <ì£¼ì†Œ>\n",
      "  user_defined_symbols: <í•™êµ>\n",
      "  user_defined_symbols: <ì‚°>\n",
      "  user_defined_symbols: <ê³µì›>\n",
      "  user_defined_symbols: <ì—­>\n",
      "  user_defined_symbols: <ìˆ™ë°•ì‹œì„¤>\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  seed_sentencepieces_file: \n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: 3\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  â‡ \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(353) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(185) LOG(INFO) Loading corpus: ./training/train/processed/spm_input.txt\n",
      "trainer_interface.cc(409) LOG(INFO) Loaded all 159150 sentences\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <pad>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <ê±´ë¬¼>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <ì§€ì—­>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <ì‹œê°„>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <ë„ë¡œ>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <ì£¼ì†Œ>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <í•™êµ>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <ì‚°>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <ê³µì›>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <ì—­>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <ìˆ™ë°•ì‹œì„¤>\n",
      "trainer_interface.cc(430) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(539) LOG(INFO) all chars count=7606550\n",
      "trainer_interface.cc(550) LOG(INFO) Done: 99.9507% characters are covered.\n",
      "trainer_interface.cc(560) LOG(INFO) Alphabet size=349\n",
      "trainer_interface.cc(561) LOG(INFO) Final character coverage=0.999507\n",
      "trainer_interface.cc(592) LOG(INFO) Done! preprocessed 159150 sentences.\n",
      "trainer_interface.cc(598) LOG(INFO) Tokenizing input sentences with whitespace: 159150\n",
      "trainer_interface.cc(609) LOG(INFO) Done! 1183\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=184250 min_freq=150\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=50250 size=20 all=2028 active=1113 piece=ì‚¬ê³ \n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=17000 size=40 all=2119 active=1204 piece=ì‹œê³ \n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10200 size=60 all=2176 active=1261 piece=ê³µì‚¬\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7000 size=80 all=2247 active=1332 piece=â–ìˆ\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5600 size=100 all=2287 active=1372 piece=â–ë°˜ì›”\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=5600 min_freq=150\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4700 size=120 all=2313 active=1026 piece=ê³µì¥\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3750 size=140 all=2350 active=1063 piece=â–ì°½ê³ \n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3250 size=160 all=2417 active=1130 piece=ë˜ì˜¤ë‹ˆ\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2550 size=180 all=2456 active=1169 piece=ë¥˜ì°½\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2200 size=200 all=2474 active=1187 piece=â–ì‹ ì†íˆ\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2150 min_freq=150\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1800 size=220 all=2505 active=1032 piece=â–í•´\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1600 size=240 all=2541 active=1068 piece=í•˜ì„¸ìš”\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1350 size=260 all=2565 active=1092 piece=â–ê³„\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1200 size=280 all=2603 active=1130 piece=â–ë°±\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1100 size=300 all=2641 active=1168 piece=â–ì¸í•˜ì—¬\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1100 min_freq=100\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1000 size=320 all=2657 active=1017 piece=ì¼€ë¯¸ìŠ¤í‹¸\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=950 size=340 all=2679 active=1039 piece=â–ìš°íšŒë°”ëë‹ˆë‹¤\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=850 size=360 all=2702 active=1062 piece=â–ëŒ€í™”\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=750 size=380 all=2722 active=1082 piece=â–ì‚¬\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=700 size=400 all=2736 active=1096 piece=â–ëŒ€ì¤‘\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=700 min_freq=100\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=650 size=420 all=2741 active=1005 piece=ì² ì†Œ\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=600 size=440 all=2753 active=1017 piece=ë˜ë‹ˆ\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=550 size=460 all=2764 active=1028 piece=â–[\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=550 size=480 all=2768 active=1032 piece=â–ì™¸ì¶œìì œ\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=500 size=500 all=2779 active=1043 piece=ì‹ ì¥\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=500 min_freq=100\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=500 size=520 all=2797 active=1016 piece=ì‹ ì¥ì• ê°€\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=450 size=540 all=2802 active=1021 piece=â–ì‚¼ê°€\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=450 size=560 all=2806 active=1025 piece=â–ì£¼ìœ ì†Œì—ì„œ\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=400 size=580 all=2819 active=1038 piece=â–ì˜¤ì „\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=400 size=600 all=2822 active=1041 piece=â–ìƒê°€ì£¼ë¯¼ë“¤ì€\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=400 min_freq=50\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=350 size=620 all=2843 active=1022 piece=â–11\n",
      "trainer_interface.cc(687) LOG(INFO) Saving model: ./training/train/processed/spm.model\n",
      "trainer_interface.cc(699) LOG(INFO) Saving vocabs: ./training/train/processed/spm.vocab\n"
     ]
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "\n",
    "# í•™ìŠµìš© txt ê²½ë¡œ\n",
    "input_txt = \"./training/train/processed/spm_input.txt\"\n",
    "\n",
    "# ì €ì¥ prefix\n",
    "model_prefix = \"./training/train/processed/spm\"\n",
    "vocab_size = 1000  # âœ… vocab ì‚¬ì´ì¦ˆ í™•ì¥\n",
    "\n",
    "# SentencePiece ëª¨ë¸ í•™ìŠµ\n",
    "spm.SentencePieceTrainer.Train(\n",
    "    input=input_txt,\n",
    "    model_prefix=model_prefix,\n",
    "    vocab_size=vocab_size,\n",
    "    character_coverage=0.9995,\n",
    "    model_type=\"bpe\",\n",
    "    unk_id=0,              # âœ… UNK = 0 (ê¸°ë³¸ê°’ê³¼ ë™ì¼í•˜ì§€ë§Œ ëª…ì‹œì ìœ¼ë¡œ ì§€ì •)\n",
    "    bos_id=1,              # âœ… BOS = 1\n",
    "    eos_id=2,              # âœ… EOS = 2\n",
    "    pad_id=3,              # âœ… PAD = 3\n",
    "    pad_piece=\"<pad>\",     # âœ… PAD í† í° ëª…ì‹œ\n",
    "    user_defined_symbols=[\n",
    "        \"<ê±´ë¬¼>\", \"<ì§€ì—­>\", \"<ì‹œê°„>\", \"<ë„ë¡œ>\", \"<ì£¼ì†Œ>\",\n",
    "        \"<í•™êµ>\", \"<ì‚°>\", \"<ê³µì›>\", \"<ì—­>\", \"<ìˆ™ë°•ì‹œì„¤>\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"âœ… SentencePiece tokenizer í•™ìŠµ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "32e3d4af-9f1a-4d22-88e6-32972913685a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸŒ¤ï¸ Encoding masked_text to y.npy:   6%|â–‹         | 10028/159150 [00:37<09:01, 275.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved y_part_0.npy â†’ 10000 sequences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸŒ¤ï¸ Encoding masked_text to y.npy:  13%|â–ˆâ–        | 20051/159150 [01:16<09:08, 253.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved y_part_1.npy â†’ 10000 sequences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸŒ¤ï¸ Encoding masked_text to y.npy:  19%|â–ˆâ–‰        | 30049/159150 [01:54<08:43, 246.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved y_part_2.npy â†’ 10000 sequences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸŒ¤ï¸ Encoding masked_text to y.npy:  25%|â–ˆâ–ˆâ–Œ       | 40031/159150 [02:32<06:57, 285.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved y_part_3.npy â†’ 10000 sequences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸŒ¤ï¸ Encoding masked_text to y.npy:  31%|â–ˆâ–ˆâ–ˆâ–      | 50046/159150 [03:09<06:29, 280.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved y_part_4.npy â†’ 10000 sequences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸŒ¤ï¸ Encoding masked_text to y.npy:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 60051/159150 [03:48<06:41, 247.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved y_part_5.npy â†’ 10000 sequences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸŒ¤ï¸ Encoding masked_text to y.npy:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 70036/159150 [04:26<05:51, 253.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved y_part_6.npy â†’ 10000 sequences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸŒ¤ï¸ Encoding masked_text to y.npy:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 80052/159150 [05:04<05:06, 258.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved y_part_7.npy â†’ 10000 sequences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸŒ¤ï¸ Encoding masked_text to y.npy:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 90040/159150 [05:41<04:43, 243.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved y_part_8.npy â†’ 10000 sequences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸŒ¤ï¸ Encoding masked_text to y.npy:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 100054/159150 [06:20<03:28, 283.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved y_part_9.npy â†’ 10000 sequences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸŒ¤ï¸ Encoding masked_text to y.npy:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 110042/159150 [06:58<02:56, 278.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved y_part_10.npy â†’ 10000 sequences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸŒ¤ï¸ Encoding masked_text to y.npy:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 120042/159150 [07:36<02:54, 223.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved y_part_11.npy â†’ 10000 sequences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸŒ¤ï¸ Encoding masked_text to y.npy:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 130048/159150 [08:14<02:00, 241.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved y_part_12.npy â†’ 10000 sequences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸŒ¤ï¸ Encoding masked_text to y.npy:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 140049/159150 [08:52<01:05, 290.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved y_part_13.npy â†’ 10000 sequences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸŒ¤ï¸ Encoding masked_text to y.npy:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 150042/159150 [09:30<00:33, 274.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved y_part_14.npy â†’ 10000 sequences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸŒ¤ï¸ Encoding masked_text to y.npy: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 159150/159150 [10:05<00:00, 262.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved y_part_15.npy â†’ 9150 sequences\n",
      "\n",
      "ğŸ‰ All masked_text â†’ y numpy ë³€í™˜ ì™„ë£Œ!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import sentencepiece as spm\n",
    "\n",
    "# ğŸ“Œ SentencePiece tokenizer ë¡œë“œ\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load(\"./training/train/processed/spm.model\")\n",
    "\n",
    "bos_id = sp.bos_id()   # 1\n",
    "eos_id = sp.eos_id()   # 2\n",
    "\n",
    "# ğŸ“ ë””ë ‰í† ë¦¬ ì„¤ì •\n",
    "DATA_DIR = \"./training/train/augmented_keypoint\"\n",
    "SAVE_DIR = \"./training/train/processed\"\n",
    "PART_SIZE = 10_000\n",
    "\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# ğŸ“„ JSON íŒŒì¼ ëª©ë¡\n",
    "file_list = sorted([\n",
    "    os.path.join(DATA_DIR, f)\n",
    "    for f in os.listdir(DATA_DIR)\n",
    "    if f.endswith(\".json\")\n",
    "])\n",
    "\n",
    "# ğŸ“¦ ì €ì¥ ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”\n",
    "y_list = []\n",
    "part_idx = 0\n",
    "\n",
    "# ğŸ” íŒŒì¼ë³„ ì²˜ë¦¬\n",
    "for i, file_path in enumerate(tqdm(file_list, desc=\"ğŸŒ¤ï¸ Encoding masked_text to y.npy\")):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    masked_text = data.get(\"masked_text\", \"\").strip()\n",
    "    if not masked_text:\n",
    "        continue\n",
    "\n",
    "    # SentencePieceë¡œ ì¸ì½”ë”© (BOS/EOS í¬í•¨)\n",
    "    y_ids = [bos_id] + sp.encode(masked_text, out_type=int) + [eos_id]\n",
    "    y_list.append(y_ids)\n",
    "\n",
    "    # PART ë‹¨ìœ„ ì €ì¥\n",
    "    if len(y_list) == PART_SIZE or i == len(file_list) - 1:\n",
    "        np.save(os.path.join(SAVE_DIR, f\"y_part_{part_idx}.npy\"), np.array(y_list, dtype=object))\n",
    "        print(f\"âœ… Saved y_part_{part_idx}.npy â†’ {len(y_list)} sequences\")\n",
    "        y_list = []\n",
    "        part_idx += 1\n",
    "\n",
    "print(\"\\nğŸ‰ All masked_text â†’ y numpy ë³€í™˜ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2a9c7d41-c5e5-4826-93ed-7950aeb6aba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Processing Validation Set: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 408/408 [00:09<00:00, 40.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved x_part_0.npy â†’ 408 samples\n",
      "âœ… Saved y_part_0.npy â†’ 408 samples\n",
      "\n",
      "ğŸ‰ Validation set ë³€í™˜ ë° ì €ì¥ ì™„ë£Œ (masked_text ê¸°ì¤€, variable-length í—ˆìš©)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Processing Validation set \n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import sentencepiece as spm\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ğŸ”§ ê²½ë¡œ ì„¤ì •\n",
    "VAL_DATA_DIR = \"/teamspace/studios/this_studio/training/val/norm_keypoint\"\n",
    "SAVE_DIR = \"/teamspace/studios/this_studio/training/val/processed\"\n",
    "SPM_MODEL = \"/teamspace/studios/this_studio/training/train/processed/spm.model\"\n",
    "PART_SIZE = 10_000\n",
    "\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# ğŸ” SentencePiece tokenizer ë¡œë“œ\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load(SPM_MODEL)\n",
    "\n",
    "bos_id = sp.bos_id()  # 1\n",
    "eos_id = sp.eos_id()  # 2\n",
    "\n",
    "# ğŸ“„ JSON íŒŒì¼ ëª©ë¡ ì •ë ¬\n",
    "file_list = sorted([\n",
    "    os.path.join(VAL_DATA_DIR, f)\n",
    "    for f in os.listdir(VAL_DATA_DIR)\n",
    "    if f.endswith(\".json\")\n",
    "])\n",
    "total_files = len(file_list)\n",
    "\n",
    "# ğŸ“¦ ì €ì¥ìš© ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”\n",
    "x_list, y_list, file_id_list = [], [], []\n",
    "part_idx = 0\n",
    "\n",
    "for i, file_path in enumerate(tqdm(file_list, desc=\"ğŸ”„ Processing Validation Set\")):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # 1ï¸âƒ£ masked_text ì¶”ì¶œ\n",
    "    masked_text = data.get(\"masked_text\", \"\").strip()\n",
    "    if not masked_text:\n",
    "        continue\n",
    "\n",
    "    # 2ï¸âƒ£ keypoint ì¶”ì¶œ\n",
    "    frames = data.get(\"frames\", [])\n",
    "    if len(frames) < 1:\n",
    "        continue\n",
    "\n",
    "    keypoints = []\n",
    "    for frame in frames:\n",
    "        pose = frame.get(\"pose\", [])\n",
    "        hand_l = frame.get(\"hand_left\", [])\n",
    "        hand_r = frame.get(\"hand_right\", [])\n",
    "        keypoint = pose + hand_l + hand_r\n",
    "        if len(keypoint) != 108:\n",
    "            break\n",
    "        keypoints.append(keypoint)\n",
    "\n",
    "    if len(keypoints) < 1:\n",
    "        continue\n",
    "\n",
    "    # 3ï¸âƒ£ ë³€í™˜ ë° ì €ì¥\n",
    "    x_list.append(np.array(keypoints, dtype=np.float32))  # variable-length\n",
    "    y_ids = [bos_id] + sp.encode(masked_text, out_type=int) + [eos_id]\n",
    "    y_list.append(y_ids)\n",
    "    file_id = os.path.basename(file_path).replace(\".json\", \"\")\n",
    "    file_id_list.append(file_id)\n",
    "\n",
    "    # ğŸ”½ ì €ì¥ ì¡°ê±´\n",
    "    if len(x_list) == PART_SIZE or i == total_files - 1:\n",
    "        np.save(os.path.join(SAVE_DIR, f\"x_part_{part_idx}.npy\"), np.array(x_list, dtype=object))\n",
    "        np.save(os.path.join(SAVE_DIR, f\"y_part_{part_idx}.npy\"), np.array(y_list, dtype=object))\n",
    "        np.save(os.path.join(SAVE_DIR, f\"file_id_part_{part_idx}.npy\"), np.array(file_id_list))\n",
    "\n",
    "        print(f\"âœ… Saved x_part_{part_idx}.npy â†’ {len(x_list)} samples\")\n",
    "        print(f\"âœ… Saved y_part_{part_idx}.npy â†’ {len(y_list)} samples\")\n",
    "\n",
    "        # ì´ˆê¸°í™”\n",
    "        x_list, y_list, file_id_list = [], [], []\n",
    "        part_idx += 1\n",
    "\n",
    "print(\"\\nğŸ‰ Validation set ë³€í™˜ ë° ì €ì¥ ì™„ë£Œ (masked_text ê¸°ì¤€, variable-length í—ˆìš©)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "62287123-ddf0-4c88-b7df-1a26d13f21ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "PAD_ID = 3  # âœ… íŒ¨ë”© í† í°ì€ í•­ìƒ 3ìœ¼ë¡œ ê³ ì •\n",
    "\n",
    "# -----------------------------\n",
    "# 1. SLTDataset (Train Dataset)\n",
    "# -----------------------------\n",
    "class SLTDataset(Dataset):\n",
    "    def __init__(self, x_dir, y_dir, part_ids):\n",
    "        self.x_paths = [os.path.join(x_dir, f\"X_part_{i}.npy\") for i in part_ids]\n",
    "        self.y_paths = [os.path.join(y_dir, f\"y_part_{i}.npy\") for i in part_ids]  # âœ… ì†Œë¬¸ì yë¡œ ë³€ê²½\n",
    "\n",
    "        self.X = []\n",
    "        self.y = []\n",
    "\n",
    "        for x_path, y_path in zip(self.x_paths, self.y_paths):\n",
    "            self.X.extend(np.load(x_path, allow_pickle=True))\n",
    "            self.y.extend(np.load(y_path, allow_pickle=True))\n",
    "\n",
    "        assert len(self.X) == len(self.y), \"X and y size mismatch\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.tensor(self.X[idx], dtype=torch.float32)  # (T, 108)\n",
    "        y = torch.tensor(self.y[idx], dtype=torch.long)     # (L,)\n",
    "        return x, y\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Collate Function\n",
    "# -----------------------------\n",
    "def collate_fn(batch, pad_id=PAD_ID, max_len=100):\n",
    "    xs, ys = zip(*batch)\n",
    "\n",
    "    # ğŸ§© x padding\n",
    "    max_x_len = min(max([x.shape[0] for x in xs]), max_len)\n",
    "    padded_xs = []\n",
    "    for x in xs:\n",
    "        if x.shape[0] >= max_x_len:\n",
    "            padded_xs.append(x[:max_x_len])\n",
    "        else:\n",
    "            pad = torch.zeros(max_x_len - x.shape[0], x.shape[1])\n",
    "            padded_xs.append(torch.cat([x, pad], dim=0))\n",
    "    xs = torch.stack(padded_xs)  # (B, T, 108)\n",
    "\n",
    "    # ğŸ§© y padding\n",
    "    max_y_len = max([len(y) for y in ys])\n",
    "    ys = [F.pad(y, (0, max_y_len - len(y)), value=pad_id) for y in ys]\n",
    "    ys = torch.stack(ys)\n",
    "\n",
    "    return xs, ys\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Train DataLoader\n",
    "# -----------------------------\n",
    "X_DIR = \"/teamspace/studios/this_studio/training/train/processed\"\n",
    "Y_DIR = X_DIR\n",
    "PART_IDS = list(range(16))\n",
    "\n",
    "train_dataset = SLTDataset(X_DIR, Y_DIR, PART_IDS)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 4. SLTValDataset (Validation)\n",
    "# -----------------------------\n",
    "class SLTValDataset(Dataset):\n",
    "    def __init__(self, data_dir):\n",
    "        self.X_paths = sorted([os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.startswith(\"X_part_\")])\n",
    "        self.y_paths = sorted([os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.startswith(\"y_part_\")])  # âœ… ì†Œë¬¸ì y\n",
    "\n",
    "        self.X = []\n",
    "        self.y = []\n",
    "\n",
    "        for x_path, y_path in zip(self.X_paths, self.y_paths):\n",
    "            self.X.extend(np.load(x_path, allow_pickle=True))\n",
    "            self.y.extend(np.load(y_path, allow_pickle=True))\n",
    "\n",
    "        assert len(self.X) == len(self.y), \"X and y size mismatch in validation set\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.tensor(self.X[idx], dtype=torch.float32)  # (T, 108)\n",
    "        y = torch.tensor(self.y[idx], dtype=torch.long)     # (L,)\n",
    "        return x, y\n",
    "\n",
    "\n",
    "def get_validation_loader(val_dir, batch_size=64, num_workers=2):\n",
    "    val_dataset = SLTValDataset(val_dir)\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "    return val_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "635cbf99-3133-441a-80f3-647f38dc9b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# -------------------------\n",
    "# 1. Attention ëª¨ë“ˆ\n",
    "# -------------------------\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, encoder_hidden_dim, decoder_hidden_dim):\n",
    "        super().__init__()\n",
    "        self.attn = nn.Linear(encoder_hidden_dim + decoder_hidden_dim, decoder_hidden_dim)\n",
    "        self.v = nn.Linear(decoder_hidden_dim, 1, bias=False)\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        # hidden: (B, dec_hidden)\n",
    "        # encoder_outputs: (B, src_len, enc_hidden_dim)\n",
    "        src_len = encoder_outputs.size(1)\n",
    "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)  # (B, src_len, dec_hidden)\n",
    "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim=2)))  # (B, src_len, dec_hidden)\n",
    "        attention = self.v(energy).squeeze(2)  # (B, src_len)\n",
    "        return F.softmax(attention, dim=1)\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# 2. Encoder (BiGRU)\n",
    "# -------------------------\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim=108, hidden_dim=256):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.GRU(input_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "\n",
    "    def forward(self, src):\n",
    "        # src: (B, T, input_dim)\n",
    "        outputs, hidden = self.rnn(src)  # outputs: (B, T, 2*H), hidden: (2, B, H)\n",
    "        return outputs, hidden\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# 3. Decoder (GRU + Attention)\n",
    "# -------------------------\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim=256, enc_hidden_dim=256, dec_hidden_dim=256):\n",
    "        super().__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        self.attention = Attention(enc_hidden_dim * 2, dec_hidden_dim)\n",
    "        self.rnn = nn.GRU(emb_dim + enc_hidden_dim * 2, dec_hidden_dim, batch_first=True)\n",
    "        self.fc_out = nn.Linear(emb_dim + enc_hidden_dim * 2 + dec_hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        # input: (B,)\n",
    "        # hidden: (1, B, dec_hidden)\n",
    "        # encoder_outputs: (B, src_len, enc_hidden*2)\n",
    "        input = input.unsqueeze(1)  # (B, 1)\n",
    "        embedded = self.embedding(input)  # (B, 1, emb_dim)\n",
    "\n",
    "        attn_weights = self.attention(hidden.squeeze(0), encoder_outputs)  # (B, src_len)\n",
    "        attn_weights = attn_weights.unsqueeze(1)  # (B, 1, src_len)\n",
    "        context = torch.bmm(attn_weights, encoder_outputs)  # (B, 1, enc_hidden*2)\n",
    "\n",
    "        rnn_input = torch.cat((embedded, context), dim=2)  # (B, 1, emb_dim + ctx)\n",
    "        output, hidden = self.rnn(rnn_input, hidden)  # output: (B, 1, dec_hidden)\n",
    "\n",
    "        concat = torch.cat((output, context, embedded), dim=2)  # (B, 1, total_dim)\n",
    "        prediction = self.fc_out(concat.squeeze(1))  # (B, output_dim)\n",
    "\n",
    "        return prediction, hidden, attn_weights.squeeze(1)\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# 4. Seq2Seq (í†µí•© ëª¨ë“ˆ)\n",
    "# -------------------------\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device, pad_id=3):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        self.pad_id = pad_id\n",
    "\n",
    "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
    "        # src: (B, T, 108), trg: (B, L)\n",
    "        batch_size = src.size(0)\n",
    "        trg_len = trg.size(1)\n",
    "        output_dim = self.decoder.output_dim\n",
    "\n",
    "        # ğŸ§± Output tensor ì´ˆê¸°í™”\n",
    "        outputs = torch.zeros(batch_size, trg_len, output_dim).to(self.device)\n",
    "\n",
    "        # ğŸ” Encoder\n",
    "        encoder_outputs, hidden = self.encoder(src)  # hidden: (2, B, H)\n",
    "        hidden = torch.tanh(hidden[0] + hidden[1]).unsqueeze(0)  # (1, B, H)\n",
    "\n",
    "        # ğŸ” Decoder ì‹œì‘ - ì²« inputì€ BOS í† í°\n",
    "        input = trg[:, 0]  # (B,)\n",
    "\n",
    "        for t in range(1, trg_len):\n",
    "            output, hidden, _ = self.decoder(input, hidden, encoder_outputs)  # output: (B, vocab)\n",
    "            outputs[:, t] = output  # t ìœ„ì¹˜ì— output ì €ì¥\n",
    "\n",
    "            teacher_force = torch.rand(1).item() < teacher_forcing_ratio\n",
    "            top1 = output.argmax(1)  # (B,)\n",
    "\n",
    "            input = trg[:, t] if teacher_force else top1\n",
    "\n",
    "        return outputs  # (B, L, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ce83d49-1dd0-4be1-9d6c-7c74acabaec0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: evaluate in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (0.4.4)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from evaluate) (3.6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from evaluate) (1.26.4)\n",
      "Requirement already satisfied: dill in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from evaluate) (2.1.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from evaluate) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from evaluate) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from evaluate) (0.33.1)\n",
      "Requirement already satisfied: packaging in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from evaluate) (24.2)\n",
      "Requirement already satisfied: filelock in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.18.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (20.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (3.12.12)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from multidict<7.0,>=4.5->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (4.14.0)\n",
      "Requirement already satisfied: idna>=2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (3.10)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2025.4.26)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "184733e6-a1ba-4e7c-99d3-d3304904aa1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /teamspace/studios/this_studio/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /teamspace/studios/this_studio/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /teamspace/studios/this_studio/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Model_1\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import evaluate\n",
    "\n",
    "# ---------------------------\n",
    "# 1. í‰ê°€ ì§€í‘œ ë¡œë“œ\n",
    "# ---------------------------\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "meteor = evaluate.load(\"meteor\")\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "\n",
    "# ---------------------------\n",
    "# 2. ë””ì½”ë”© í•¨ìˆ˜\n",
    "# ---------------------------\n",
    "def decode_sequence(tokenizer, sequences, eos_id=2):\n",
    "    decoded = []\n",
    "    for seq in sequences:\n",
    "        tokens = []\n",
    "        for tok in seq:\n",
    "            if tok == eos_id:\n",
    "                break\n",
    "            tokens.append(tok)\n",
    "        sentence = tokenizer.decode(tokens)\n",
    "        decoded.append(sentence.replace(\"â–\", \" \").strip())\n",
    "    return decoded\n",
    "\n",
    "# ---------------------------\n",
    "# 3. í‰ê°€ ì§€í‘œ ê³„ì‚°\n",
    "# ---------------------------\n",
    "def compute_metrics(preds, refs, tokenizer, eos_id=2):\n",
    "    decoded_preds = decode_sequence(tokenizer, preds, eos_id)\n",
    "    decoded_refs = decode_sequence(tokenizer, refs, eos_id)\n",
    "    return {\n",
    "        \"BLEU\": bleu.compute(predictions=decoded_preds, references=[[r] for r in decoded_refs])[\"bleu\"],\n",
    "        \"METEOR\": meteor.compute(predictions=decoded_preds, references=decoded_refs)[\"meteor\"],\n",
    "        \"ROUGE\": rouge.compute(predictions=decoded_preds, references=decoded_refs)[\"rougeL\"]\n",
    "    }\n",
    "\n",
    "# ---------------------------\n",
    "# 4. ì²´í¬í¬ì¸íŠ¸ ì €ì¥\n",
    "# ---------------------------\n",
    "def save_checkpoint(model, optimizer, epoch, val_bleu, val_meteor, val_loss, path):\n",
    "    checkpoint = {\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        \"epoch\": epoch,\n",
    "        \"val_bleu\": val_bleu,\n",
    "        \"val_meteor\": val_meteor,\n",
    "        \"val_loss\": val_loss\n",
    "    }\n",
    "    torch.save(checkpoint, path)\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# 5. í•™ìŠµ ë£¨í”„ with EOS/BOS + ìƒ˜í”Œ ì¶œë ¥\n",
    "# ---------------------------\n",
    "def train_with_early_stopping(\n",
    "    model, train_loader, val_loader, tokenizer,\n",
    "    optimizer, criterion, device,\n",
    "    num_epochs=30,\n",
    "    teacher_forcing_ratio=0.5,\n",
    "    clip=1.0,\n",
    "    pad_id=0,\n",
    "    eos_id=2,\n",
    "    save_path=\"best_model.pt\",\n",
    "    early_stopping_patience=5,\n",
    "    checkpoint_dir=\"checkpoints\"\n",
    "):\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    best_bleu = -1\n",
    "    patience = 0\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        pbar = tqdm(train_loader, desc=f\"[Epoch {epoch}] Training\")\n",
    "\n",
    "        for X, y in pbar:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            decoder_input = y[:, :-1]\n",
    "            target = y[:, 1:]\n",
    "\n",
    "            output = model(X, decoder_input, teacher_forcing_ratio=teacher_forcing_ratio)\n",
    "            output = output.reshape(-1, output.shape[-1])\n",
    "            target = target.reshape(-1)\n",
    "\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            pbar.set_postfix(train_loss=epoch_loss / (pbar.n + 1))\n",
    "\n",
    "        # -----------------------\n",
    "        # Train Sample ì¶œë ¥\n",
    "        # -----------------------\n",
    "        model.eval()\n",
    "        train_preds, train_refs = [], []\n",
    "        with torch.no_grad():\n",
    "            for X_train, y_train in train_loader:\n",
    "                X_train, y_train = X_train.to(device), y_train.to(device)\n",
    "                output = model(X_train, y_train[:, :-1], teacher_forcing_ratio=0.0)\n",
    "                output_tokens = output.argmax(-1)\n",
    "                train_preds = decode_sequence(tokenizer, output_tokens[:5].tolist(), eos_id)\n",
    "                train_refs = decode_sequence(tokenizer, y_train[:5].tolist(), eos_id)\n",
    "                break  # ì²« batchë§Œ\n",
    "\n",
    "        print(\"\\nğŸŸ¦ [Train Samples]\")\n",
    "        for i in range(len(train_preds)):\n",
    "            print(f\"ğŸ”¹ [Pred] {train_preds[i]}\")\n",
    "            print(f\"ğŸ”¸ [True] {train_refs[i]}\")\n",
    "            print()\n",
    "\n",
    "        # -----------------------\n",
    "        # Validation\n",
    "        # -----------------------\n",
    "        val_loss = 0\n",
    "        preds, refs = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for X_val, y_val in val_loader:\n",
    "                X_val, y_val = X_val.to(device), y_val.to(device)\n",
    "                decoder_input = y_val[:, :-1]\n",
    "                target = y_val[:, 1:]\n",
    "\n",
    "                output = model(X_val, decoder_input, teacher_forcing_ratio=0.0)\n",
    "                output_tokens = output.argmax(-1)\n",
    "\n",
    "                preds.extend(output_tokens.tolist())\n",
    "                refs.extend(y_val.tolist())\n",
    "\n",
    "                output = output.reshape(-1, output.shape[-1])\n",
    "                target = target.reshape(-1)\n",
    "                val_loss += criterion(output, target).item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        metrics = compute_metrics(preds, refs, tokenizer, eos_id)\n",
    "        val_bleu = metrics[\"BLEU\"]\n",
    "        val_preds = decode_sequence(tokenizer, preds[:5], eos_id)\n",
    "        val_refs = decode_sequence(tokenizer, refs[:5], eos_id)\n",
    "\n",
    "        print(\"\\nğŸŸ© [Validation Samples]\")\n",
    "        for i in range(len(val_preds)):\n",
    "            print(f\"ğŸ”¹ [Pred] {val_preds[i]}\")\n",
    "            print(f\"ğŸ”¸ [True] {val_refs[i]}\")\n",
    "            print()\n",
    "\n",
    "        print(f\"[Epoch {epoch}] Val Loss: {val_loss:.4f} | BLEU: {val_bleu:.4f} | METEOR: {metrics['METEOR']:.4f} | ROUGE: {metrics['ROUGE']:.4f}\")\n",
    "        # â¬…ï¸ 1. í˜„ì¬ epoch checkpoint ì €ì¥ (ì¼ë°˜)\n",
    "        ckpt_path = os.path.join(checkpoint_dir, f\"checkpoint_epoch{epoch}.pt\")\n",
    "        save_checkpoint(\n",
    "            model,\n",
    "            optimizer,\n",
    "            epoch,\n",
    "            val_bleu,\n",
    "            metrics[\"METEOR\"],\n",
    "            val_loss,\n",
    "            ckpt_path  # âœ… ì—¬ê¸°ì— ì €ì¥!\n",
    "        )\n",
    "        \n",
    "        # â¬…ï¸ 2. BLEU ê¸°ì¤€ best model ì €ì¥\n",
    "        if val_bleu > best_bleu:\n",
    "            best_bleu = val_bleu\n",
    "            patience = 0\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            save_checkpoint(\n",
    "                model,\n",
    "                optimizer,\n",
    "                epoch,\n",
    "                val_bleu,\n",
    "                metrics[\"METEOR\"],\n",
    "                val_loss,\n",
    "                os.path.join(checkpoint_dir, \"best_checkpoint.pt\")  # âœ… ì—¬ê¸°ì—ë§Œ best ì €ì¥\n",
    "            )\n",
    "            print(f\"âœ… Best model saved at epoch {epoch} (BLEU={val_bleu:.4f})\")\n",
    "        else:\n",
    "            patience += 1\n",
    "            if patience >= early_stopping_patience:\n",
    "                print(f\"ğŸ›‘ Early stopping triggered. Best BLEU: {best_bleu:.4f}\")\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d59b65d6-76a3-4edf-85d6-ecdeb43210df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /teamspace/studios/this_studio/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /teamspace/studios/this_studio/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /teamspace/studios/this_studio/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Model_2\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import evaluate\n",
    "\n",
    "# ---------------------------\n",
    "# 1. í‰ê°€ ì§€í‘œ ë¡œë“œ (HuggingFace Evaluate)\n",
    "# ---------------------------\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "meteor = evaluate.load(\"meteor\")\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# 2. í† í° ì‹œí€€ìŠ¤ë¥¼ ìì—°ì–´ë¡œ ë³µì›\n",
    "# (ë°°ì¹˜ ë””ì½”ë”©ìš©, eos_id ê¸°ì¤€ìœ¼ë¡œ ì˜ë¼ëƒ„)\n",
    "# ---------------------------\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def top_k_top_p_filtering(logits, top_k=0, top_p=1.0, filter_value=-float(\"Inf\")):\n",
    "    \"\"\"\n",
    "    Filter a distribution of logits using top-k and/or nucleus (top-p) filtering.\n",
    "    \"\"\"\n",
    "    logits = logits.clone()\n",
    "\n",
    "    # Top-k filtering\n",
    "    if top_k > 0:\n",
    "        top_k = min(top_k, logits.size(-1))  # Safety check\n",
    "        indices_to_remove = logits < torch.topk(logits, top_k)[0][..., -1, None]\n",
    "        logits[indices_to_remove] = filter_value\n",
    "\n",
    "    # Top-p (nucleus) filtering\n",
    "    if top_p < 1.0:\n",
    "        sorted_logits, sorted_indices = torch.sort(logits, descending=True)\n",
    "        cumulative_probs = torch.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\n",
    "\n",
    "        # Remove tokens with cumulative prob > top_p\n",
    "        sorted_indices_to_remove = cumulative_probs > top_p\n",
    "        # Shift right to keep at least one token\n",
    "        sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n",
    "        sorted_indices_to_remove[..., 0] = 0\n",
    "\n",
    "        indices_to_remove = sorted_indices[sorted_indices_to_remove]\n",
    "        logits[indices_to_remove] = filter_value\n",
    "\n",
    "    return logits\n",
    "\n",
    "def decode_sequence(\n",
    "    model,\n",
    "    input_tensor,\n",
    "    tokenizer,\n",
    "    device,\n",
    "    max_len=100,\n",
    "    eos_id=2,\n",
    "    repetition_penalty=1.2,\n",
    "    top_k=5,\n",
    "    top_p=0.9\n",
    "):\n",
    "    \"\"\"\n",
    "    Sampling-based decoding using top-k, top-p, and repetition penalty.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    input_tensor = input_tensor.unsqueeze(0).to(device)  # (1, T, D)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        encoder_outputs, hidden = model.encoder(input_tensor)\n",
    "        hidden = torch.tanh(hidden[0] + hidden[1]).unsqueeze(0)  # (1, 1, H)\n",
    "\n",
    "        input_token = torch.tensor([tokenizer.bos_id()], device=device)  # (1,)\n",
    "        decoded = []\n",
    "        used_tokens = set()\n",
    "\n",
    "        for _ in range(max_len):\n",
    "            output, hidden, _ = model.decoder(input_token, hidden, encoder_outputs)  # output: (1, vocab)\n",
    "            output = output.squeeze(0)  # (vocab,)\n",
    "\n",
    "            # Apply repetition penalty\n",
    "            for token_id in used_tokens:\n",
    "                if output[token_id] < 0:\n",
    "                    output[token_id] *= repetition_penalty\n",
    "                else:\n",
    "                    output[token_id] /= repetition_penalty\n",
    "\n",
    "            # Sampling with top-k and/or top-p\n",
    "            filtered_logits = top_k_top_p_filtering(output, top_k=top_k, top_p=top_p)\n",
    "            probs = F.softmax(filtered_logits, dim=-1)\n",
    "            top1 = torch.multinomial(probs, num_samples=1).item()\n",
    "\n",
    "            if top1 == eos_id:\n",
    "                break\n",
    "\n",
    "            decoded.append(top1)\n",
    "            used_tokens.add(top1)\n",
    "            input_token = torch.tensor([top1], device=device)\n",
    "\n",
    "    return tokenizer.decode(decoded).replace(\"â–\", \" \").strip()\n",
    "\n",
    "\n",
    "def decode_tokens(tokenizer, sequences, eos_id=2, pad_id=3):\n",
    "    \"\"\"\n",
    "    sequences: List of token ids (List[List[int]])\n",
    "    Returns: List of decoded strings\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for seq in sequences:\n",
    "        tokens = []\n",
    "        for t in seq:\n",
    "            if t == eos_id or t == pad_id:\n",
    "                break\n",
    "            tokens.append(t)\n",
    "        results.append(tokenizer.decode(tokens).replace(\"â–\", \" \").strip())\n",
    "    return results\n",
    "\n",
    "# ---------------------------\n",
    "# 3. BLEU, METEOR, ROUGE ê³„ì‚°\n",
    "# ---------------------------\n",
    "def compute_metrics(preds, refs, tokenizer, eos_id=2, pad_id=3):\n",
    "    decoded_preds = decode_tokens(tokenizer, preds, eos_id, pad_id)\n",
    "    decoded_refs = decode_tokens(tokenizer, refs, eos_id, pad_id)\n",
    "\n",
    "    return {\n",
    "        \"BLEU\": bleu.compute(predictions=decoded_preds, references=[[r] for r in decoded_refs])[\"bleu\"],\n",
    "        \"METEOR\": meteor.compute(predictions=decoded_preds, references=decoded_refs)[\"meteor\"],\n",
    "        \"ROUGE\": rouge.compute(predictions=decoded_preds, references=decoded_refs)[\"rougeL\"]\n",
    "    }\n",
    "\n",
    "# ---------------------------\n",
    "# 4. ì²´í¬í¬ì¸íŠ¸ ì €ì¥\n",
    "# ---------------------------\n",
    "def save_checkpoint(model, optimizer, epoch, val_bleu, val_meteor, val_loss, path):\n",
    "    checkpoint = {\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        \"epoch\": epoch,\n",
    "        \"val_bleu\": val_bleu,\n",
    "        \"val_meteor\": val_meteor,\n",
    "        \"val_loss\": val_loss\n",
    "    }\n",
    "    torch.save(checkpoint, path)\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# 4. label smoothing ì ìš©\n",
    "# ---------------------------\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LabelSmoothingLoss(nn.Module):\n",
    "    def __init__(self, label_smoothing, tgt_vocab_size, ignore_index=-100):\n",
    "        super().__init__()\n",
    "        self.ignore_index = ignore_index\n",
    "        self.confidence = 1.0 - label_smoothing\n",
    "        self.smoothing = label_smoothing\n",
    "        self.vocab_size = tgt_vocab_size\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        pred = pred.log_softmax(dim=-1)  # (B*T, V)\n",
    "        true_dist = torch.zeros_like(pred)\n",
    "        true_dist.fill_(self.smoothing / (self.vocab_size - 2))\n",
    "        ignore = target == self.ignore_index\n",
    "        target = target.masked_fill(ignore, 0)\n",
    "        true_dist.scatter_(1, target.unsqueeze(1), self.confidence)\n",
    "        true_dist.masked_fill_(ignore.unsqueeze(1), 0.0)\n",
    "        return F.kl_div(pred, true_dist, reduction='batchmean')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_with_early_stopping(\n",
    "    model, train_loader, val_loader, tokenizer,\n",
    "    optimizer, criterion, device,\n",
    "    num_epochs=30,\n",
    "    teacher_forcing_ratio=0.5,\n",
    "    clip=1.0,\n",
    "    pad_id=0,\n",
    "    eos_id=2,\n",
    "    save_path=\"best_model.pt\",\n",
    "    early_stopping_patience=5,\n",
    "    checkpoint_dir=\"checkpoints\"\n",
    "):\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    best_bleu = -1\n",
    "    patience = 0\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        pbar = tqdm(train_loader, desc=f\"[Epoch {epoch}] Training\")\n",
    "\n",
    "        for X, y in pbar:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            decoder_input = y[:, :-1]\n",
    "            target = y[:, 1:]\n",
    "\n",
    "            output = model(X, decoder_input, teacher_forcing_ratio=teacher_forcing_ratio)\n",
    "            output = output.reshape(-1, output.shape[-1])\n",
    "            target = target.reshape(-1)\n",
    "\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            pbar.set_postfix(train_loss=epoch_loss / (pbar.n + 1))\n",
    "\n",
    "        # ğŸ”µ Train ìƒ˜í”Œ 5ê°œ ì¶œë ¥\n",
    "        model.eval()\n",
    "        train_preds, train_refs = [], []\n",
    "        with torch.no_grad():\n",
    "            for X_train, y_train in train_loader:\n",
    "                X_train, y_train = X_train.to(device), y_train.to(device)\n",
    "                out = model(X_train, y_train[:, :-1], teacher_forcing_ratio=0.0)\n",
    "                out_tokens = out.argmax(-1)\n",
    "                train_preds = [decode_sequence(model, x, tokenizer, device, eos_id=eos_id) for x in X_train[:5]]\n",
    "                train_refs = [\n",
    "                    tokenizer.decode([t for t in sent if t != PAD_ID and t != eos_id]).replace(\"â–\", \" \").strip()\n",
    "                    for sent in y_train[:5].tolist()\n",
    "                ]\n",
    "                break\n",
    "\n",
    "        print(\"\\nğŸŸ¦ [Train Samples]\")\n",
    "        for i in range(len(train_preds)):\n",
    "            print(f\"ğŸ”¹ [Pred] {train_preds[i]}\")\n",
    "            print(f\"ğŸ”¸ [True] {train_refs[i]}\")\n",
    "            print()\n",
    "\n",
    "        # ğŸŸ¢ Validation\n",
    "        val_loss = 0\n",
    "        preds, refs = [], []\n",
    "        with torch.no_grad():\n",
    "            for X_val, y_val in val_loader:\n",
    "                X_val, y_val = X_val.to(device), y_val.to(device)\n",
    "                out = model(X_val, y_val[:, :-1], teacher_forcing_ratio=0.0)\n",
    "                out_tokens = out.argmax(-1)\n",
    "                preds.extend(out_tokens.tolist())\n",
    "                refs.extend(y_val.tolist())\n",
    "\n",
    "                out = out.reshape(-1, out.shape[-1])\n",
    "                target = y_val[:, 1:].reshape(-1)\n",
    "                val_loss += criterion(out, target).item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        metrics = compute_metrics(preds, refs, tokenizer, eos_id)\n",
    "        val_bleu = metrics[\"BLEU\"]\n",
    "        val_preds = [decode_sequence(model, x, tokenizer, device, eos_id=eos_id) for x in X_val[:5]]\n",
    "        val_refs = decode_tokens(tokenizer, refs[:5], eos_id=eos_id, pad_id=pad_id)\n",
    "\n",
    "        print(\"\\nğŸŸ© [Validation Samples]\")\n",
    "        for i in range(len(val_preds)):\n",
    "            print(f\"ğŸ”¹ [Pred] {val_preds[i]}\")\n",
    "            print(f\"ğŸ”¸ [True] {val_refs[i]}\")\n",
    "            print()\n",
    "\n",
    "        print(f\"[Epoch {epoch}] Val Loss: {val_loss:.4f} | BLEU: {val_bleu:.4f} | METEOR: {metrics['METEOR']:.4f} | ROUGE: {metrics['ROUGE']:.4f}\")\n",
    "\n",
    "        # âœ… Checkpoint ì €ì¥\n",
    "        ckpt_path = os.path.join(checkpoint_dir, f\"checkpoint_epoch{epoch}.pt\")\n",
    "        save_checkpoint(\n",
    "            model,\n",
    "            optimizer,\n",
    "            epoch,\n",
    "            val_bleu,\n",
    "            metrics[\"METEOR\"],\n",
    "            val_loss,\n",
    "            ckpt_path  # âœ… ì—¬ê¸°ì— ì €ì¥!\n",
    "        )\n",
    "        \n",
    "        # â¬…ï¸ 2. BLEU ê¸°ì¤€ best model ì €ì¥\n",
    "        if val_bleu > best_bleu:\n",
    "            best_bleu = val_bleu\n",
    "            patience = 0\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            save_checkpoint(\n",
    "                model,\n",
    "                optimizer,\n",
    "                epoch,\n",
    "                val_bleu,\n",
    "                metrics[\"METEOR\"],\n",
    "                val_loss,\n",
    "                os.path.join(checkpoint_dir, \"best_checkpoint.pt\")  # âœ… ì—¬ê¸°ì—ë§Œ best ì €ì¥\n",
    "            )\n",
    "            print(f\"âœ… Best model saved at epoch {epoch} (BLEU={val_bleu:.4f})\")\n",
    "        else:\n",
    "            patience += 1\n",
    "            if patience >= early_stopping_patience:\n",
    "                print(f\"ğŸ›‘ Early stopping triggered. Best BLEU: {best_bleu:.4f}\")\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aad0fbb9-cbac-490a-abad-53f64a31faa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ Using CPU\n",
      "âœ… Seq2Seq model initialized and moved to cpu\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 1000  # âœ… vocab ì‚¬ì´ì¦ˆ í™•ì¥\n",
    "\n",
    "import torch\n",
    "\n",
    "# -------------------------\n",
    "# 0. ë””ë°”ì´ìŠ¤ ì„¤ì •\n",
    "# -------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if device.type == \"cuda\":\n",
    "    print(\"âœ… Using device:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"âš ï¸ Using CPU\")\n",
    "\n",
    "# -------------------------\n",
    "# 1. í•˜ì´í¼íŒŒë¼ë¯¸í„° ì •ì˜\n",
    "# -------------------------\n",
    "INPUT_DIM = 108\n",
    "ENC_HIDDEN_DIM = 256\n",
    "DEC_HIDDEN_DIM = 256\n",
    "EMB_DIM = 256\n",
    "VOCAB_SIZE = vocab_size      # âœ… ìµœì‹  SentencePiece vocab size ë°˜ì˜\n",
    "\n",
    "PAD_ID = 3              # âœ… pad_id ì„¤ì • (unk=0, bos=1, eos=2, pad=3)\n",
    "\n",
    "# -------------------------\n",
    "# 2. ëª¨ë¸ ì •ì˜\n",
    "# -------------------------\n",
    "encoder = Encoder(input_dim=INPUT_DIM, hidden_dim=ENC_HIDDEN_DIM)\n",
    "decoder = Decoder(\n",
    "    output_dim=VOCAB_SIZE,\n",
    "    emb_dim=EMB_DIM,\n",
    "    enc_hidden_dim=ENC_HIDDEN_DIM,\n",
    "    dec_hidden_dim=DEC_HIDDEN_DIM\n",
    ")\n",
    "\n",
    "model = Seq2Seq(encoder, decoder, device).to(device)\n",
    "print(\"âœ… Seq2Seq model initialized and moved to\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "30fce4fd-a5b0-484e-a2b0-b29ea64f8926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# í† í¬ë‚˜ì´ì € ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "import sentencepiece as spm\n",
    "from tqdm import tqdm  # âœ… ì¶”ì²œ ë°©ì‹\n",
    "import torch.nn as nn  # í•„ìš”ì‹œ ìƒë‹¨ì— ì¶”ê°€\n",
    "\n",
    "spm_tokenizer = spm.SentencePieceProcessor()\n",
    "spm_tokenizer.load(\"/teamspace/studios/this_studio/training/train/processed/spm.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f517e64b-08cb-4569-b4a7-a24ae970c0ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Using device: NVIDIA L40S\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2487/2487 [02:27<00:00, 16.84it/s, train_loss=0.836]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŸ¦ [Train Samples]\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì§€ì—­> <ê±´ë¬¼> í™”ì¬ ë°œìƒ, ì¸ê·¼ì£¼ë¯¼ì€ ì•ˆì „í•œ ëŒ€í”¼ ë°”ëŒ.\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„> <ì§€ì—­> <ê±´ë¬¼> í™”ì¬ ë°œìƒ, ì¸ê·¼ì£¼ë¯¼ì€ ì•ˆì „í•œ ê³³ìœ¼ë¡œ ëŒ€í”¼ ë°”ëŒ.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì§€ì—­> <ì§€ì—­> ì†Œì¬ ì˜¤í”¼ìŠ¤í…” í™”ì¬ë°œìƒìœ¼ë¡œ ì£¼ë³€ì€ êµí†µ ìš°íšŒí•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„> <ì§€ì—­> <ì§€ì—­> ì†Œì¬ ì˜¤í”¼ìŠ¤í…” í™”ì¬ë°œìƒìœ¼ë¡œ ì£¼ë³€ êµí†µì€ í˜¼ì¡í•˜ì˜¤ë‹ˆ ìš°íšŒí•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì§€ì—­> <ê±´ë¬¼> ë¡¯ë°ë¦¬ì•„  í™”ì¬ ë°œìƒ. ì£¼ë¯¼ì€ ì¸ê·¼ ì•ˆì „í•œ ê³³ìœ¼ë¡œ ëŒ€í”¼í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„> <ì§€ì—­> <ê±´ë¬¼> ë¡¯ë°ë¦¬ì•„ <ê±´ë¬¼> í™”ì¬ ë°œìƒ. ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „í•œ ê³³ìœ¼ë¡œ ëŒ€í”¼í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„>ê²½ <ì§€ì—­> <ì£¼ì†Œ> ì‚¼ì„±í™”ì¬ <ê±´ë¬¼> í™”ì¬ë¡œ ì—°ê¸° ë°œìƒ. ì£¼ë¯¼ì€ ì•ˆì „ì‚¬ê³  ì•ˆì „ì— ìœ ì˜ ë°”ëë‹ˆë‹¤\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„>ê²½ <ì§€ì—­> <ì£¼ì†Œ> ì‚¼ì„±í™”ì¬ <ê±´ë¬¼> í™”ì¬ë¡œ ì—°ê¸° ë°œìƒ. ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „ì— ìœ ì˜ ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ë„ë¡œ>ê°€ í™”ì¬ë¡œ ì¸í•´ í†µì œì¤‘ì´ì˜¤ë‹ˆ ì¸ê·¼ ì°¨ëŸ‰ ì£¼ë¯¼ì€ ì£¼ì‹œê¸° ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„> <ë„ë¡œ>ê°€ í™”ì¬ë¡œ ì¸í•´ ì°¨ëŸ‰ í†µì œì¤‘ì´ì˜¤ë‹ˆ ì¸ê·¼ ì°¨ëŸ‰ì€ ìš°íšŒí•˜ì—¬ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "\n",
      "ğŸŸ© [Validation Samples]\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì—­>ì— í™”ì¬, ë°œìƒ, ì£¼ë¯¼ì€ ë‹«ì•„ì£¼ì‹œê³  ë‹«ì•„ì£¼ì‹œê³  ì•ˆì „ì‚¬ê³ ì— ìœ ì˜ ë°”ëë‹ˆë‹¤\n",
      "ğŸ”¸ [True] 5.23. <ì‹œê°„> <ì§€ì—­> <ê±´ë¬¼> <ê±´ë¬¼> ì§€í•˜ì£¼ì°¨ì¥ í™”ì¬ë¡œ ì¸í•´ ì°¨ëŸ‰í†µì œ ì¤‘ì„ì„ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì§€ì—­> <ì£¼ì†Œ> <ê±´ë¬¼> í™”ì¬ ë°œìƒ.. ê¸°ê¸° ë°”ëë‹ˆë‹¤ ë°”ëë‹ˆë‹¤ ìš°íšŒí•˜ì—¬ ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] 5.23. <ì‹œê°„> <ì§€ì—­> <ê±´ë¬¼> <ê±´ë¬¼> ì§€í•˜ì£¼ì°¨ì¥ í™”ì¬ë¡œ ì¸í•´ ì°¨ëŸ‰í†µì œ ì¤‘ì„ì„ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì—­> ì¸ê·¼ <ê±´ë¬¼> í™”ì¬ ë°œìƒ, ì¸ê·¼ ì£¼ë¯¼ì€ ë‹«ì•„ì£¼ì‹œê³  ì•ˆì „ì‚¬ê³ ì— ìœ ì˜ ë°”ëë‹ˆë‹¤\n",
      "ğŸ”¸ [True] 5.23. <ì‹œê°„> <ì§€ì—­> <ê±´ë¬¼> <ê±´ë¬¼> ì§€í•˜ì£¼ì°¨ì¥ í™”ì¬ë¡œ ì¸í•´ ì°¨ëŸ‰í†µì œ ì¤‘ì„ì„ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì£¼ì†Œ> ì°¨ëŸ‰í†µì œ<ê±´ë¬¼> í™”ì¬ ë°œìƒìœ¼ë¡œ ì£¼ë¯¼ì€ ì•ˆì „í•œ ê³³ìœ¼ë¡œ ì•ˆì „í•œ ëŒ€í”¼í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„> ë°˜ì›”ê³µë‹¨ ë‚´ ëŒ€ë¦¼ë¹„ì•¤ì½” í™”ì¬ë¡œ ì¸í•´ ì°¨ëŸ‰í†µí–‰ ë¶ˆê°€í•˜ì˜¤ë‹ˆ ìš°íšŒí•˜ì—¬ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì§€ì—­> <ê±´ë¬¼> í™”ì¬ë¡œ  ê³  <ë„ë¡œ>ê°€ í†µì œ ë°œìƒí•˜ì˜€ìœ¼ë‹ˆ ë°œìƒí•˜ì˜€ìœ¼ë‹ˆ ìš°íšŒí•˜ì—¬ ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„> ë°˜ì›”ê³µë‹¨ ë‚´ ëŒ€ë¦¼ë¹„ì•¤ì½” í™”ì¬ë¡œ ì¸í•´ ì°¨ëŸ‰í†µí–‰ ë¶ˆê°€í•˜ì˜¤ë‹ˆ ìš°íšŒí•˜ì—¬ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "[Epoch 1] Val Loss: 3.4670 | BLEU: 0.2032 | METEOR: 0.3541 | ROUGE: 0.0000\n",
      "âœ… Best model saved at epoch 1 (BLEU=0.2032)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 2] Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2487/2487 [02:18<00:00, 18.02it/s, train_loss=0.342]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŸ¦ [Train Samples]\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì§€ì—­> <ì£¼ì†Œ> SM ì˜¤í”¼ìŠ¤í…” í™”ì¬ ë°œìƒ. ì¸ê·¼ ì•ˆì „ì— ë°”ëë‹ˆë‹¤\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„> <ì§€ì—­> <ì£¼ì†Œ> SM ì˜¤í”¼ìŠ¤í…” <ê±´ë¬¼> í™”ì¬ ë°œìƒ. ì•ˆì „ì— ìœ ì˜ ë°”ëë‹ˆë‹¤\n",
      "\n",
      "ğŸ”¹ [Pred] í˜„ì¬ <ì‚°> ì¼ëŒ€ ëŒ€í˜•í™”ì¬ë°œìƒ, <ë„ë¡œ>ë¥¼ ì‹œë¯¼ë“¤ê»˜ì„œëŠ” ë¥¼ ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ í˜„ì¬ <ì‚°> ì¼ëŒ€ ëŒ€í˜•í™”ì¬ë°œìƒ, <ì‚°> ì¸ê·¼ ì‹œë¯¼ë“¤ê»˜ì„œëŠ” <ë„ë¡œ>ë¥¼ ì´ìš©í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„>ê²½ <ì§€ì—­> <ì‚°>ê°€ì‚°ê¸¸ <ì£¼ì†Œ> í™”ì¬ë°œìƒ, ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „ì— ìœ ì˜í•˜ê¸° ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„>ê²½ <ì§€ì—­> <ì‚°>ê°€ì‚°ê¸¸ <ì£¼ì†Œ> í™”ì¬ë°œìƒ, ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „ì— ìœ ì˜í•˜ê¸° ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì§€ì—­> <ì§€ì—­> <ê±´ë¬¼> ìƒê°€ í™”ì¬ ë°œìƒ. ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „ì‚¬ê³  ë°œìƒì— ìœ ì˜ ë°”ëë‹ˆë‹¤\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„> <ì§€ì—­> <ì§€ì—­> <ê±´ë¬¼> ìƒê°€ í™”ì¬ ë°œìƒ. ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „ì‚¬ê³  ë°œìƒì— ìœ ì˜ ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì§€ì—­> <ì£¼ì†Œ> í™”ì¬ ë°œìƒ. ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „ì— ìœ ì˜ ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„> <ì§€ì—­> <ì£¼ì†Œ> í™”ì¬ ë°œìƒ. ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „ì‚¬ê³ ì— ìœ ì˜ ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "\n",
      "ğŸŸ© [Validation Samples]\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì—­> í™”ì¬ ë°œìƒ, ì¸ê·¼ ì£¼ë¯¼ì€ ì°½ë¬¸ì„ ë‹«ì•„ì£¼ì‹œê³  ì•ˆì „ì‚¬ê³ ì— ìœ ì˜ ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] 5.23. <ì‹œê°„> <ì§€ì—­> <ê±´ë¬¼> <ê±´ë¬¼> ì§€í•˜ì£¼ì°¨ì¥ í™”ì¬ë¡œ ì¸í•´ ì°¨ëŸ‰í†µì œ ì¤‘ì„ì„ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì§€ì—­> <ì§€ì—­> <ê±´ë¬¼> ì¸ê·¼ì—ì„œ ë°œìƒ..  ì£¼ë¯¼ë“¤ì€ ë°œìƒì— ìœ ì˜ ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] 5.23. <ì‹œê°„> <ì§€ì—­> <ê±´ë¬¼> <ê±´ë¬¼> ì§€í•˜ì£¼ì°¨ì¥ í™”ì¬ë¡œ ì¸í•´ ì°¨ëŸ‰í†µì œ ì¤‘ì„ì„ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì—­> ì¸ê·¼ <ê±´ë¬¼> í™”ì¬ë°œìƒ, ì¸ê·¼ ì£¼ë¯¼ì€ ë‹«ì•„ì£¼ì‹œê³  ì•ˆì „ì— ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] 5.23. <ì‹œê°„> <ì§€ì—­> <ê±´ë¬¼> <ê±´ë¬¼> ì§€í•˜ì£¼ì°¨ì¥ í™”ì¬ë¡œ ì¸í•´ ì°¨ëŸ‰í†µì œ ì¤‘ì„ì„ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì£¼ì†Œ> ëŒ€í˜•í™”ì¬ ë°œìƒ, ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „í•œ ê³³ìœ¼ë¡œ ëŒ€í”¼í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„> ë°˜ì›”ê³µë‹¨ ë‚´ ëŒ€ë¦¼ë¹„ì•¤ì½” í™”ì¬ë¡œ ì¸í•´ ì°¨ëŸ‰í†µí–‰ ë¶ˆê°€í•˜ì˜¤ë‹ˆ ìš°íšŒí•˜ì—¬ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„>ê²½<ì§€ì—­> <ì§€ì—­> <ê±´ë¬¼> í™”ì¬ë¡œ, ì£¼ë¯¼ë“¤ì€ ì£¼ë¯¼ë“¤ì€ ë°œìƒì— ìœ ì˜ ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„> ë°˜ì›”ê³µë‹¨ ë‚´ ëŒ€ë¦¼ë¹„ì•¤ì½” í™”ì¬ë¡œ ì¸í•´ ì°¨ëŸ‰í†µí–‰ ë¶ˆê°€í•˜ì˜¤ë‹ˆ ìš°íšŒí•˜ì—¬ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "[Epoch 2] Val Loss: 3.6630 | BLEU: 0.2268 | METEOR: 0.3920 | ROUGE: 0.0000\n",
      "âœ… Best model saved at epoch 2 (BLEU=0.2268)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 3] Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2487/2487 [02:15<00:00, 18.35it/s, train_loss=0.278]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŸ¦ [Train Samples]\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì§€ì—­> <ì£¼ì†Œ> í™”ì¬ ë°œìƒ. ì´ ì§€ì—­ì„ ìš°íšŒí•˜ì—¬ ì£¼ì‹œê³  ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „ì‚¬ê³  ë°œìƒì— ìœ ì˜ ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„> <ì§€ì—­> <ì£¼ì†Œ> í™”ì¬ ë°œìƒ. ì´ ì§€ì—­ì„ ìš°íšŒí•˜ì—¬ ì£¼ì‹œê³  ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „ì‚¬ê³  ë°œìƒì— ìœ ì˜ ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì§€ì—­> ë‚´ ëŒ€í˜•í™”ì¬ ë°œìƒ, ì¸ê·¼ ì§€ì—­ ì£¼ë¯¼ê»˜ì„œëŠ” ìœ ì˜ ë°”ëë‹ˆë‹¤\n",
      "ğŸ”¸ [True] í˜„ì¬ <ì§€ì—­> ë‚´ ëŒ€í˜•í™”ì¬ ë°œìƒ, ì¸ê·¼ ì§€ì—­ ì£¼ë¯¼ê»˜ì„œëŠ” ì•ˆì „ì— ìœ ì˜ ë°”ëë‹ˆë‹¤\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì§€ì—­> ì‚¼í™˜ì•„ë¥´ëˆ„ë³´ <ê±´ë¬¼> í™”ì¬ ë°œìƒ. ì´ ì§€ì—­ì„ ìš°íšŒí•˜ì—¬ ì£¼ì‹œê³  ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „ì‚¬ê³  ë°œìƒì— ìœ ì˜ ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„> <ì§€ì—­> ì‚¼í™˜ì•„ë¥´ëˆ„ë³´ <ê±´ë¬¼> í™”ì¬ ë°œìƒ. ì´ ì§€ì—­ì„ ìš°íšŒí•˜ì—¬ ì£¼ì‹œê³  ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „ì‚¬ê³  ë°œìƒì— ìœ ì˜ ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì§€ì—­> <ì£¼ì†Œ> ì†¡ìœ ê´€ê³µì‚¬ í™”ì¬ ë°œìƒ. ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „í•œ ê³³ìœ¼ë¡œ ëŒ€í”¼í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„> <ì§€ì—­> <ì£¼ì†Œ> ì†¡ìœ ê´€ê³µì‚¬ í™”ì¬ ë°œìƒ. ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „í•œ ê³³ìœ¼ë¡œ ëŒ€í”¼í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì§€ì—­> <ì£¼ì†Œ> <ê±´ë¬¼> í™”ì¬ë°œìƒ. ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „ì‚¬ê³ ì— ìœ ì˜ ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„> <ì§€ì—­> <ì£¼ì†Œ> <ê±´ë¬¼> í™”ì¬ë°œìƒ. ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „ì‚¬ê³ ì— ìœ ì˜ ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "\n",
      "ğŸŸ© [Validation Samples]\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> í™”ì¬ ë°œìƒìœ¼ë¡œ ì¸ê·¼, ì£¼ë¯¼ì€ì— ê³„ì‹ ë¶„ ì‹ ì† ë°œìƒì— ìœ ì˜ ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] 5.23. <ì‹œê°„> <ì§€ì—­> <ê±´ë¬¼> <ê±´ë¬¼> ì§€í•˜ì£¼ì°¨ì¥ í™”ì¬ë¡œ ì¸í•´ ì°¨ëŸ‰í†µì œ ì¤‘ì„ì„ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì§€ì—­> <ì§€ì—­> <ê±´ë¬¼>. ë°œìƒ. í†µí–‰ì´ê¸° ìœ„ ìˆìœ¼ë‹ˆ, ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] 5.23. <ì‹œê°„> <ì§€ì—­> <ê±´ë¬¼> <ê±´ë¬¼> ì§€í•˜ì£¼ì°¨ì¥ í™”ì¬ë¡œ ì¸í•´ ì°¨ëŸ‰í†µì œ ì¤‘ì„ì„ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ë„ë¡œ> í™”ì¬ ë°œìƒ, í™”ì¬ì „ë™ì„ í™”ì¬, ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „ì‚¬ê³ ì— ìœ ì˜ ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] 5.23. <ì‹œê°„> <ì§€ì—­> <ê±´ë¬¼> <ê±´ë¬¼> ì§€í•˜ì£¼ì°¨ì¥ í™”ì¬ë¡œ ì¸í•´ ì°¨ëŸ‰í†µì œ ì¤‘ì„ì„ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ë„ë¡œ> í™”ì¬ ë°œìƒ ì£¼ë¯¼ì€ ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „í•œ ê³³ìœ¼ë¡œ.\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„> ë°˜ì›”ê³µë‹¨ ë‚´ ëŒ€ë¦¼ë¹„ì•¤ì½” í™”ì¬ë¡œ ì¸í•´ ì°¨ëŸ‰í†µí–‰ ë¶ˆê°€í•˜ì˜¤ë‹ˆ ìš°íšŒí•˜ì—¬ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„>ê²½ <ì§€ì—­> <ê±´ë¬¼> í™”ì¬ë¡œ, êµí†µì´ ë°œìƒí•˜ì˜€ìœ¼ë‹ˆ ì•ˆì „ì‚¬ê³  ìœ ì˜ ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„> ë°˜ì›”ê³µë‹¨ ë‚´ ëŒ€ë¦¼ë¹„ì•¤ì½” í™”ì¬ë¡œ ì¸í•´ ì°¨ëŸ‰í†µí–‰ ë¶ˆê°€í•˜ì˜¤ë‹ˆ ìš°íšŒí•˜ì—¬ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "[Epoch 3] Val Loss: 3.7028 | BLEU: 0.2413 | METEOR: 0.4095 | ROUGE: 0.0000\n",
      "âœ… Best model saved at epoch 3 (BLEU=0.2413)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 4] Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2487/2487 [02:16<00:00, 18.28it/s, train_loss=0.271]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŸ¦ [Train Samples]\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> í•˜ì–‘ë§ˆì„ ì¸ê·¼ì—ì„œ í™”ì¬ ë°œìƒ, ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „í•œ ê³³ìœ¼ë¡œ ëŒ€í”¼ë°”ëë‹ˆë‹¤\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„> í˜„ì¬ í•˜ì–‘ë§ˆì„ ì¸ê·¼ì—ì„œ í™”ì¬ ì‚¬ê³ ë°œìƒ, ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „í•œ ê³³ìœ¼ë¡œ ëŒ€í”¼ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] ì â†’ì„í¬ <ë„ë¡œ> <ì§€ì—­> í™”ì¬ ì‚¬ê³  ì²˜ë¦¬ê°€  â‡  ë˜ì–´ êµí†µí†µì œêµ¬ê°„ì„ í•´ì œí•˜ì˜¤ë‹ˆ ì°¸ê³ í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] ë™ì â†’ì„í¬ <ë„ë¡œ> <ì§€ì—­> í™”ì¬ ì‚¬ê³  ì²˜ë¦¬ê°€ <ì§€ì—­> ë˜ì–´ êµí†µí†µì œêµ¬ê°„ì„ í•´ì œí•˜ì˜¤ë‹ˆ ì°¸ê³ í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì§€ì—­> ê³„ì–‘ë§ˆì„ ì¸ê·¼ì—ì„œ ë°œìƒí•œ í™”ì¬ ì”í™”ì •ë¦¬ë¡œ ì—°ê¸°ê°€ ë§ì´ ë‚˜ê³  ìˆìœ¼ë‹ˆ ì£¼ë¯¼ì€ ëŒ€í”¼ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„> <ì§€ì—­> ê³„ì–‘ë§ˆì„ ì¸ê·¼ì—ì„œ ë°œìƒí•œ í™”ì¬ ì”í™”ì •ë¦¬ë¡œ ì—°ê¸°ê°€ ë§ì´ ë‚˜ê³  ìˆìœ¼ë‹ˆ ì¸ê·¼ ì£¼ë¯¼ì€ ëŒ€í”¼ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì§€ì—­> <ì§€ì—­> <ì£¼ì†Œ>ì— ë°œìƒí•œ í™”ì¬ ì§„ì••ì¤‘. ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „ì‚¬ê³  ë°œìƒì— ìœ ì˜ ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„> <ì§€ì—­> <ì§€ì—­> <ì£¼ì†Œ>ì— ë°œìƒí•œ í™”ì¬ ì§„ì••ì¤‘. ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „ì‚¬ê³  ë°œìƒì— ìœ ì˜ ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì§€ì—­> <ì£¼ì†Œ>ì—ì„œ í™”ì¬ì‚¬ê³  ë°œìƒ. <ì‚°> ë° ì£¼ë³€ìƒí™© ì˜ˆì£¼ì‹œíŒœì— ìœ ì˜ ë°”ëë‹ˆë‹¤\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„> <ì§€ì—­> <ì£¼ì†Œ>ì—ì„œ í™”ì¬ì‚¬ê³  ë°œìƒ. <ì‚°> ë° ì£¼ë³€ìƒí™© ì˜ˆì˜ì£¼ì‹œë¡œ ì•ˆì „ì‚¬ê³  ë°œìƒì— ìœ ì˜ ë°”ëë‹ˆë‹¤\n",
      "\n",
      "\n",
      "ğŸŸ© [Validation Samples]\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì£¼ì†Œ> í™”ì¬ë°œìƒ, ì¸ê·¼ ê±´ë¬¼ í™”ì¬ ë°œìƒ ì°¨ëŸ‰í†µì œ ì¸ëª… ë°œìƒì— ìœ ì˜ ë°”ëë‹ˆë‹¤\n",
      "ğŸ”¸ [True] 5.23. <ì‹œê°„> <ì§€ì—­> <ê±´ë¬¼> <ê±´ë¬¼> ì§€í•˜ì£¼ì°¨ì¥ í™”ì¬ë¡œ ì¸í•´ ì°¨ëŸ‰í†µì œ ì¤‘ì„ì„ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì§€ì—­> <ì§€ì—­> <ê±´ë¬¼>. ë°œìƒ. ì§€ì—­ì„ë‚˜ëŠ” ìš°íšŒí•˜ì—¬ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤\n",
      "ğŸ”¸ [True] 5.23. <ì‹œê°„> <ì§€ì—­> <ê±´ë¬¼> <ê±´ë¬¼> ì§€í•˜ì£¼ì°¨ì¥ í™”ì¬ë¡œ ì¸í•´ ì°¨ëŸ‰í†µì œ ì¤‘ì„ì„ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì‚°> ì¸ê·¼ 1 ê±´ë¬¼í™”ì¬, í™”ì¬. ì£¼ë¯¼ì€ ì£¼ë¯¼ì€ ë“± ì•ˆì „ì— ìœ ì˜ ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] 5.23. <ì‹œê°„> <ì§€ì—­> <ê±´ë¬¼> <ê±´ë¬¼> ì§€í•˜ì£¼ì°¨ì¥ í™”ì¬ë¡œ ì¸í•´ ì°¨ëŸ‰í†µì œ ì¤‘ì„ì„ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì£¼ì†Œ> í™”ì¬ ë°œìƒ, ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „í•œ ê³³ìœ¼ë¡œ ëŒ€í”¼í•˜ì—¬ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„> ë°˜ì›”ê³µë‹¨ ë‚´ ëŒ€ë¦¼ë¹„ì•¤ì½” í™”ì¬ë¡œ ì¸í•´ ì°¨ëŸ‰í†µí–‰ ë¶ˆê°€í•˜ì˜¤ë‹ˆ ìš°íšŒí•˜ì—¬ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„>ê²½ <ì§€ì—­>   ì—ì„œ ë°œìƒí•˜ì˜€ìœ¼ë‹ˆ, ì£¼ë¯¼ë“¤ì€ ë°œìƒí•œ ìš°íšŒí•˜ì—¬ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„> ë°˜ì›”ê³µë‹¨ ë‚´ ëŒ€ë¦¼ë¹„ì•¤ì½” í™”ì¬ë¡œ ì¸í•´ ì°¨ëŸ‰í†µí–‰ ë¶ˆê°€í•˜ì˜¤ë‹ˆ ìš°íšŒí•˜ì—¬ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "[Epoch 4] Val Loss: 3.6291 | BLEU: 0.2529 | METEOR: 0.4156 | ROUGE: 0.0000\n",
      "âœ… Best model saved at epoch 4 (BLEU=0.2529)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 5] Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2487/2487 [02:15<00:00, 18.40it/s, train_loss=0.255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŸ¦ [Train Samples]\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì§€ì—­><ì§€ì—­><ì£¼ì†Œ> <ì£¼ì†Œ> ëŒ€í˜•í™”ì¬ë°œìƒìœ¼ë¡œ ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „ì— ìœ ì˜ ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„> <ì§€ì—­> <ì£¼ì†Œ> <ì£¼ì†Œ> ëŒ€í˜•í™”ì¬ë°œìƒìœ¼ë¡œ ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „ì— ìœ ì˜í•˜ê¸° ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì§€ì—­> <ì£¼ì†Œ> ì¶©ì •êµ  <ê±´ë¬¼> í™”ì¬ ë°œìƒ, ì´ ì§€ì—­ì„ ìš°íšŒí•˜ì—¬ ì£¼ì‹œê³  ì£¼ë¯¼ì€ ì•ˆì „ì‚¬ê³  ë°œìƒì— ìœ ì˜ ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] í˜„ì¬ <ì§€ì—­> <ì£¼ì†Œ> ì¶©ì •êµ ì¸ê·¼ <ê±´ë¬¼> í™”ì¬ ë°œìƒ, ì´ ì§€ì—­ì„ ìš°íšŒí•˜ì—¬ ì£¼ì‹œê³  ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „ì‚¬ê³  ë°œìƒì— ìœ ì˜ ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì§€ì—­> <ì£¼ì†Œ> <ê±´ë¬¼> <ê±´ë¬¼> í™”ì¬ê°€ ë°œìƒí•˜ì˜€ìœ¼ë‹ˆ ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „í•œ ê³³ìœ¼ë¡œ ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„> <ì§€ì—­> <ì£¼ì†Œ> <ê±´ë¬¼> <ê±´ë¬¼> í™”ì¬ê°€ ë°œìƒí•˜ì˜€ìœ¼ë‹ˆ ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „í•œ ê³³ìœ¼ë¡œ ëŒ€í”¼ ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì§€ì—­> ëŒ€í˜•í™”ì¬ ë°œìƒ. ì¸ê·¼ ì£¼ë¯¼ì€ ì™¸ì¶œì„ ìì œí•˜ëŠ” ë“± ì•ˆì „ì‚¬ê³ ì— ìœ ì˜ ë°”ëë‹ˆë‹¤\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„> <ì§€ì—­> ëŒ€í˜•í™”ì¬ ë°œìƒ. ì¸ê·¼ ì£¼ë¯¼ì€ ì™¸ì¶œì„ ìì œí•˜ëŠ” ë“± ì•ˆì „ì‚¬ê³ ì— ìœ ì˜ ë°”ëë‹ˆë‹¤\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì—­> ì¸ê·¼ì—ì„œ ë°œìƒí•œ í™”ì¬ ì”í™”ì •ë¦¬ë¡œ ì—°ê¸°ê°€ ë°œìƒë˜ê³  ìˆìœ¼ë‹ˆ ì¸ê·¼ ì£¼ë¯¼ê»˜ì„œëŠ” ìœ ì˜ ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„> <ì—­> ì¸ê·¼ì—ì„œ ë°œìƒí•œ í™”ì¬ ì”í™”ì •ë¦¬ë¡œ ì—°ê¸°ê°€ ë°œìƒë˜ê³  ìˆìœ¼ë‹ˆ ì¸ê·¼ ì£¼ë¯¼ê»˜ì„œëŠ” ìœ ì˜ ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "\n",
      "ğŸŸ© [Validation Samples]\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì§€ì—­> ì¸ê·¼ í™”ì¬ë°œìƒ, ì¸ê·¼ ì£¼ë¯¼ë“¤ê»˜ì„œëŠ”ì— ê³„ì‹  ì°½ë¬¸ì„ ë“± ì•ˆì „ì— ìœ ì˜.\n",
      "ğŸ”¸ [True] 5.23. <ì‹œê°„> <ì§€ì—­> <ê±´ë¬¼> <ê±´ë¬¼> ì§€í•˜ì£¼ì°¨ì¥ í™”ì¬ë¡œ ì¸í•´ ì°¨ëŸ‰í†µì œ ì¤‘ì„ì„ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì§€ì—­> ë‹¬ë™ì§€ í™”ì¬ ë°œìƒ. ì´ ì§€ì—­ì„ ìš°íšŒí•˜ì—¬ ì£¼ì‹œê³ , ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] 5.23. <ì‹œê°„> <ì§€ì—­> <ê±´ë¬¼> <ê±´ë¬¼> ì§€í•˜ì£¼ì°¨ì¥ í™”ì¬ë¡œ ì¸í•´ ì°¨ëŸ‰í†µì œ ì¤‘ì„ì„ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> ë°œìƒí•œ<ì§€ì—­> 1ë²ˆì¶œêµ¬ì‚¬ ë¶€ê·¼84 í™”ì¬<ê±´ë¬¼>, ë°œìƒ ì¸ê·¼ì— ìœ ì˜ ìœ ì˜ ìœ ì˜ ë°”ëë‹ˆë‹¤\n",
      "ğŸ”¸ [True] 5.23. <ì‹œê°„> <ì§€ì—­> <ê±´ë¬¼> <ê±´ë¬¼> ì§€í•˜ì£¼ì°¨ì¥ í™”ì¬ë¡œ ì¸í•´ ì°¨ëŸ‰í†µì œ ì¤‘ì„ì„ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì£¼ì†Œ> í™”ì¬ ë°œìƒ, ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „í•œ ê³³ìœ¼ë¡œ ëŒ€í”¼í•˜ì—¬ ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„> ë°˜ì›”ê³µë‹¨ ë‚´ ëŒ€ë¦¼ë¹„ì•¤ì½” í™”ì¬ë¡œ ì¸í•´ ì°¨ëŸ‰í†µí–‰ ë¶ˆê°€í•˜ì˜¤ë‹ˆ ìš°íšŒí•˜ì—¬ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„>ê²½ <ì§€ì—­> <ê±´ë¬¼>ì—ì„œ í™”ì¬ê°€ ë°œìƒí•˜ì˜€ìœ¼ë‹ˆ ì¸ê·¼ ì£¼ë¯¼ì€ ìš°íšŒí•˜ì—¬ ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„> ë°˜ì›”ê³µë‹¨ ë‚´ ëŒ€ë¦¼ë¹„ì•¤ì½” í™”ì¬ë¡œ ì¸í•´ ì°¨ëŸ‰í†µí–‰ ë¶ˆê°€í•˜ì˜¤ë‹ˆ ìš°íšŒí•˜ì—¬ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "[Epoch 5] Val Loss: 3.7314 | BLEU: 0.2443 | METEOR: 0.4167 | ROUGE: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 6] Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2487/2487 [02:15<00:00, 18.30it/s, train_loss=0.252]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŸ¦ [Train Samples]\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì§€ì—­> <ì§€ì—­> <ê±´ë¬¼> í™”ì¬ ë°œìƒ ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „ì‚¬ê³  ìœ ì˜ ìœ ì˜ ë°”ëë‹ˆë‹¤\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„> <ì§€ì—­> <ì§€ì—­> <ê±´ë¬¼> í™”ì¬ ë°œìƒ, ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „ì‚¬ê³  ë°œìƒì— ìœ ì˜ ë°”ëë‹ˆë‹¤\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> ë°˜ì›”ê³µë‹¨ ì¸ê·¼ì—ì„œ ë°œìƒí•œ í™”ì¬ ì‚¬ê³  ìˆ˜ìŠµìœ¼ë¡œ <ë„ë¡œ> í˜¼ì¡í•˜ì˜¤ë‹ˆ ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„> ë°˜ì›”ê³µë‹¨ ì¸ê·¼ì—ì„œ ë°œìƒí•œ í™”ì¬ ì‚¬ê³  ìˆ˜ìŠµìœ¼ë¡œ <ë„ë¡œ> í˜¼ì¡í•˜ì˜¤ë‹ˆ ìš°íšŒí•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì§€ì—­> <ì§€ì—­> <ì§€ì—­> <ì£¼ì†Œ> <ê±´ë¬¼> í™”ì¬ë°œìƒ, í™”ì¬, ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „ì— ìœ ì˜ ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„> <ì§€ì—­> <ì§€ì—­> <ì§€ì—­> <ì£¼ì†Œ> <ê±´ë¬¼> í™”ì¬ ë°œìƒ, ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „ì— ìœ ì˜ ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] ì›” 26ì¼ <ì‹œê°„> <ì§€ì—­><ë„ë¡œ> ë°œìƒìœ¼ë¡œ <ë„ë¡œ>ê°€ í˜¼ì¡í•˜ì˜¤ë‹ˆ, ìš°íšŒí•˜ì—¬ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤\n",
      "ğŸ”¸ [True] 7ì›” 26ì¼ <ì‹œê°„> <ì§€ì—­> <ë„ë¡œ> í™”ì¬ ë°œìƒìœ¼ë¡œ ì–‘ë°©í–¥ ì°¨ëŸ‰í†µì œ í•˜ì˜¤ë‹ˆ, ìš°íšŒí•˜ì—¬ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„>í˜„ì¬ <ì§€ì—­> <í•™êµ> ë’·í¸ <ê±´ë¬¼> í™”ì¬ ë°œìƒ ì—°ê¸°, ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „ì— ìœ ì˜ ë°”ëë‹ˆë‹¤\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„>ê²½ <ì§€ì—­> <í•™êµ> ë’·í¸ <ê±´ë¬¼> í™”ì¬ë¡œ ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „ì‚¬ê³  ë°œìƒì— ìœ ì˜ ë°”ëë‹ˆë‹¤\n",
      "\n",
      "\n",
      "ğŸŸ© [Validation Samples]\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì—­>ì— ë°œìƒ, ì£¼ë¯¼ë“¤ê»˜ì„œëŠ”ì›”9ì¼ ìœ ì˜ ë°”ëë‹ˆë‹¤\n",
      "ğŸ”¸ [True] 5.23. <ì‹œê°„> <ì§€ì—­> <ê±´ë¬¼> <ê±´ë¬¼> ì§€í•˜ì£¼ì°¨ì¥ í™”ì¬ë¡œ ì¸í•´ ì°¨ëŸ‰í†µì œ ì¤‘ì„ì„ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì§€ì—­> <ë„ë¡œ> í™”ì¬ ë°œìƒ, ì¸ê·¼ ì£¼ë¯¼ì€ ì§€ì—­ì„ ì´ìš© ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] 5.23. <ì‹œê°„> <ì§€ì—­> <ê±´ë¬¼> <ê±´ë¬¼> ì§€í•˜ì£¼ì°¨ì¥ í™”ì¬ë¡œ ì¸í•´ ì°¨ëŸ‰í†µì œ ì¤‘ì„ì„ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì§€ì—­> ë¡¯ë°ë¦¬ì•„<ì—­>, í™”ì¬ ë°œìƒí•œì— ìœ ì˜.\n",
      "ğŸ”¸ [True] 5.23. <ì‹œê°„> <ì§€ì—­> <ê±´ë¬¼> <ê±´ë¬¼> ì§€í•˜ì£¼ì°¨ì¥ í™”ì¬ë¡œ ì¸í•´ ì°¨ëŸ‰í†µì œ ì¤‘ì„ì„ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ê±´ë¬¼> í™”ì¬ ë°œìƒ. ì¸ê·¼ ì£¼ë¯¼ì€ ê³³ìœ¼ë¡œ ì•ˆì „í•œ ëŒ€í”¼í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„> ë°˜ì›”ê³µë‹¨ ë‚´ ëŒ€ë¦¼ë¹„ì•¤ì½” í™”ì¬ë¡œ ì¸í•´ ì°¨ëŸ‰í†µí–‰ ë¶ˆê°€í•˜ì˜¤ë‹ˆ ìš°íšŒí•˜ì—¬ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì§€ì—­><ì§€ì—­><ê±´ë¬¼> <ë„ë¡œ> í™”ì¬. ì£¼ë¯¼ì€ ì£¼ë¯¼ë“¤ì€ ê³³ìœ¼ë¡œì—ì„œ ë°”ëë‹ˆë‹¤ ë°”ëë‹ˆë‹¤\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„> ë°˜ì›”ê³µë‹¨ ë‚´ ëŒ€ë¦¼ë¹„ì•¤ì½” í™”ì¬ë¡œ ì¸í•´ ì°¨ëŸ‰í†µí–‰ ë¶ˆê°€í•˜ì˜¤ë‹ˆ ìš°íšŒí•˜ì—¬ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "[Epoch 6] Val Loss: 3.6404 | BLEU: 0.2270 | METEOR: 0.3926 | ROUGE: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 7] Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2487/2487 [02:14<00:00, 18.50it/s, train_loss=0.241]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŸ¦ [Train Samples]\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì§€ì—­> <ê±´ë¬¼> í™”ì¬ ë°œìƒìœ¼ë¡œ ì—°ê¸° ë‹¤ìˆ˜ ë°œìƒ. ì¸ê·¼ ì£¼ë¯¼ì€ ë¹„ìƒìƒí™© ë°œìƒì— ìœ ì˜ ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„> <ì§€ì—­> <ê±´ë¬¼> í™”ì¬ ë°œìƒìœ¼ë¡œ ì—°ê¸° ë‹¤ìˆ˜ ë°œìƒ. ì¸ê·¼ ì£¼ë¯¼ì€ ë¹„ìƒìƒí™© ë°œìƒì— ìœ ì˜ ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„>ë¶€í„° <ì§€ì—­> <ì§€ì—­> ë¶€ì˜3ì°¨ í™”ì¬ ë°œìƒ, ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „í•œ ê³³ìœ¼ë¡œ ëŒ€í”¼í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„>ë¶€í„° <ì§€ì—­> <ì§€ì—­> ë¶€ì˜3ì°¨ í™”ì¬ ë°œìƒ, ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „í•œ ê³³ìœ¼ë¡œ ëŒ€í”¼í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì§€ì—­> <ê±´ë¬¼>ì—ì„œ í™”ì¬ ë°œìƒ, ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „ì— ìœ ì˜ ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„> <ì§€ì—­> <ê±´ë¬¼>ì—ì„œ í™”ì¬ ë°œìƒ, ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „ì— ìœ ì˜ ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì§€ì—­> <ì§€ì—­> <ì£¼ì†Œ> í™”ì¬ ë°œìƒ. ì£¼ë³€ìœ¼ë¡œ í™•ì‚°ë  ìš°ë ¤ê°€ ìˆìœ¼ë‹ˆ ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „í•œ ê³³ìœ¼ë¡œ ëŒ€í”¼í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„> <ì§€ì—­> <ì§€ì—­> <ì£¼ì†Œ> í™”ì¬ ë°œìƒ. ì£¼ë³€ìœ¼ë¡œ í™•ì‚°ë  ìš°ë ¤ê°€ ìˆìœ¼ë‹ˆ ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „í•œ ê³³ìœ¼ë¡œ ëŒ€í”¼í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ë„ë¡œ> í™”ì¬ ë°œìƒìœ¼ë¡œ <ë„ë¡œ>ê°€ í˜¼ì¡í•˜ì˜¤ë‹ˆ ì°¨ëŸ‰ì„ ìš°íšŒí•˜ì—¬ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„> <ë„ë¡œ> í™”ì¬ ë°œìƒìœ¼ë¡œ <ë„ë¡œ>ê°€ í˜¼ì¡í•˜ì˜¤ë‹ˆ ì°¨ëŸ‰ì„ ìš°íšŒí•˜ì—¬ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "\n",
      "ğŸŸ© [Validation Samples]\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì—­> í™”ì¬ ë°œìƒ. ì¸ê·¼ ì£¼ë¯¼ì€ ì°¨ëŸ‰ ë‹«ì•„ì£¼ì‹œê³  ì•ˆì „ì‚¬ê³ ì— ìœ ì˜ ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] 5.23. <ì‹œê°„> <ì§€ì—­> <ê±´ë¬¼> <ê±´ë¬¼> ì§€í•˜ì£¼ì°¨ì¥ í™”ì¬ë¡œ ì¸í•´ ì°¨ëŸ‰í†µì œ ì¤‘ì„ì„ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì§€ì—­> <ë„ë¡œ> í™”ì¬ë¡œ í™”ì¬ë°œìƒ. ì¸ê·¼ ì£¼ë¯¼ì€ë©”ëœ°<ì£¼ì†Œ> ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] 5.23. <ì‹œê°„> <ì§€ì—­> <ê±´ë¬¼> <ê±´ë¬¼> ì§€í•˜ì£¼ì°¨ì¥ í™”ì¬ë¡œ ì¸í•´ ì°¨ëŸ‰í†µì œ ì¤‘ì„ì„ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„>ì¼<ì‹œê°„> <ì—­> ì¸ê·¼ í™”ì¬ë°œìƒ ì„œëŒ€ë¬¸ì— ë°œìƒ. ì¸ëª… ë°œìƒì— ìœ ì˜ ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] 5.23. <ì‹œê°„> <ì§€ì—­> <ê±´ë¬¼> <ê±´ë¬¼> ì§€í•˜ì£¼ì°¨ì¥ í™”ì¬ë¡œ ì¸í•´ ì°¨ëŸ‰í†µì œ ì¤‘ì„ì„ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ê±´ë¬¼> í™”ì¬ ë°œìƒ. ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „í•œ ê³³ìœ¼ë¡œ ëŒ€í”¼í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„> ë°˜ì›”ê³µë‹¨ ë‚´ ëŒ€ë¦¼ë¹„ì•¤ì½” í™”ì¬ë¡œ ì¸í•´ ì°¨ëŸ‰í†µí–‰ ë¶ˆê°€í•˜ì˜¤ë‹ˆ ìš°íšŒí•˜ì—¬ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„>ê²½<ì§€ì—­><ì§€ì—­><ì§€ì—­><ê±´ë¬¼> í™”ì¬ë¡œ ì¸í•´ì„œì—ì„œ ë°œìƒí•˜ì˜€ìœ¼ë‹ˆ ìš°íšŒí•˜ì—¬ ì¸ê·¼ ì£¼ë¯¼ì€ ìœ ì˜ ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„> ë°˜ì›”ê³µë‹¨ ë‚´ ëŒ€ë¦¼ë¹„ì•¤ì½” í™”ì¬ë¡œ ì¸í•´ ì°¨ëŸ‰í†µí–‰ ë¶ˆê°€í•˜ì˜¤ë‹ˆ ìš°íšŒí•˜ì—¬ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "[Epoch 7] Val Loss: 3.8326 | BLEU: 0.2608 | METEOR: 0.4440 | ROUGE: 0.0000\n",
      "âœ… Best model saved at epoch 7 (BLEU=0.2608)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 8] Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2487/2487 [02:15<00:00, 18.31it/s, train_loss=0.257]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŸ¦ [Train Samples]\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì§€ì—­> <ì§€ì—­> <ì£¼ì†Œ> í™”ì¬ ë°œìƒ, ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „ì‚¬ê³  ë°œìƒì— ìœ ì˜ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„> <ì§€ì—­> <ì§€ì—­> <ì£¼ì†Œ> í™”ì¬ ë°œìƒ, ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „ì‚¬ê³  ë°œìƒì— ìœ ì˜ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„>ê²½ <ë„ë¡œ>ì— í™”ì¬ê°€ ë°œìƒí•˜ì˜€ìœ¼ë‹ˆ ì¸ê·¼ ì£¼ë¯¼ê»˜ì„œëŠ” ì•ˆì „ì— ìœ ì˜ ë°”ëë‹ˆë‹¤\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„>ê²½ <ë„ë¡œ>ì— í™”ì¬ê°€ ë°œìƒí•˜ì˜€ìœ¼ë‹ˆ ì¸ê·¼ ì£¼ë¯¼ê»˜ì„œëŠ” ì•ˆì „ì— ìœ ì˜ ë°”ëë‹ˆë‹¤\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì§€ì—­> <ì§€ì—­> <ì£¼ì†Œ> <ê±´ë¬¼> í™”ì¬ ë°œìƒ. ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „í•œ ê³³ìœ¼ë¡œ ëŒ€í”¼í•˜ëŠ” ë“± ì•ˆì „ì— ìœ ì˜ ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„> <ì§€ì—­> <ì§€ì—­> <ì£¼ì†Œ> <ê±´ë¬¼> í™”ì¬ ë°œìƒ. ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „í•œ ê³³ìœ¼ë¡œ ëŒ€í”¼í•˜ëŠ” ë“± ì•ˆì „ì— ìœ ì˜ ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì§€ì—­> <ê±´ë¬¼>ì—ì„œ í™”ì¬ ë°œìƒ, ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „ì— ìœ ì˜ ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„> <ì§€ì—­> <ê±´ë¬¼>ì—ì„œ í™”ì¬ ë°œìƒ, ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „ì— ìœ ì˜ ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì§€ì—­> <ì§€ì—­> <ì£¼ì†Œ> ì¸ê·¼ ìƒê°€, <ê±´ë¬¼>, ë†ê²½ì§€ ë“± í™”ì¬ë°œìƒ ìœ ì˜ ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„> <ì§€ì—­> <ì§€ì—­> <ì£¼ì†Œ> ì¸ê·¼ ìƒê°€, <ê±´ë¬¼>, ë†ê²½ì§€ ë“± í™”ì¬ë°œìƒ ìœ ì˜ ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "\n",
      "ğŸŸ© [Validation Samples]\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì—­> ì¸ê·¼ í™”ì¬ ë°œìƒ, ì¸ê·¼ ì£¼ë¯¼ì€ ì°½ë¬¸ì„ ë‹«ì•„ì£¼ì‹œê³  ì•ˆì „ì‚¬ê³ ì— ìœ ì˜ ë°”ëë‹ˆë‹¤\n",
      "ğŸ”¸ [True] 5.23. <ì‹œê°„> <ì§€ì—­> <ê±´ë¬¼> <ê±´ë¬¼> ì§€í•˜ì£¼ì°¨ì¥ í™”ì¬ë¡œ ì¸í•´ ì°¨ëŸ‰í†µì œ ì¤‘ì„ì„ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì§€ì—­> <ë„ë¡œ> í™”ì¬ë°œìƒ.ì—ì„œ ë°œìƒí•˜ì˜€ìœ¼ë‹ˆ ë‚¨ ìš°íšŒí•˜ì—¬ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] 5.23. <ì‹œê°„> <ì§€ì—­> <ê±´ë¬¼> <ê±´ë¬¼> ì§€í•˜ì£¼ì°¨ì¥ í™”ì¬ë¡œ ì¸í•´ ì°¨ëŸ‰í†µì œ ì¤‘ì„ì„ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„>Kí†µì‹ êµ¬ í™”ì¬ë°œìƒ, ì¸ê·¼ ì£¼ë¯¼ì€ì— ê³µì‚¬ì¥<í•™êµ> ê³  ì•ˆì „ì— ë°”ëë‹ˆë‹¤\n",
      "ğŸ”¸ [True] 5.23. <ì‹œê°„> <ì§€ì—­> <ê±´ë¬¼> <ê±´ë¬¼> ì§€í•˜ì£¼ì°¨ì¥ í™”ì¬ë¡œ ì¸í•´ ì°¨ëŸ‰í†µì œ ì¤‘ì„ì„ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ê±´ë¬¼> í™”ì¬ ë°œìƒ ì¸ê·¼ ì£¼ë¯¼ì€ ì£¼ë¯¼ì€ ê³³ìœ¼ë¡œ ê³³ìœ¼ë¡œ ëŒ€í”¼í•˜ì—¬ ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„> ë°˜ì›”ê³µë‹¨ ë‚´ ëŒ€ë¦¼ë¹„ì•¤ì½” í™”ì¬ë¡œ ì¸í•´ ì°¨ëŸ‰í†µí–‰ ë¶ˆê°€í•˜ì˜¤ë‹ˆ ìš°íšŒí•˜ì—¬ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„>ê²½ <ì§€ì—­> <ê±´ë¬¼> í™”ì¬ë¡œ í™”ì¬ë°œìƒ,  ì£¼ë¯¼ì€ ì•ˆì „ì— ìœ ì˜ ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„> ë°˜ì›”ê³µë‹¨ ë‚´ ëŒ€ë¦¼ë¹„ì•¤ì½” í™”ì¬ë¡œ ì¸í•´ ì°¨ëŸ‰í†µí–‰ ë¶ˆê°€í•˜ì˜¤ë‹ˆ ìš°íšŒí•˜ì—¬ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "[Epoch 8] Val Loss: 3.7164 | BLEU: 0.2590 | METEOR: 0.4371 | ROUGE: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 9] Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2487/2487 [02:13<00:00, 18.63it/s, train_loss=0.247]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŸ¦ [Train Samples]\n",
      "ğŸ”¹ [Pred] <ì‹œê°„>ê²½ <ì§€ì—­> <ì£¼ì†Œ> í™”ì¬ ë°œìƒ, ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „ì‚¬ê³  ë°œìƒì— ìœ ì˜ ë°”ëë‹ˆë‹¤\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„>ê²½ <ì§€ì—­> <ì£¼ì†Œ> í™”ì¬ ë°œìƒ, ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „ì‚¬ê³  ë°œìƒì— ìœ ì˜ ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„>ê²½ <ì§€ì—­> <ì£¼ì†Œ> ì‚¼ì„±í™”ì¬ ì„¸ì¢…ì§€ì  í™”ì¬ ë°œìƒ, ì£¼ë¯¼ì€ ì£¼ë¯¼ì€ ì•ˆì „ì— ì£¼ì˜ë°”ëŒ.\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„>ê²½ <ì§€ì—­> <ì£¼ì†Œ> ì‚¼ì„±í™”ì¬ ì„¸ì¢…ì§€ì  í™”ì¬ ë°œìƒ, ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „ì— ìœ ì˜í•˜ì„¸ìš”.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„>ê²½ ë°œìƒí•œ<ì§€ì—­><ì§€ì—­> ì¸ì²œêµë§¤ë§¤ë‹¨ì§€ ìƒê°€í™”ì¬ì—ì„œ ì¸ê·¼ì£¼ë¯¼ì€ ì•ˆì „ì— ìœ ì˜\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„>ê²½ ë°œìƒí•œ <ì§€ì—­> ì¸ì²œêµë§¤ë§¤ë‹¨ì§€ ìƒê°€í™”ì¬ì—ì„œ ì¸ê·¼ì£¼ë¯¼ì€ ì•ˆì „ì— ìœ ì˜ ë°”ëë‹ˆë‹¤\n",
      "\n",
      "ğŸ”¹ [Pred] ì›”04ì¼ <ì‹œê°„> <ì§€ì—­> <ì£¼ì†Œ> ê´‘ì§„ì¼€ì´ë¸” ê³µì¥ í™”ì¬ ë°œìƒ, ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „ì‚¬ê³ ì— ìœ ì˜ í•˜ì„¸ìš”\n",
      "ğŸ”¸ [True] 4ì›”04ì¼ <ì‹œê°„> <ì§€ì—­> <ì£¼ì†Œ> ê´‘ì§„ì¼€ì´ë¸” ê³µì¥ í™”ì¬ ë°œìƒ, ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „ì‚¬ê³ ì— ìœ ì˜ í•˜ì„¸ìš”\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì§€ì—­> <ì‚°> ì¸ê·¼ì—ì„œ<ì£¼ì†Œ> í™”ì¬ ì¸ê·¼ì—ì„œ ë°œìƒí•œ ìˆ˜ìŠµìœ¼ë¡œ <ë„ë¡œ>ê°€ í˜¼ì¡í•˜ì˜¤ë‹ˆ ìš°íšŒë°”ëë‹ˆë‹¤\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„> <ì§€ì—­> <ì‚°><ì£¼ì†Œ> <ì£¼ì†Œ> ì¸ê·¼ì—ì„œ ë°œìƒí•œ í™”ì¬ ìˆ˜ìŠµìœ¼ë¡œ <ë„ë¡œ>ê°€ í˜¼ì¡í•˜ì˜¤ë‹ˆ ìš°íšŒë°”ëë‹ˆë‹¤.\n",
      "\n",
      "\n",
      "ğŸŸ© [Validation Samples]\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> ì²­ 8ë²ˆì§€ ë°œìƒ ì°¨ëŸ‰ í™”ì¬ ë°œìƒ ì¸ê·¼ ì¸ê·¼ ì•ˆì „ì‚¬ê³ ì— ë‹«ì•„ì£¼ì‹œê³  ìœ ì˜ ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] 5.23. <ì‹œê°„> <ì§€ì—­> <ê±´ë¬¼> <ê±´ë¬¼> ì§€í•˜ì£¼ì°¨ì¥ í™”ì¬ë¡œ ì¸í•´ ì°¨ëŸ‰í†µì œ ì¤‘ì„ì„ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì§€ì—­> <ë„ë¡œ> í™”ì¬ë¡œ ë°œìƒ. ì¸ê·¼ ì£¼ë¯¼ì€ ì‹ ì†íˆ ì´ë™í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] 5.23. <ì‹œê°„> <ì§€ì—­> <ê±´ë¬¼> <ê±´ë¬¼> ì§€í•˜ì£¼ì°¨ì¥ í™”ì¬ë¡œ ì¸í•´ ì°¨ëŸ‰í†µì œ ì¤‘ì„ì„ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> ë°˜ì—¬ë†ì‚°ë¬¼ì‹œì¥ ëŒ€í˜•í™”ì¬ ë°œìƒ ì¸ê·¼,<ê±´ë¬¼> í™”ì¬ë°œìƒ ìœ ì˜ ë°”ëë‹ˆë‹¤\n",
      "ğŸ”¸ [True] 5.23. <ì‹œê°„> <ì§€ì—­> <ê±´ë¬¼> <ê±´ë¬¼> ì§€í•˜ì£¼ì°¨ì¥ í™”ì¬ë¡œ ì¸í•´ ì°¨ëŸ‰í†µì œ ì¤‘ì„ì„ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì£¼ì†Œ> ëŒ€í˜•í™”ì¬ ë°œìƒ, ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „í•œ ê³³ìœ¼ë¡œ ëŒ€í”¼í•˜ì—¬ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„> ë°˜ì›”ê³µë‹¨ ë‚´ ëŒ€ë¦¼ë¹„ì•¤ì½” í™”ì¬ë¡œ ì¸í•´ ì°¨ëŸ‰í†µí–‰ ë¶ˆê°€í•˜ì˜¤ë‹ˆ ìš°íšŒí•˜ì—¬ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„>ê²½ <ì§€ì—­> <ê±´ë¬¼> í™”ì¬ë¡œ ìœ„í—˜ì„ <ì£¼ì†Œ>, ì¸ê·¼ ìœ ì˜ì—ì„œ ë°œìƒí•˜ì˜€ìœ¼ë‹ˆ ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„> ë°˜ì›”ê³µë‹¨ ë‚´ ëŒ€ë¦¼ë¹„ì•¤ì½” í™”ì¬ë¡œ ì¸í•´ ì°¨ëŸ‰í†µí–‰ ë¶ˆê°€í•˜ì˜¤ë‹ˆ ìš°íšŒí•˜ì—¬ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "[Epoch 9] Val Loss: 3.5896 | BLEU: 0.2275 | METEOR: 0.4032 | ROUGE: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 10] Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2487/2487 [02:16<00:00, 18.23it/s, train_loss=0.236]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŸ¦ [Train Samples]\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì§€ì—­> <ì§€ì—­> <ì£¼ì†Œ> í™”ì¬ ë°œìƒ. ì´ ì§€ì—­ì„ ìš°íšŒí•˜ì—¬ ì£¼ì‹œê³  ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „ì‚¬ê³  ë°œìƒì— ìœ ì˜ ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„> <ì§€ì—­> <ì§€ì—­> <ì£¼ì†Œ> í™”ì¬ ë°œìƒ. ì´ ì§€ì—­ì„ ìš°íšŒí•˜ì—¬ ì£¼ì‹œê³  ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „ì‚¬ê³  ë°œìƒì— ìœ ì˜ ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì§€ì—­> <ì§€ì—­> <ê±´ë¬¼> í™”ì¬ ë°œìƒ. ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „í•œ ê³³ìœ¼ë¡œ ëŒ€í”¼í•˜ê¸° ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] 1.28 <ì‹œê°„> <ì§€ì—­> <ì§€ì—­> <ê±´ë¬¼> í™”ì¬ ë°œìƒ. ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „í•œ ê³³ìœ¼ë¡œ ëŒ€í”¼í•˜ê¸° ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì§€ì—­> <ì§€ì—­> <ì§€ì—­> <ì£¼ì†Œ> ê³µì¥ í™”ì¬ ë°œìƒ, ì¸ê·¼ ì£¼ë¯¼ì€ ëŒ€í”¼í•˜ì‹œê³ , ì°¨ëŸ‰ì€ ìš°íšŒ ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„> <ì§€ì—­> <ì§€ì—­> <ì§€ì—­> <ì£¼ì†Œ> ê³µì¥ í™”ì¬ ë°œìƒ, ì¸ê·¼ ì£¼ë¯¼ì€ ëŒ€í”¼í•˜ì‹œê³ , ì°¨ëŸ‰ì€ ìš°íšŒ ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] . ì˜¤ëŠ˜ <ì‹œê°„> <ì§€ì—­> ì„ ë°• í™”ì¬ ë°œìƒ. ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „í•œ ê³³ìœ¼ë¡œ ì´ë™í•´ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] ì•ˆì „ì•ˆë‚´. ì˜¤ëŠ˜ <ì‹œê°„> <ì§€ì—­> ì„ ë°• í™”ì¬ ë°œìƒ. ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „í•œ ê³³ìœ¼ë¡œ ì´ë™í•´ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì§€ì—­> <ì§€ì—­> <ì£¼ì†Œ> ì¸ê·¼ ìƒê°€ í™”ì¬ ë°œìƒ. ì¸ê·¼ ì£¼ë¯¼ì€ ì°½ë¬¸ì„ ë‹«ì•„ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„> <ì§€ì—­> <ì§€ì—­> <ì£¼ì†Œ> ì¸ê·¼ ìƒê°€ í™”ì¬ ë°œìƒ. ì¸ê·¼ ì£¼ë¯¼ì€ ì°½ë¬¸ì„ ë‹«ì•„ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "\n",
      "ğŸŸ© [Validation Samples]\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ë„ë¡œ> í™”ì¬ë°œìƒ ë°œìƒ, ì¸ê·¼ ì£¼ë¯¼ì€ ë°œìƒí•œ ë“±ì‚° ì•ˆì „ì— ìœ ì˜ ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] 5.23. <ì‹œê°„> <ì§€ì—­> <ê±´ë¬¼> <ê±´ë¬¼> ì§€í•˜ì£¼ì°¨ì¥ í™”ì¬ë¡œ ì¸í•´ ì°¨ëŸ‰í†µì œ ì¤‘ì„ì„ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì§€ì—­> <ê±´ë¬¼> í™”ì¬ ë°œìƒ. ì¸ê·¼ í™•ì‚°ë  ìš°ë ¤ê°€ ìˆìœ¼ë‹ˆ ìš°íšŒí•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] 5.23. <ì‹œê°„> <ì§€ì—­> <ê±´ë¬¼> <ê±´ë¬¼> ì§€í•˜ì£¼ì°¨ì¥ í™”ì¬ë¡œ ì¸í•´ ì°¨ëŸ‰í†µì œ ì¤‘ì„ì„ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì§€ì—­> ì¸ê·¼ í™”ì¬ë°œìƒ, ì¸ê·¼<ê±´ë¬¼> ì£¼ë¯¼ë“¤ì€ ì•ˆì „ì— ìœ ì˜ ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] 5.23. <ì‹œê°„> <ì§€ì—­> <ê±´ë¬¼> <ê±´ë¬¼> ì§€í•˜ì£¼ì°¨ì¥ í™”ì¬ë¡œ ì¸í•´ ì°¨ëŸ‰í†µì œ ì¤‘ì„ì„ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„>  í™”ì¬ë°œìƒ8 í™”ì¬ ì¸ê·¼ ì£¼ë¯¼ì€ í™”ì¬, ì¼ì› ìœ ì˜ë°”ëë‹ˆë‹¤ ì£¼ë¯¼ë“¤ì€ ëŒ€í”¼í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„> ë°˜ì›”ê³µë‹¨ ë‚´ ëŒ€ë¦¼ë¹„ì•¤ì½” í™”ì¬ë¡œ ì¸í•´ ì°¨ëŸ‰í†µí–‰ ë¶ˆê°€í•˜ì˜¤ë‹ˆ ìš°íšŒí•˜ì—¬ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„>ê²½ <ì§€ì—­> <ê±´ë¬¼> í™”ì¬ë¡œ ìš°íšŒë°”ëë‹ˆë‹¤, ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „ì— ìœ ì˜ ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„> ë°˜ì›”ê³µë‹¨ ë‚´ ëŒ€ë¦¼ë¹„ì•¤ì½” í™”ì¬ë¡œ ì¸í•´ ì°¨ëŸ‰í†µí–‰ ë¶ˆê°€í•˜ì˜¤ë‹ˆ ìš°íšŒí•˜ì—¬ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "[Epoch 10] Val Loss: 3.7541 | BLEU: 0.2772 | METEOR: 0.4584 | ROUGE: 0.0000\n",
      "âœ… Best model saved at epoch 10 (BLEU=0.2772)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 16] Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2487/2487 [02:15<00:00, 18.35it/s, train_loss=0.258]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŸ¦ [Train Samples]\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì§€ì—­> <ì§€ì—­> ë¬¼ë¥˜ì°½ê³  ê³µì‚¬ì¥ í™”ì¬ ë‹¤ëŸ‰ì˜ ì—°ê¸°ê°€ ë°œìƒ. ì¸ê·¼ ì£¼ë¯¼ì€ ëŒ€í”¼ ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„> <ì§€ì—­> <ì§€ì—­> ë¬¼ë¥˜ì°½ê³  ê³µì‚¬ì¥ í™”ì¬ë¡œ ë‹¤ëŸ‰ì˜ ì—°ê¸°ê°€ ë°œìƒ. ì¸ê·¼ ì£¼ë¯¼ì€ ëŒ€í”¼ ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì§€ì—­> ê´‘ì¥ë™ì—ì„œ <ê±´ë¬¼> í™”ì¬ ë°œìƒ. ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „ì— ìœ ì˜í•˜ì„¸ìš”!\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„> <ì§€ì—­> ê´‘ì¥ë™ì—ì„œ <ê±´ë¬¼> í™”ì¬ ë°œìƒ. ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „ì— ìœ ì˜í•˜ì„¸ìš”!\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì§€ì—­> ì—¼í¬ë¶€ë‘ ì„ ë°•í™”ì¬ ë°œìƒ. ì£¼ë¯¼ë“¤ê»˜ì„œëŠ” í™”ì¬ë¡œ ë°œìƒí•˜ì§€ì•Šë„ë¡ ì£¼ì˜ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„> <ì§€ì—­> ì—¼í¬ë¶€ë‘ ì„ ë°•í™”ì¬ ë°œìƒ. ì£¼ë¯¼ë“¤ê»˜ì„œëŠ” í™”ì¬ì—°ê¸°ë¡œ ì¸í•œ í”¼í•´ê°€ ë°œìƒí•˜ì§€ ì•Šë„ë¡ ì£¼ì˜ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì§€ì—­> ì„ ë°•í™”ì¬ í˜„ì¥ ìˆ˜ìŠµìœ¼ë¡œ ë‹¤ëŸ‰ì˜ ì—°ê¸°ê°€ ë°œìƒí•˜ê³ ìˆìœ¼ë‹ˆ ì¸ê·¼ ì£¼ë¯¼ì€ ëŒ€í”¼í•˜ì—¬ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] í˜„ì¬ <ì§€ì—­> ì„ ë°•í™”ì¬ í˜„ì¥ ìˆ˜ìŠµìœ¼ë¡œ ë‹¤ëŸ‰ì˜ ì—°ê¸°ê°€ ë°œìƒí•˜ê³ ìˆìœ¼ë‹ˆ ì¸ê·¼ ì£¼ë¯¼ì€ ëŒ€í”¼í•˜ì—¬ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì§€ì—­> ë´‰ê¸¸ë§ˆì„ <ì£¼ì†Œ> ì¸ê·¼ì—ì„œ í™”ì¬ ë°œìƒìœ¼ë¡œ ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „ì‚¬ê³ ì— ìœ ì˜ ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„> <ì§€ì—­> ë´‰ê¸¸ë§ˆì„ <ì£¼ì†Œ> ì¸ê·¼ì—ì„œ í™”ì¬ ë°œìƒìœ¼ë¡œ ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „ì‚¬ê³ ì— ìœ ì˜ ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "\n",
      "ğŸŸ© [Validation Samples]\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ë„ë¡œ> í™”ì¬ ë°œìƒ. ì¸ê·¼ ì£¼ë¯¼ì€ ë°œìƒí•œ ë‹«ì•„ì£¼ì‹œê³  ë“± ì•ˆì „ì— ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] 5.23. <ì‹œê°„> <ì§€ì—­> <ê±´ë¬¼> <ê±´ë¬¼> ì§€í•˜ì£¼ì°¨ì¥ í™”ì¬ë¡œ ì¸í•´ ì°¨ëŸ‰í†µì œ ì¤‘ì„ì„ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì§€ì—­> <ì§€ì—­> <ê±´ë¬¼> í™”ì¬ ë°œìƒ. ì´ ì§€ì—­ì„ ìš°íšŒí•˜ì—¬ ì£¼ì‹œê³  ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] 5.23. <ì‹œê°„> <ì§€ì—­> <ê±´ë¬¼> <ê±´ë¬¼> ì§€í•˜ì£¼ì°¨ì¥ í™”ì¬ë¡œ ì¸í•´ ì°¨ëŸ‰í†µì œ ì¤‘ì„ì„ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì§€ì—­> ì„ ë°• í™”ì¬ ë°œìƒ. ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „ì— ë°œìƒì— ìœ ì˜ ë°”ëë‹ˆë‹¤\n",
      "ğŸ”¸ [True] 5.23. <ì‹œê°„> <ì§€ì—­> <ê±´ë¬¼> <ê±´ë¬¼> ì§€í•˜ì£¼ì°¨ì¥ í™”ì¬ë¡œ ì¸í•´ ì°¨ëŸ‰í†µì œ ì¤‘ì„ì„ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ê±´ë¬¼> í™”ì¬ ë°œìƒ. ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „í•œ ê³³ìœ¼ë¡œ ëŒ€í”¼í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„> ë°˜ì›”ê³µë‹¨ ë‚´ ëŒ€ë¦¼ë¹„ì•¤ì½” í™”ì¬ë¡œ ì¸í•´ ì°¨ëŸ‰í†µí–‰ ë¶ˆê°€í•˜ì˜¤ë‹ˆ ìš°íšŒí•˜ì—¬ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„>ê²½ <ì§€ì—­> <ì‚°>ì˜ í™”ì¬ë°œìƒì— ë°œìƒ, ì£¼ë¯¼ë“¤ì€ ì°½ë¬¸ì„ ë‹«ì•„ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„> ë°˜ì›”ê³µë‹¨ ë‚´ ëŒ€ë¦¼ë¹„ì•¤ì½” í™”ì¬ë¡œ ì¸í•´ ì°¨ëŸ‰í†µí–‰ ë¶ˆê°€í•˜ì˜¤ë‹ˆ ìš°íšŒí•˜ì—¬ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "[Epoch 16] Val Loss: 3.7174 | BLEU: 0.2736 | METEOR: 0.4552 | ROUGE: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 17] Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2487/2487 [02:13<00:00, 18.63it/s, train_loss=0.226]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŸ¦ [Train Samples]\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì‚°> <ì§€ì—­> <ì£¼ì†Œ> í™”ì¬ ë°œìƒ, ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „ì— ìœ ì˜ ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„> <ì‚°> <ì§€ì—­> <ì£¼ì†Œ> í™”ì¬ ë°œìƒ, ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „ì— ìœ ì˜ ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì§€ì—­> <ê±´ë¬¼> <ê±´ë¬¼> í™”ì¬ ë°œìƒ, ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „ì— ìœ ì˜í•˜ì‹œê¸¸ ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„> <ì§€ì—­> <ê±´ë¬¼> <ê±´ë¬¼> í™”ì¬ ë°œìƒ, ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „ì— ìœ ì˜í•˜ì‹œê¸¸ ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì§€ì—­> ê³„ì–‘ë§ˆì„ ì¸ê·¼ì—ì„œ ë°œìƒí•œ í™”ì¬ ì”í™”ì •ë¦¬ë¡œ ì—°ê¸°ê°€ ë§ì´ ë‚˜ê³  ìˆìœ¼ë‹ˆ ì¸ê·¼ ì£¼ë¯¼ì€ ëŒ€í”¼ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„> <ì§€ì—­> ê³„ì–‘ë§ˆì„ ì¸ê·¼ì—ì„œ ë°œìƒí•œ í™”ì¬ ì”í™”ì •ë¦¬ë¡œ ì—°ê¸°ê°€ ë§ì´ ë‚˜ê³  ìˆìœ¼ë‹ˆ ì¸ê·¼ ì£¼ë¯¼ì€ ëŒ€í”¼ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„>ê²½ <ì§€ì—­> <ì£¼ì†Œ> <ê±´ë¬¼> í™”ì¬ ë°œìƒ, ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „ì— ìœ ì˜ ë°”ëë‹ˆë‹¤\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„>ê²½ <ì§€ì—­> <ì£¼ì†Œ> <ê±´ë¬¼> í™”ì¬ ë°œìƒ, ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „ì— ìœ ì˜ ë°”ëë‹ˆë‹¤\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> ë°˜ì›”ê³µë‹¨ ë‚´ ëŒ€ë¦¼ë¹„ì•¤ì½” í™”ì¬ë¡œ ê²€ì€ì—°ê¸° ë°œìƒ. ì¸ê·¼ ì‹œë¯¼ì€ ì•ˆì „ì‚¬ê³  ë°œìƒì— ìœ ì˜ ë°”ëë‹ˆë‹¤\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„> ë°˜ì›”ê³µë‹¨ ë‚´ ëŒ€ë¦¼ë¹„ì•¤ì½” í™”ì¬ë¡œ ê²€ì€ì—°ê¸° ë°œìƒ. ì¸ê·¼ ì‹œë¯¼ì€ ì•ˆì „ì‚¬ê³  ë°œìƒì— ìœ ì˜ ë°”ëë‹ˆë‹¤\n",
      "\n",
      "\n",
      "ğŸŸ© [Validation Samples]\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ë„ë¡œ> í™”ì¬ ë°œìƒ, ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „ì— ìœ ì˜ ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] 5.23. <ì‹œê°„> <ì§€ì—­> <ê±´ë¬¼> <ê±´ë¬¼> ì§€í•˜ì£¼ì°¨ì¥ í™”ì¬ë¡œ ì¸í•´ ì°¨ëŸ‰í†µì œ ì¤‘ì„ì„ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì§€ì—­> <ì§€ì—­> <ê±´ë¬¼> í™”ì¬ ë°œìƒ. ì´ ì£¼ë¯¼ì€ ìš°íšŒí•˜ì—¬ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] 5.23. <ì‹œê°„> <ì§€ì—­> <ê±´ë¬¼> <ê±´ë¬¼> ì§€í•˜ì£¼ì°¨ì¥ í™”ì¬ë¡œ ì¸í•´ ì°¨ëŸ‰í†µì œ ì¤‘ì„ì„ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì§€ì—­> ì¸ê·¼ í™”ì¬ ë°œìƒ. ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „ì— ìœ ì˜ ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] 5.23. <ì‹œê°„> <ì§€ì—­> <ê±´ë¬¼> <ê±´ë¬¼> ì§€í•˜ì£¼ì°¨ì¥ í™”ì¬ë¡œ ì¸í•´ ì°¨ëŸ‰í†µì œ ì¤‘ì„ì„ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ê±´ë¬¼> í™”ì¬ ë°œìƒìœ¼ë¡œ ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „í•œ ê³³ìœ¼ë¡œ ëŒ€í”¼í•˜ì—¬ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„> ë°˜ì›”ê³µë‹¨ ë‚´ ëŒ€ë¦¼ë¹„ì•¤ì½” í™”ì¬ë¡œ ì¸í•´ ì°¨ëŸ‰í†µí–‰ ë¶ˆê°€í•˜ì˜¤ë‹ˆ ìš°íšŒí•˜ì—¬ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„>ê²½ <ì§€ì—­> <ì§€ì—­> <ë„ë¡œ> í™”ì¬ ë°œìƒ ì¸ê·¼ ì£¼ë¯¼ì€ ìš°íšŒí•˜ì—¬ ë¡¯ë°ë¦¬ì•„ ìœ ì˜ ë°”ëë‹ˆë‹¤\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„> ë°˜ì›”ê³µë‹¨ ë‚´ ëŒ€ë¦¼ë¹„ì•¤ì½” í™”ì¬ë¡œ ì¸í•´ ì°¨ëŸ‰í†µí–‰ ë¶ˆê°€í•˜ì˜¤ë‹ˆ ìš°íšŒí•˜ì—¬ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "[Epoch 17] Val Loss: 3.7682 | BLEU: 0.2936 | METEOR: 0.4689 | ROUGE: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 18] Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2487/2487 [02:15<00:00, 18.32it/s, train_loss=0.264]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŸ¦ [Train Samples]\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì§€ì—­> <ì£¼ì†Œ> <ê±´ë¬¼> í™”ì¬ ë°œìƒ. ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „ì‚¬ê³ ì— ìœ ì˜ ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„> <ì§€ì—­> <ì£¼ì†Œ> <ê±´ë¬¼> í™”ì¬ ë°œìƒ. ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „ì‚¬ê³ ì— ìœ ì˜ ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì£¼ì†Œ>ì—­ 1ë²ˆì¶œêµ¬ ì¸ê·¼ ì „ì£¼íì°¨ì¥ì—ì„œ í™”ì¬ ë°œìƒìœ¼ë¡œ ì£¼ë³€ êµí†µì´ í˜¼ì¡í•˜ì˜¤ë‹ˆ í‡´ê·¼ê¸¸ ì•ˆì „ì—  â‡ íˆ ìœ ì˜ ë°”ëë‹ˆë‹¤\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„> <ì£¼ì†Œ>ì—­ 1ë²ˆì¶œêµ¬ ì¸ê·¼ ì „ì£¼íì°¨ì¥ì—ì„œ í™”ì¬ ë°œìƒìœ¼ë¡œ ì£¼ë³€ êµí†µì´ í˜¼ì¡í•˜ì˜¤ë‹ˆ í‡´ê·¼ê¸¸ ì•ˆì „ì—  â‡ íˆ ìœ ì˜ ë°”ëë‹ˆë‹¤\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì§€ì—­> <ì§€ì—­> <ê±´ë¬¼> ìƒê°€ í™”ì¬ ë°œìƒ. ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „ì‚¬ê³  ë°œìƒì— ìœ ì˜ ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„> <ì§€ì—­> <ì§€ì—­> <ê±´ë¬¼> ìƒê°€ í™”ì¬ ë°œìƒ. ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „ì‚¬ê³  ë°œìƒì— ìœ ì˜ ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì§€ì—­> <ì§€ì—­> ëª¨í† ê³ ê°œ <ì£¼ì†Œ> ì¬í™œìš©ê³µì¥ í™”ì¬ ë°œìƒìœ¼ë¡œ ì¸ê·¼ ì£¼ë¯¼ë“¤ì€ ì•ˆì „ì‚¬ê³  ë°œìƒì— ìœ ì˜ ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„> <ì§€ì—­> <ì§€ì—­> ëª¨í† ê³ ê°œ <ì£¼ì†Œ> ì¬í™œìš©ê³µì¥ í™”ì¬ ë°œìƒìœ¼ë¡œ ì¸ê·¼ ì£¼ë¯¼ë“¤ì€ ì•ˆì „ì‚¬ê³  ë°œìƒì— ìœ ì˜ ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì§€ì—­> ë´‰ê°•ì €ìˆ˜ì§€ <ë„ë¡œ> í™”ì¬ ë°œìƒ. ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „ì‚¬ê³ ì— ìœ ì˜ ë°”ëë‹ˆë‹¤\n",
      "ğŸ”¸ [True] <ì‹œê°„> <ì§€ì—­> ë´‰ê°•ì €ìˆ˜ì§€ <ë„ë¡œ> í™”ì¬ ë°œìƒ. ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „ì‚¬ê³ ì— ìœ ì˜ ë°”ëë‹ˆë‹¤\n",
      "\n",
      "\n",
      "ğŸŸ© [Validation Samples]\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì—­> í™”ì¬ ë°œìƒ, ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „ì— ë°œìƒì— ìœ ì˜ ë°”ëë‹ˆë‹¤\n",
      "ğŸ”¸ [True] 5.23. <ì‹œê°„> <ì§€ì—­> <ê±´ë¬¼> <ê±´ë¬¼> ì§€í•˜ì£¼ì°¨ì¥ í™”ì¬ë¡œ ì¸í•´ ì°¨ëŸ‰í†µì œ ì¤‘ì„ì„ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì§€ì—­> <ì§€ì—­> <ê±´ë¬¼> í™”ì¬ ë°œìƒ. ì´<ë„ë¡œ> ì´ìš©í•˜ì—¬ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] 5.23. <ì‹œê°„> <ì§€ì—­> <ê±´ë¬¼> <ê±´ë¬¼> ì§€í•˜ì£¼ì°¨ì¥ í™”ì¬ë¡œ ì¸í•´ ì°¨ëŸ‰í†µì œ ì¤‘ì„ì„ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> ë°œìƒí•œ<ì—­>Kí†µì‹ êµ¬ í™”ì¬ ì”í™”ì •ë¦¬ë¡œ, ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „ì— ìœ ì˜ ë°”ëë‹ˆë‹¤\n",
      "ğŸ”¸ [True] 5.23. <ì‹œê°„> <ì§€ì—­> <ê±´ë¬¼> <ê±´ë¬¼> ì§€í•˜ì£¼ì°¨ì¥ í™”ì¬ë¡œ ì¸í•´ ì°¨ëŸ‰í†µì œ ì¤‘ì„ì„ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì£¼ì†Œ> í™”ì¬ ë°œìƒ, ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „í•œ ê³³ìœ¼ë¡œ ëŒ€í”¼í•˜ì—¬ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„> ë°˜ì›”ê³µë‹¨ ë‚´ ëŒ€ë¦¼ë¹„ì•¤ì½” í™”ì¬ë¡œ ì¸í•´ ì°¨ëŸ‰í†µí–‰ ë¶ˆê°€í•˜ì˜¤ë‹ˆ ìš°íšŒí•˜ì—¬ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„>ê²½,<ì§€ì—­> <ê±´ë¬¼> <í•™êµ>ì—ì„œ  ê³µì‚¬ì¥ ì•ˆì „ìœ ì˜ë§ˆì„ ìœ ì˜ ë°”ëë‹ˆë‹¤\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„> ë°˜ì›”ê³µë‹¨ ë‚´ ëŒ€ë¦¼ë¹„ì•¤ì½” í™”ì¬ë¡œ ì¸í•´ ì°¨ëŸ‰í†µí–‰ ë¶ˆê°€í•˜ì˜¤ë‹ˆ ìš°íšŒí•˜ì—¬ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "[Epoch 18] Val Loss: 3.7349 | BLEU: 0.2759 | METEOR: 0.4557 | ROUGE: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 19] Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2487/2487 [02:15<00:00, 18.35it/s, train_loss=0.25] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŸ¦ [Train Samples]\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> êµ¬ í™”ì¥í„° í™”ì¬ë¡œ ì¸í•´ ë²”ì–´ë¡œ ì¼ëŒ€ êµí†µì´ ì •ì²´ë˜ê³  ìˆìœ¼ë‹ˆ ìš°íšŒí•˜ì—¬ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„> êµ¬ í™”ì¥í„° í™”ì¬ë¡œ ì¸í•´ ë²”ì–´ë¡œ ì¼ëŒ€ êµí†µì´ ì •ì²´ë˜ê³  ìˆìœ¼ë‹ˆ ìš°íšŒí•˜ì—¬ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> ë°œìƒí•œ <ì§€ì—­> ê³µì¥í™”ì¬ ì‚¬ê³  ìˆ˜ìŠµìœ¼ë¡œ ìˆ˜ìŠµìœ¼ë¡œ<ë„ë¡œ>í˜¼ì¡í•˜ ì•ˆì „ì‚¬ê³ ì— ë°”ëë‹ˆë‹¤ ìœ ì˜\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„> ë°œìƒí•œ <ì§€ì—­> <ì§€ì—­> ê³µì¥í™”ì¬ ì‚¬ê³  ìˆ˜ìŠµìœ¼ë¡œ <ë„ë¡œ>í˜¼ì¡í•˜ë‹ˆ ì•ˆì „ì‚¬ê³ ì— ìœ ì˜ ë°”ëë‹ˆë‹¤\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„>í˜„ì¬ <ì—­> ì¸ê·¼ <ê±´ë¬¼> í™”ì¬ ë°œìƒ, ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „í•œ ê³³ìœ¼ë¡œ ëŒ€í”¼í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] <ì‹œê°„>í˜„ì¬ <ì—­> ì¸ê·¼ <ê±´ë¬¼> í™”ì¬ ë°œìƒ, ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „í•œ ê³³ìœ¼ë¡œ ëŒ€í”¼í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> ë™ê´‘êµ ê³µì‚¬ì¥ ê³µì‚¬ì¥ í™”ì¬ë¡œ ë°œìƒ. ì¸ê·¼ ì£¼ë¯¼ë“¤ì€ ì•ˆì „ì— ìœ ì˜ ë°”ëë‹ˆë‹¤\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜<ì‹œê°„> ë™ê´‘êµ ì¸ê·¼ ê³µì‚¬ì¥ í™”ì¬ë¡œ ë‹¤ëŸ‰ì˜ ì—°ê¸°ê°€ ë°œìƒ. ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „ì— ìœ ì˜ ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì§€ì—­> ëŒ€í™”ê³µë‹¨ë‚´ ëŒ€í˜•í™”ì¬ ë°œìƒ, ì¶œê·¼ê¸¸ êµí†µí˜¼ì¡ì´ ì˜ˆìƒë˜ì˜¤ë‹ˆ ëŒ€ì¤‘êµí†µì„ ì´ìš©í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] í˜„ì¬ <ì§€ì—­> ëŒ€í™”ê³µë‹¨ë‚´ ëŒ€í˜•í™”ì¬ ë°œìƒ, ì¶œê·¼ê¸¸ êµí†µí˜¼ì¡ì´ ì˜ˆìƒë˜ì˜¤ë‹ˆ ëŒ€ì¤‘êµí†µì„ ì´ìš©í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "\n",
      "ğŸŸ© [Validation Samples]\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì—­>ì— í™”ì¬, ì¸ê·¼ ì£¼ë¯¼ì€ ì°½ë¬¸ì„ ë‹«ì•„ì£¼ì‹œê³  ì•ˆì „ì— ìœ ì˜ ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] 5.23. <ì‹œê°„> <ì§€ì—­> <ê±´ë¬¼> <ê±´ë¬¼> ì§€í•˜ì£¼ì°¨ì¥ í™”ì¬ë¡œ ì¸í•´ ì°¨ëŸ‰í†µì œ ì¤‘ì„ì„ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì§€ì—­> <ì§€ì—­> í™”ì¬ ë°œìƒ. ì´ ì§€ì—­ì„ ìš°íšŒí•˜ì—¬ ì£¼ì‹œê³  ë¡¯ë°ë¦¬ì•„ ì£¼ë¯¼ì€ ìœ ì˜ ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] 5.23. <ì‹œê°„> <ì§€ì—­> <ê±´ë¬¼> <ê±´ë¬¼> ì§€í•˜ì£¼ì°¨ì¥ í™”ì¬ë¡œ ì¸í•´ ì°¨ëŸ‰í†µì œ ì¤‘ì„ì„ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì§€ì—­>Kí†µì‹ êµ¬ì— ë°œìƒí•˜ì˜€ìœ¼ë‹ˆ, ì£¼ë¯¼ë“¤ê»˜ì„œëŠ” ì°½ë¬¸ì„ ì•ˆì „ì— ë°”ëë‹ˆë‹¤..\n",
      "ğŸ”¸ [True] 5.23. <ì‹œê°„> <ì§€ì—­> <ê±´ë¬¼> <ê±´ë¬¼> ì§€í•˜ì£¼ì°¨ì¥ í™”ì¬ë¡œ ì¸í•´ ì°¨ëŸ‰í†µì œ ì¤‘ì„ì„ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì£¼ì†Œ> í™”ì¬ ë°œìƒìœ¼ë¡œ ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „í•œ ê³³ìœ¼ë¡œ ëŒ€í”¼í•˜ì—¬ í™”ì¬ê°€ ëŒ€í”¼í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„> ë°˜ì›”ê³µë‹¨ ë‚´ ëŒ€ë¦¼ë¹„ì•¤ì½” í™”ì¬ë¡œ ì¸í•´ ì°¨ëŸ‰í†µí–‰ ë¶ˆê°€í•˜ì˜¤ë‹ˆ ìš°íšŒí•˜ì—¬ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„>ê²½ <ì§€ì—­> <ì‚°>ì—ì„œ ë°œìƒ, ì¸ê·¼ ì£¼ë¯¼ë“¤ì€ ì°½ë¬¸ì„ ë‹«ì•„ì£¼ì‹œê³  ìš°íšŒë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„> ë°˜ì›”ê³µë‹¨ ë‚´ ëŒ€ë¦¼ë¹„ì•¤ì½” í™”ì¬ë¡œ ì¸í•´ ì°¨ëŸ‰í†µí–‰ ë¶ˆê°€í•˜ì˜¤ë‹ˆ ìš°íšŒí•˜ì—¬ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "[Epoch 19] Val Loss: 3.6319 | BLEU: 0.2500 | METEOR: 0.4239 | ROUGE: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 20] Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2487/2487 [02:14<00:00, 18.49it/s, train_loss=0.244]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŸ¦ [Train Samples]\n",
      "ğŸ”¹ [Pred] <ì§€ì—­> 658ë²ˆì§€ ì¸ê·¼ <ê±´ë¬¼> í™”ì¬ê°€ ë°œìƒí•˜ì˜€ìœ¼ë‹ˆ ë‚¨ì‚°ë¡œ ì¼ëŒ€ ì°¨ëŸ‰í†µí–‰ì„ ìì œí•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] í˜„ì¬ <ì§€ì—­> 658ë²ˆì§€ ì¸ê·¼ <ê±´ë¬¼> í™”ì¬ê°€ ë°œìƒí•˜ì˜€ìœ¼ë‹ˆ ë‚¨ì‚°ë¡œ ì¼ëŒ€ ì°¨ëŸ‰í†µí–‰ì„ ìì œí•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì§€ì—­> <ì£¼ì†Œ> í™”ì¬ ë°œìƒ. ì¸ê·¼ ì£¼ë¯¼ì€ ëŒ€í”¼ ë° ì°¨ëŸ‰ìš´í–‰ì„ ìì œí•˜ê¸° ë°”ëë‹ˆë‹¤\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„> <ì§€ì—­> <ì£¼ì†Œ> í™”ì¬ ë°œìƒ. ì¸ê·¼ ì£¼ë¯¼ì€ ëŒ€í”¼ ë° ì°¨ëŸ‰ìš´í–‰ì„ ìì œí•˜ê¸° ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] .24 <ì‹œê°„> <ì§€ì—­> <ì§€ì—­> 56ë²ˆê¸¸ í™”ì¬ ë°œìƒ. ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „í•œ ê³³ìœ¼ë¡œ ëŒ€í”¼í•˜ì—¬ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] 4.24 <ì‹œê°„> <ì§€ì—­> <ì§€ì—­> 56ë²ˆê¸¸ í™”ì¬ ë°œìƒ. ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „í•œ ê³³ìœ¼ë¡œ ëŒ€í”¼í•˜ì—¬ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì§€ì—­> <ë„ë¡œ> ì–‘êµ¬ë¦¬êµ¬ê°„ í™”ì¬ ë°œìƒ, ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „í•œ ê³³ìœ¼ë¡œ ëŒ€í”¼ ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„> <ì§€ì—­> <ë„ë¡œ> ì–‘êµ¬ë¦¬êµ¬ê°„ í™”ì¬ ë°œìƒ, ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „í•œ ê³³ìœ¼ë¡œ ëŒ€í”¼ ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] .29 <ì‹œê°„> ë¶€ë¡œ <ì§€ì—­> <ì£¼ì†Œ> í™”ì¬ ë°œìƒ, ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „í•œ ê³³ìœ¼ë¡œ ëŒ€í”¼ ë°”ëŒ\n",
      "ğŸ”¸ [True] 7.29 <ì‹œê°„> ë¶€ë¡œ <ì§€ì—­> <ì£¼ì†Œ> í™”ì¬ ë°œìƒ, ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „í•œ ê³³ìœ¼ë¡œ ëŒ€í”¼ ë°”ëŒ\n",
      "\n",
      "\n",
      "ğŸŸ© [Validation Samples]\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> ë°œìƒí•œ<ì—­>ì— í™”ì¬ ë°œìƒ ë°œìƒ ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „ì— ìœ ì˜ ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] 5.23. <ì‹œê°„> <ì§€ì—­> <ê±´ë¬¼> <ê±´ë¬¼> ì§€í•˜ì£¼ì°¨ì¥ í™”ì¬ë¡œ ì¸í•´ ì°¨ëŸ‰í†µì œ ì¤‘ì„ì„ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì§€ì—­> <ì£¼ì†Œ> í™”ì¬ ë°œìƒ. ì¸ê·¼ ì£¼ë¯¼ì€<ì—­> ì§€ì—­ì„ ìš°íšŒí•˜ì—¬ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] 5.23. <ì‹œê°„> <ì§€ì—­> <ê±´ë¬¼> <ê±´ë¬¼> ì§€í•˜ì£¼ì°¨ì¥ í™”ì¬ë¡œ ì¸í•´ ì°¨ëŸ‰í†µì œ ì¤‘ì„ì„ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì—­>ì— í™”ì¬ê°€ ë°œìƒí•˜ì˜€ìœ¼ë‹ˆ, ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „ì— ìœ ì˜ ë°”ëë‹ˆë‹¤\n",
      "ğŸ”¸ [True] 5.23. <ì‹œê°„> <ì§€ì—­> <ê±´ë¬¼> <ê±´ë¬¼> ì§€í•˜ì£¼ì°¨ì¥ í™”ì¬ë¡œ ì¸í•´ ì°¨ëŸ‰í†µì œ ì¤‘ì„ì„ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì£¼ì†Œ> <ê±´ë¬¼> í™”ì¬ ë°œìƒ, ì¸ê·¼ ì£¼ë¯¼ì€ ì•ˆì „í•œ ê³³ìœ¼ë¡œ ëŒ€í”¼í•˜ì—¬ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„> ë°˜ì›”ê³µë‹¨ ë‚´ ëŒ€ë¦¼ë¹„ì•¤ì½” í™”ì¬ë¡œ ì¸í•´ ì°¨ëŸ‰í†µí–‰ ë¶ˆê°€í•˜ì˜¤ë‹ˆ ìš°íšŒí•˜ì—¬ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”¹ [Pred] <ì‹œê°„> <ì§€ì—­> <ê±´ë¬¼> <ê±´ë¬¼> í™”ì¬ ë°œìƒ, ì¸ê·¼ ì£¼ë¯¼ë“¤ì€ ì•ˆì „ì— ìœ ì˜ ë°”ëë‹ˆë‹¤.\n",
      "ğŸ”¸ [True] ì˜¤ëŠ˜ <ì‹œê°„> ë°˜ì›”ê³µë‹¨ ë‚´ ëŒ€ë¦¼ë¹„ì•¤ì½” í™”ì¬ë¡œ ì¸í•´ ì°¨ëŸ‰í†µí–‰ ë¶ˆê°€í•˜ì˜¤ë‹ˆ ìš°íšŒí•˜ì—¬ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "[Epoch 20] Val Loss: 3.8131 | BLEU: 0.2902 | METEOR: 0.4685 | ROUGE: 0.0016\n",
      "ğŸ›‘ Early stopping triggered. Best BLEU: 0.3073\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if device.type == \"cuda\":\n",
    "    print(\"âœ… Using device:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"âš ï¸ Using CPU\")\n",
    "\n",
    "PAD_ID = 3  # âœ… ë°˜ë“œì‹œ vocabê³¼ ì¼ì¹˜í•´ì•¼ í•¨\n",
    "\n",
    "train_with_early_stopping(\n",
    "    model=model.to(device),\n",
    "    train_loader=train_loader,\n",
    "    val_loader=get_validation_loader(\"/teamspace/studios/this_studio/training/val/processed\"),\n",
    "    tokenizer=spm_tokenizer,\n",
    "    optimizer=torch.optim.Adam(model.parameters(), lr=1e-3),\n",
    "    criterion = LabelSmoothingLoss(label_smoothing=0.1, tgt_vocab_size=spm_tokenizer.vocab_size(), ignore_index=PAD_ID),\n",
    "    # criterion = nn.CrossEntropyLoss(ignore_index=PAD_ID),\n",
    "    device=device,\n",
    "    num_epochs=30,\n",
    "    teacher_forcing_ratio=0.5,\n",
    "    clip=1.0,\n",
    "    save_path=\"best_model.pt\",\n",
    "    early_stopping_patience=5,\n",
    "    checkpoint_dir=\"checkpoints\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4af0908b-adba-406f-b58a-5468a3c47b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['â–ì£¼ì‹œê¸°', 'â–ë°”ëë‹ˆë‹¤']\n",
      "['â–ì–‘í•´', 'â–ë°”ëë‹ˆë‹¤']\n",
      "['â–í™”ì¬', 'â–ë°œìƒìœ¼ë¡œ', 'â–ì¸í•´']\n"
     ]
    }
   ],
   "source": [
    "# Tokenization ì˜ˆ\n",
    "\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load(\"training/train/processed/spm.model\")\n",
    "\n",
    "print(sp.encode(\"ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤\", out_type=str))\n",
    "print(sp.encode(\"ì–‘í•´ ë°”ëë‹ˆë‹¤\", out_type=str))\n",
    "print(sp.encode(\"í™”ì¬ ë°œìƒìœ¼ë¡œ ì¸í•´\", out_type=str))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "452f5d51-5008-49a2-8541-d7db5c0de1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "def evaluate_validation_set(model, val_loader, tokenizer, device, eos_id=2, pad_id=3):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_refs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_val, y_val in tqdm(val_loader, desc=\"Evaluating\"):\n",
    "            X_val, y_val = X_val.to(device), y_val.to(device)\n",
    "\n",
    "            # ğŸ”¹ ë””ì½”ë”©ëœ ì˜ˆì¸¡ (sampling ê¸°ë°˜)\n",
    "            preds = [decode_sequence(model, x, tokenizer, device, eos_id=eos_id) for x in X_val]\n",
    "\n",
    "            # ğŸ”¹ ì •ë‹µ ì‹œí€€ìŠ¤ë¥¼ ë””ì½”ë”© (token â†’ string)\n",
    "            refs = decode_tokens(tokenizer, y_val.tolist(), eos_id=eos_id, pad_id=pad_id)\n",
    "\n",
    "            all_preds.extend(preds)\n",
    "            all_refs.extend(refs)\n",
    "\n",
    "    # ğŸ”¹ ê²°ê³¼ ì •ë¦¬\n",
    "    return pd.DataFrame({\n",
    "        \"prediction\": all_preds,\n",
    "        \"reference\": all_refs\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7a3272c7-b6f5-4151-8099-3e000c524108",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'evaluate_validation_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m val_loader \u001b[38;5;241m=\u001b[39m get_validation_loader(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/teamspace/studios/this_studio/training/val/processed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# 3. í‰ê°€ ë° ë””ì½”ë”©\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m df_result \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_validation_set\u001b[49m(model, val_loader, spm_tokenizer, device)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# 5. ì €ì¥ (ì„ íƒ)\u001b[39;00m\n\u001b[1;32m     16\u001b[0m df_result\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_predictions.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8-sig\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'evaluate_validation_set' is not defined"
     ]
    }
   ],
   "source": [
    "# 1. ëª¨ë¸ ë¡œë“œ \n",
    "model = Seq2Seq(encoder, decoder, device).to(device)\n",
    "\n",
    "checkpoint = torch.load(\"checkpoints/best_checkpoint.pt\", map_location=device, weights_only=False)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# 2. Validation loader ì¤€ë¹„ (ì´ë¯¸ í–ˆë‹¤ë©´ ìƒëµ)\n",
    "val_loader = get_validation_loader(\"/teamspace/studios/this_studio/training/val/processed\")\n",
    "\n",
    "# 3. í‰ê°€ ë° ë””ì½”ë”©\n",
    "df_result = evaluate_validation_set(model, val_loader, spm_tokenizer, device)\n",
    "\n",
    "# 5. ì €ì¥ (ì„ íƒ)\n",
    "df_result.to_csv(\"val_predictions.csv\", index=False, encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb040936-58ad-4687-99ec-b5e652a92441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_checkpoint.pt     checkpoint_epoch16.pt  checkpoint_epoch23.pt\n",
      "checkpoint_epoch1.pt   checkpoint_epoch17.pt  checkpoint_epoch3.pt\n",
      "checkpoint_epoch10.pt  checkpoint_epoch18.pt  checkpoint_epoch4.pt\n",
      "checkpoint_epoch11.pt  checkpoint_epoch19.pt  checkpoint_epoch5.pt\n",
      "checkpoint_epoch12.pt  checkpoint_epoch2.pt   checkpoint_epoch6.pt\n",
      "checkpoint_epoch13.pt  checkpoint_epoch20.pt  checkpoint_epoch7.pt\n",
      "checkpoint_epoch14.pt  checkpoint_epoch21.pt  checkpoint_epoch8.pt\n",
      "checkpoint_epoch15.pt  checkpoint_epoch22.pt  checkpoint_epoch9.pt\n"
     ]
    }
   ],
   "source": [
    "!ls checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1dfa7577-6e34-4d28-9be4-a44cb35f00b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… checkpoints í´ë” ì•ˆ ëª¨ë“  íŒŒì¼ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# Checkpoint ë¹„ì›Œì£¼ê¸°\n",
    "\n",
    "import glob\n",
    "checkpoint_dir = \"checkpoints\"\n",
    "\n",
    "# í•´ë‹¹ í´ë” ì•ˆì˜ ëª¨ë“  íŒŒì¼ ì‚­ì œ\n",
    "files = glob.glob(os.path.join(checkpoint_dir, \"*\"))\n",
    "for f in files:\n",
    "    os.remove(f)\n",
    "\n",
    "print(f\"âœ… {checkpoint_dir} í´ë” ì•ˆ ëª¨ë“  íŒŒì¼ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9cf692c5-015b-457f-9585-e2f821a3346d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "def restore_slots(masked_text: str, slot_values: dict) -> str:\n",
    "    restored = masked_text\n",
    "    for slot, value in slot_values.items():\n",
    "        restored = restored.replace(slot, value)\n",
    "    return restored\n",
    "\n",
    "def restore_pred_and_ref_with_file_ids(pred_csv_path: str, json_dir: str, file_id_npy_path: str):\n",
    "    # 1. Load prediction DataFrame\n",
    "    df = pd.read_csv(pred_csv_path)\n",
    "\n",
    "    # 2. Load file IDs from .npy\n",
    "    file_ids = np.load(file_id_npy_path)\n",
    "\n",
    "    # 3. Iterate and restore both prediction and reference\n",
    "    restored_preds = []\n",
    "    restored_refs = []\n",
    "\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        file_id = file_ids[idx]\n",
    "        json_path = Path(json_dir) / f\"{file_id}.json\"\n",
    "\n",
    "        if json_path.exists():\n",
    "            with open(json_path, encoding=\"utf-8\") as f:\n",
    "                data = json.load(f)\n",
    "            slot_values = data.get(\"slot_values\", {})\n",
    "        else:\n",
    "            slot_values = {}\n",
    "\n",
    "        pred_restored = restore_slots(row[\"prediction\"], slot_values)\n",
    "        ref_restored = restore_slots(row[\"reference\"], slot_values)\n",
    "\n",
    "        restored_preds.append(pred_restored)\n",
    "        restored_refs.append(ref_restored)\n",
    "\n",
    "    # 4. Add new columns to DataFrame\n",
    "    df[\"restored_prediction\"] = restored_preds\n",
    "    df[\"restored_reference\"] = restored_refs\n",
    "    df[\"file_id\"] = file_ids  # IDê¹Œì§€ ë¶™ì—¬ì£¼ë©´ ë””ë²„ê¹… í¸í•¨\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc237284-c3d7-4086-80b4-9cef8aee1cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 408/408 [00:08<00:00, 48.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              file_id  \\\n",
      "0  NIA_SL_G2_FIRE000004_1_KU02_F_norm   \n",
      "1  NIA_SL_G2_FIRE000004_2_KU02_F_norm   \n",
      "2  NIA_SL_G2_FIRE000004_3_KU02_F_norm   \n",
      "3  NIA_SL_G2_FIRE000020_1_KU02_F_norm   \n",
      "4  NIA_SL_G2_FIRE000020_2_KU02_F_norm   \n",
      "\n",
      "                                          prediction  \\\n",
      "0  <ë„ë¡œ>  ëŒ€í”¼í•˜ì‹œê¸° ì£¼ë¯¼ë“¤ê»˜ì„œëŠ” ì§€ì—­ì„ ëŒ€í”¼í•˜ê¸°<ë„ë¡œ> í™”ì¬ ë°œìƒìœ¼ë¡œ ì¸ê·¼ì— ë¶„ë“¤...   \n",
      "1                  <ì§€ì—­> <ë„ë¡œ>ì—ì„œ ë°œìƒìœ¼ë¡œ ì¼ë¶€ ì°¨ëŸ‰í†µì œ,ìœ¼ë¡œ ë°”ëë‹ˆë‹¤.   \n",
      "2            <ì§€ì—­> <ì£¼ì†Œ> í™”ì¬ ë°œìƒìœ¼ë¡œ ì¸ê·¼ ì£¼ë¯¼ì€<ë„ë¡œ>ì˜ì§€í•˜ì˜¤ë‹ˆ ë°”ëë‹ˆë‹¤.   \n",
      "3              <ì‹œê°„> <ì§€ì—­> <ê±´ë¬¼> í™”ì¬ë°œìƒ, ì¸ê·¼ ì— ì•ˆì „ì— ìœ ì˜ ë°”ëë‹ˆë‹¤   \n",
      "4     <ì‹œê°„> <ì§€ì—­> <ì£¼ì†Œ>ì—ì„œ í™”ì¬ë°œìƒ, ì¸ê·¼<ê±´ë¬¼> ì£¼ë¯¼ë“¤ì€ ì•ˆì „ì— ìœ ì˜ ë°”ëë‹ˆë‹¤   \n",
      "\n",
      "                                           reference  \\\n",
      "0  5.23. <ì‹œê°„> <ì§€ì—­> <ê±´ë¬¼> <ê±´ë¬¼> ì§€í•˜ì£¼ì°¨ì¥ í™”ì¬ë¡œ ì¸í•´ ì°¨ëŸ‰í†µì œ ì¤‘ì„...   \n",
      "1  5.23. <ì‹œê°„> <ì§€ì—­> <ê±´ë¬¼> <ê±´ë¬¼> ì§€í•˜ì£¼ì°¨ì¥ í™”ì¬ë¡œ ì¸í•´ ì°¨ëŸ‰í†µì œ ì¤‘ì„...   \n",
      "2  5.23. <ì‹œê°„> <ì§€ì—­> <ê±´ë¬¼> <ê±´ë¬¼> ì§€í•˜ì£¼ì°¨ì¥ í™”ì¬ë¡œ ì¸í•´ ì°¨ëŸ‰í†µì œ ì¤‘ì„...   \n",
      "3  ì˜¤ëŠ˜ <ì‹œê°„> ë°˜ì›”ê³µë‹¨ ë‚´ ëŒ€ë¦¼ë¹„ì•¤ì½” í™”ì¬ë¡œ ì¸í•´ ì°¨ëŸ‰í†µí–‰ ë¶ˆê°€í•˜ì˜¤ë‹ˆ ìš°íšŒí•˜ì—¬ ì£¼ì‹œ...   \n",
      "4  ì˜¤ëŠ˜ <ì‹œê°„> ë°˜ì›”ê³µë‹¨ ë‚´ ëŒ€ë¦¼ë¹„ì•¤ì½” í™”ì¬ë¡œ ì¸í•´ ì°¨ëŸ‰í†µí–‰ ë¶ˆê°€í•˜ì˜¤ë‹ˆ ìš°íšŒí•˜ì—¬ ì£¼ì‹œ...   \n",
      "\n",
      "                                 restored_prediction  \\\n",
      "0  <ë„ë¡œ>  ëŒ€í”¼í•˜ì‹œê¸° ì£¼ë¯¼ë“¤ê»˜ì„œëŠ” ì§€ì—­ì„ ëŒ€í”¼í•˜ê¸°<ë„ë¡œ> í™”ì¬ ë°œìƒìœ¼ë¡œ ì¸ê·¼ì— ë¶„ë“¤...   \n",
      "1                   êµ°í¬ì‹œ <ë„ë¡œ>ì—ì„œ ë°œìƒìœ¼ë¡œ ì¼ë¶€ ì°¨ëŸ‰í†µì œ,ìœ¼ë¡œ ë°”ëë‹ˆë‹¤.   \n",
      "2             êµ°í¬ì‹œ <ì£¼ì†Œ> í™”ì¬ ë°œìƒìœ¼ë¡œ ì¸ê·¼ ì£¼ë¯¼ì€<ë„ë¡œ>ì˜ì§€í•˜ì˜¤ë‹ˆ ë°”ëë‹ˆë‹¤.   \n",
      "3             14:40 <ì§€ì—­> <ê±´ë¬¼> í™”ì¬ë°œìƒ, ì¸ê·¼ ì— ì•ˆì „ì— ìœ ì˜ ë°”ëë‹ˆë‹¤   \n",
      "4    14:40 <ì§€ì—­> <ì£¼ì†Œ>ì—ì„œ í™”ì¬ë°œìƒ, ì¸ê·¼<ê±´ë¬¼> ì£¼ë¯¼ë“¤ì€ ì•ˆì „ì— ìœ ì˜ ë°”ëë‹ˆë‹¤   \n",
      "\n",
      "                                  restored_reference  \n",
      "0  5.23. 09:50 êµ°í¬ì‹œ ë¡¯ë°ë¦¬ì•„ê±´ë¬¼ ë¡¯ë°ë¦¬ì•„ê±´ë¬¼ ì§€í•˜ì£¼ì°¨ì¥ í™”ì¬ë¡œ ì¸í•´ ì°¨ëŸ‰í†µ...  \n",
      "1  5.23. 09:50 êµ°í¬ì‹œ ë¡¯ë°ë¦¬ì•„ê±´ë¬¼ ë¡¯ë°ë¦¬ì•„ê±´ë¬¼ ì§€í•˜ì£¼ì°¨ì¥ í™”ì¬ë¡œ ì¸í•´ ì°¨ëŸ‰í†µ...  \n",
      "2  5.23. 09:50 êµ°í¬ì‹œ ë¡¯ë°ë¦¬ì•„ê±´ë¬¼ ë¡¯ë°ë¦¬ì•„ê±´ë¬¼ ì§€í•˜ì£¼ì°¨ì¥ í™”ì¬ë¡œ ì¸í•´ ì°¨ëŸ‰í†µ...  \n",
      "3  ì˜¤ëŠ˜ 14:40 ë°˜ì›”ê³µë‹¨ ë‚´ ëŒ€ë¦¼ë¹„ì•¤ì½” í™”ì¬ë¡œ ì¸í•´ ì°¨ëŸ‰í†µí–‰ ë¶ˆê°€í•˜ì˜¤ë‹ˆ ìš°íšŒí•˜ì—¬ ì£¼...  \n",
      "4  ì˜¤ëŠ˜ 14:40 ë°˜ì›”ê³µë‹¨ ë‚´ ëŒ€ë¦¼ë¹„ì•¤ì½” í™”ì¬ë¡œ ì¸í•´ ì°¨ëŸ‰í†µí–‰ ë¶ˆê°€í•˜ì˜¤ë‹ˆ ìš°íšŒí•˜ì—¬ ì£¼...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_restored = restore_pred_and_ref_with_file_ids(\n",
    "    pred_csv_path=\"val_predictions.csv\",\n",
    "    json_dir=\"training/val/norm_keypoint\",\n",
    "    file_id_npy_path=\"training/val/processed/file_id_part_0.npy\"\n",
    ")\n",
    "\n",
    "# ë¯¸ë¦¬ë³´ê¸°\n",
    "print(df_restored[[\"file_id\", \"prediction\", \"reference\", \"restored_prediction\", \"restored_reference\"]].head())\n",
    "\n",
    "# ì €ì¥\n",
    "df_restored.to_csv(\"val_predictions_restored.csv\", index=False, encoding=\"utf-8-sig\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c486e0c1-e317-44e0-b789-ee075e0b9b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1751285248.457784   11380 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1751285248.474995   11382 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1751285248.487133   11377 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1751285248.523309   11379 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    }
   ],
   "source": [
    "# ì‹œì—° \n",
    "# keypoint ì¶”ì¶œ\n",
    "\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# MediaPipe pose ì´ˆê¸°í™”\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(static_image_mode=False)\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(static_image_mode=False)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "def extract_keypoints_from_video(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    all_keypoints = []\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # BGR â†’ RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Pose ì¶”ì¶œ\n",
    "        pose_result = pose.process(image)\n",
    "        hand_result = hands.process(image)\n",
    "\n",
    "        keypoints = []\n",
    "\n",
    "        # Pose keypoints\n",
    "        if pose_result.pose_landmarks:\n",
    "            for lm in pose_result.pose_landmarks.landmark:\n",
    "                keypoints.extend([lm.x, lm.y, lm.visibility])\n",
    "        else:\n",
    "            keypoints.extend([0.0, 0.0, 0.0] * 33)\n",
    "\n",
    "        # Hands keypoints (ì™¼ì† + ì˜¤ë¥¸ì†)\n",
    "        for hand_landmarks in [hand_result.left_hand_landmarks, hand_result.right_hand_landmarks]:\n",
    "            if hand_landmarks:\n",
    "                for lm in hand_landmarks.landmark:\n",
    "                    keypoints.extend([lm.x, lm.y, lm.visibility])\n",
    "            else:\n",
    "                keypoints.extend([0.0, 0.0, 0.0] * 21)\n",
    "\n",
    "        # ì´ keypoint ìˆ˜ í™•ì¸ (33 + 21 + 21 = 75ê°œ â†’ 75 x 3 = 225ì°¨ì›)\n",
    "        all_keypoints.append(keypoints)\n",
    "\n",
    "    cap.release()\n",
    "    return np.array(all_keypoints)  # shape: (T, 225)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fff8114e-ef8a-4b62-9f69-e98d7a164eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“Œ MediaPipe ì²˜ë¦¬ ì¤‘:   0%|          | 0/707 [00:00<?, ?it/s]W0000 00:00:1751286223.754911   14048 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1751286223.773966   14044 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1751286223.777339   14048 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1751286223.813469   14044 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "ğŸ“Œ MediaPipe ì²˜ë¦¬ ì¤‘: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 707/707 [00:29<00:00, 23.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â–¶ ìµœì¢… shape: (707, 108)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ğŸ¯ ìœ ì§€í•  pose index\n",
    "POSE_KEEP_IDX = [0, 1, 2, 3, 4, 5, 6, 7, 15, 16, 17, 18]\n",
    "\n",
    "def extract_video_frames(video_path, fps=30):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    original_fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_interval = int(original_fps // fps) if original_fps > fps else 1\n",
    "\n",
    "    frames = []\n",
    "    count = 0\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        if count % frame_interval == 0:\n",
    "            frames.append(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        count += 1\n",
    "    cap.release()\n",
    "    return frames\n",
    "\n",
    "def extract_filtered_keypoints(frames):\n",
    "    mp_pose = mp.solutions.pose\n",
    "    mp_hands = mp.solutions.hands\n",
    "\n",
    "    pose = mp_pose.Pose(static_image_mode=False)\n",
    "    hands = mp_hands.Hands(static_image_mode=False, max_num_hands=2)\n",
    "\n",
    "    results = []\n",
    "    for frame in tqdm(frames, desc=\"ğŸ“Œ MediaPipe ì²˜ë¦¬ ì¤‘\"):\n",
    "        frame_kpts = []\n",
    "\n",
    "        # ğŸ”¹ Pose keypoints\n",
    "        pose_result = pose.process(frame)\n",
    "        if pose_result.pose_landmarks:\n",
    "            pose_kpts = pose_result.pose_landmarks.landmark\n",
    "            for idx in POSE_KEEP_IDX:\n",
    "                lm = pose_kpts[idx]\n",
    "                frame_kpts.extend([lm.x, lm.y])\n",
    "        else:\n",
    "            frame_kpts.extend([0.0, 0.0] * len(POSE_KEEP_IDX))\n",
    "\n",
    "        # ğŸ”¹ Hands keypoints\n",
    "        hand_result = hands.process(frame)\n",
    "        left_hand = [0.0, 0.0] * 21\n",
    "        right_hand = [0.0, 0.0] * 21\n",
    "\n",
    "        if hand_result.multi_hand_landmarks and hand_result.multi_handedness:\n",
    "            for i, hand_landmarks in enumerate(hand_result.multi_hand_landmarks):\n",
    "                label = hand_result.multi_handedness[i].classification[0].label\n",
    "                coords = [coord for lm in hand_landmarks.landmark for coord in (lm.x, lm.y)]\n",
    "                if label == \"Left\":\n",
    "                    left_hand = coords\n",
    "                elif label == \"Right\":\n",
    "                    right_hand = coords\n",
    "\n",
    "        frame_kpts.extend(left_hand)\n",
    "        frame_kpts.extend(right_hand)\n",
    "        results.append(frame_kpts)\n",
    "\n",
    "    return np.array(results)  # shape: (T, 108)\n",
    "\n",
    "# âœ… ì‹¤í–‰ ì˜ˆì‹œ\n",
    "video_path = \"video.mp4\"\n",
    "\n",
    "frames = extract_video_frames(video_path, fps=30)\n",
    "kpt_108 = extract_filtered_keypoints(frames)\n",
    "\n",
    "print(\"â–¶ ìµœì¢… shape:\", kpt_108.shape)  # (T, 108)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4ea66c3a-07eb-48a1-9c42-03d0fc9acefd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â–¶ ì •ê·œí™”ëœ shape: (707, 108)\n"
     ]
    }
   ],
   "source": [
    "# Size ë³µì› í›„ ì •ê·œí™” \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def normalize_mediapipe_keypoints(kpt_108: np.ndarray, stat_path: str,\n",
    "                                   image_width=1280, image_height=720) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Normalize MediaPipe keypoints using OpenPose-based statistics.\n",
    "    \n",
    "    Args:\n",
    "        kpt_108 (np.ndarray): Keypoints of shape (T, 108) with (x, y) in range [0, 1]\n",
    "        stat_path (str): Path to 'norm_stat.npz' from training\n",
    "        image_width (int): Width of original video frames\n",
    "        image_height (int): Height of original video frames\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: Normalized keypoints of shape (T, 108)\n",
    "    \"\"\"\n",
    "    # 1. ì¢Œí‘œ ë³µì› (0~1 â†’ í”½ì…€)\n",
    "    kpt = np.copy(kpt_108)\n",
    "    kpt[:, 0::2] *= image_width   # x ì¢Œí‘œ\n",
    "    kpt[:, 1::2] *= image_height  # y ì¢Œí‘œ\n",
    "\n",
    "    # 2. í†µê³„ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "    stats = np.load(stat_path)\n",
    "    pose_mu = stats[\"pose_mu\"]\n",
    "    pose_sd = stats[\"pose_sd\"]\n",
    "    left_min = stats[\"left_min\"]\n",
    "    left_max = stats[\"left_max\"]\n",
    "    right_min = stats[\"right_min\"]\n",
    "    right_max = stats[\"right_max\"]\n",
    "\n",
    "    # 3. ë¶„í• \n",
    "    pose = kpt[:, :24]\n",
    "    left = kpt[:, 24:66]\n",
    "    right = kpt[:, 66:]\n",
    "\n",
    "    # 4. ì •ê·œí™”\n",
    "    norm_pose = (pose - pose_mu) / (pose_sd + 1e-8)\n",
    "    norm_left = (left - left_min) / (left_max - left_min + 1e-8) - 0.5\n",
    "    norm_right = (right - right_min) / (right_max - right_min + 1e-8) - 0.5\n",
    "\n",
    "    # 5. í•©ì¹˜ê¸°\n",
    "    norm_kpt = np.concatenate([norm_pose, norm_left, norm_right], axis=-1)\n",
    "    return norm_kpt\n",
    "\n",
    "norm_kpt = normalize_mediapipe_keypoints(kpt_108, stat_path=\"training/norm_stat.npz\")\n",
    "print(\"â–¶ ì •ê·œí™”ëœ shape:\", norm_kpt.shape)  # (T, 108)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "541ded9c-9eb2-4c65-831e-cb06032f110b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Pose í‰ê· ê³¼ í‘œì¤€í¸ì°¨\n",
      "Mean: [-11.16571178   1.61261149 -12.24069937  -5.13413468  -4.6927129\n",
      "  -4.9362072   -1.33633479  -4.47444851  -2.59699363  -1.37483823\n",
      " -21.97698555  -4.95795615 -13.19388483  -5.35643645  -6.284303\n",
      "  -1.91416178  -5.98963323   6.05604604 -15.13240997   5.09070572\n",
      "  -3.08469361   5.56407687 -10.08432758   4.61333059]\n",
      "Std:  [0.19218931 0.06411243 0.18897083 0.0786324  0.13019507 0.07248655\n",
      " 0.06903451 0.02829407 0.06687626 0.01036941 0.21694626 0.0653447\n",
      " 0.10574796 0.02625473 0.05032789 0.00819363 1.37046651 1.27776483\n",
      " 1.44009533 0.94750438 1.15802779 1.67799417 1.16173833 1.25872799]\n",
      "\n",
      "âœ… Left hand ë²”ìœ„\n",
      "Min: -0.5 Max: 0.061749881855847955\n",
      "\n",
      "âœ… Right hand ë²”ìœ„\n",
      "Min: -0.5 Max: 0.20890637965029302\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Pose (ì•ìª½ 24ì°¨ì›): 12ê°œ keypoint Ã— 2 = 24\n",
    "pose = norm_kpt[:, :24]\n",
    "# Left hand (ì¤‘ê°„ 42ì°¨ì›): 21ê°œ keypoint Ã— 2 = 42\n",
    "left = norm_kpt[:, 24:66]\n",
    "# Right hand (ë’¤ìª½ 42ì°¨ì›)\n",
    "right = norm_kpt[:, 66:]\n",
    "\n",
    "print(\"âœ… Pose í‰ê· ê³¼ í‘œì¤€í¸ì°¨\")\n",
    "print(\"Mean:\", pose.mean(axis=0))\n",
    "print(\"Std: \", pose.std(axis=0))\n",
    "\n",
    "print(\"\\nâœ… Left hand ë²”ìœ„\")\n",
    "print(\"Min:\", left.min(), \"Max:\", left.max())\n",
    "\n",
    "print(\"\\nâœ… Right hand ë²”ìœ„\")\n",
    "print(\"Min:\", right.min(), \"Max:\", right.max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e468c11c-5287-4340-864f-845e83106617",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def predict_from_keypoint(model, keypoint_seq, tokenizer, device, eos_id=2, max_len=100):\n",
    "    model.eval()\n",
    "\n",
    "    # 1. numpy â†’ torch tensor ë³€í™˜: (T, 108) â†’ (1, T, 108)\n",
    "    x = torch.tensor(keypoint_seq, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "\n",
    "    # 2. Decoder ì‹œì‘ í† í°: BOS\n",
    "    bos_id = tokenizer.bos_id()\n",
    "    decoder_input = torch.tensor([[bos_id]], dtype=torch.long).to(device)\n",
    "\n",
    "    preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_len):\n",
    "            # 3. ëª¨ë¸ forward\n",
    "            output = model(x, decoder_input, teacher_forcing_ratio=0.0)\n",
    "\n",
    "            # 4. ê°€ì¥ ë§ˆì§€ë§‰ í† í°ì˜ í™•ë¥  â†’ ì˜ˆì¸¡ token id\n",
    "            next_token = output[:, -1, :].argmax(dim=-1).item()\n",
    "\n",
    "            # 5. EOS í† í°ì´ë©´ ì¢…ë£Œ\n",
    "            if next_token == eos_id:\n",
    "                break\n",
    "\n",
    "            preds.append(next_token)\n",
    "\n",
    "            # 6. decoder input ì—…ë°ì´íŠ¸\n",
    "            next_token_tensor = torch.tensor([[next_token]], dtype=torch.long).to(device)\n",
    "            decoder_input = torch.cat([decoder_input, next_token_tensor], dim=1)\n",
    "\n",
    "    # 7. í† í° ID â†’ ë¬¸ì¥ ë³µì›\n",
    "    return tokenizer.decode(preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d3a13344-f1cd-4da7-8397-64ae9ba4693c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (rnn): GRU(108, 256, batch_first=True, bidirectional=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(1000, 256)\n",
       "    (attention): Attention(\n",
       "      (attn): Linear(in_features=768, out_features=256, bias=True)\n",
       "      (v): Linear(in_features=256, out_features=1, bias=False)\n",
       "    )\n",
       "    (rnn): GRU(768, 256, batch_first=True)\n",
       "    (fc_out): Linear(in_features=1024, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. ëª¨ë¸ ë¡œë“œ \n",
    "model = Seq2Seq(encoder, decoder, device).to(device)\n",
    "\n",
    "checkpoint = torch.load(\"checkpoints/best_checkpoint.pt\", map_location=device, weights_only=False)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e71a8ca0-741e-4829-9f02-ba322583608a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” ì˜ˆì¸¡ ê²°ê³¼:  â‡ <ì‹œê°„> ë°œìƒìœ¼ë¡œ<ë„ë¡œ><ë„ë¡œ><ë„ë¡œ> ë°œìƒìœ¼ë¡œ ë°œìƒìœ¼ë¡œ<ë„ë¡œ><ë„ë¡œ> ì¼ëŒ€ê°€ ì¼ëŒ€ê°€ ëŒ€í”¼ ì¼ëŒ€ ëŒ€í”¼ ë°œìƒìœ¼ë¡œ ëŒ€í”¼ ì¼ëŒ€ê°€ ì¼ëŒ€ê°€ ì¼ëŒ€ê°€ ì¼ëŒ€ê°€ ì¼ëŒ€ê°€ ì¼ëŒ€ê°€ ì¼ëŒ€ê°€ ì¼ëŒ€ê°€ ì¼ëŒ€ê°€ ì¼ëŒ€ê°€ ì¼ëŒ€ê°€ ì¼ëŒ€ê°€ ì¼ëŒ€ê°€ ì¼ëŒ€ê°€ ì¼ëŒ€ê°€ ì¼ëŒ€ê°€ ì¼ëŒ€ê°€ ì¼ëŒ€ê°€ ì¼ëŒ€ê°€ ì¼ëŒ€ê°€ ì¼ëŒ€ê°€ ì¼ëŒ€ê°€ ì¼ëŒ€ê°€ ì¼ëŒ€ê°€ ì¼ëŒ€ê°€ ì¼ëŒ€ê°€ ì¼ëŒ€ê°€ ì¼ëŒ€ê°€ ì¼ëŒ€ê°€ ì¼ëŒ€ê°€ ì¼ëŒ€ê°€ ì¼ëŒ€ê°€ ì¼ëŒ€ê°€ ì¼ëŒ€ê°€ ì¼ëŒ€ê°€ ì¼ëŒ€ê°€ ì¼ëŒ€ê°€ ì¼ëŒ€ê°€ ì¼ëŒ€ê°€ ì¼ëŒ€ê°€ ì¼ëŒ€\n"
     ]
    }
   ],
   "source": [
    "# ì˜ˆì¸¡\n",
    "output_text = predict_from_keypoint(model, norm_kpt, spm_tokenizer, device)\n",
    "print(\"ğŸ” ì˜ˆì¸¡ ê²°ê³¼:\", output_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "77b12bae-4387-444a-9b84-49475955b426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì´ ê°’ ì¤‘ 0ì˜ ë¹„ìœ¨: 14.47%\n"
     ]
    }
   ],
   "source": [
    "# ì¶”ì¶œì´ ì˜ ì•ˆë¨\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Convert the first few frames to a DataFrame for easier inspection\n",
    "df = pd.DataFrame(kpt_108)  # Show first 5 frames\n",
    "\n",
    "total_elements = df.size\n",
    "\n",
    "# 0ì˜ ê°œìˆ˜\n",
    "zero_count = (df < 0.1).sum().sum()\n",
    "\n",
    "# ë¹„ìœ¨ ê³„ì‚° (%)\n",
    "zero_ratio = (zero_count / total_elements) * 100\n",
    "\n",
    "print(f\"ì´ ê°’ ì¤‘ 0ì˜ ë¹„ìœ¨: {zero_ratio:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
