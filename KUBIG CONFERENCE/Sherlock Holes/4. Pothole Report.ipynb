{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMs7A59gX0SNfUqGk2RI+y+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#### 1. 변수 중요도 - SHAP"],"metadata":{"id":"Rpe9O1dAfURH"}},{"cell_type":"code","source":["###----- 모델 로드 -----###\n","model_path = model_path = ###### 모델 경로 ######\n","xgb_model = joblib.load(model_path)\n","\n","# 모델 만들 때 사용한 x\n","x_train_up = pd.read_csv(###### 모델 학습 시 사용한 train set 경로 ######)\n","\n","# 살펴볼 데이터\n","x_test = pd.read_csv(###### 중요도를 확인할 데이터 경로 #######)\n","x_test.drop(['Unnamed: 0'], axis = 1, inplace = True)\n","\n","###----- SHAP -----###\n","shap_explainer = shap.Explainer(xgb_model, x_train_up)\n","shap_values_ex = shap_explainer(x_test) # 각 SHAP value에 대한 정보를 담은 Explainer\n","\n","# 보고서 예시 1 - 전체 feature importance\n","shap.plots.bar(shap_values_ex)\n","\n","# 보고서 예시 2 - 평균 feature importance\n","shap.plots.bar(shap_values_ex.mean(axis = 0))\n","\n","# 보고서 예시 3 - 특정 feature 하나 (scatter)\n","shap.plots.scatter(shap_values_ex[:, \"승용차\"]) # '승용차' 변수"],"metadata":{"id":"j4j3ZvgKfh38"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 2. 예측 리포트"],"metadata":{"id":"GsvUQxSPfQyO"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"s1-bpKkFfELI"},"outputs":[],"source":["###----- 함수 정의 -----###\n","### 지오코딩 - 위도, 경도, 자치구, 행정동 찾아오기\n","def geo_coding(df):\n","    ### 위도, 경도\n","    gk.add_coordinates_to_dataframe(df, '주소')\n","    df = df.rename(columns = {\"decimalLatitude\" : \"위도\", \"decimalLongitude\" : \"경도\"})\n","\n","    ### 자치구, 행정동\n","    # 동 : ~동, ~가 부분 찾아오기\n","    def get_dong(address):\n","        find = re.search(r\"\\b(\\w+[동가])\\b\", address)\n","        if find:\n","            dong = find.group(1)\n","            return(dong)\n","        else:\n","            return(np.nan)\n","\n","    # 구 : ~구 부분 찾아오기\n","    def get_gu(address):\n","        find = re.search(r\"\\b(\\w+구)\\b\", address)\n","        if find:\n","            gu = find.group(1)\n","            return(gu)\n","        else:\n","            return(np.nan)\n","\n","    # DataFrame 추가\n","    def add_dong_gu_to_dataframe(df):\n","        dongs = []\n","        gus = []\n","\n","        for i in range(len(df)):\n","            address = df.loc[i, '주소']\n","\n","            if address:\n","                try:\n","                    dong = get_dong(address)\n","                except:\n","                    dong = np.nan\n","                try:\n","                    gu = get_gu(address)\n","                except:\n","                    gu = np.nan\n","            else:\n","                dong = np.nan\n","                gu = np.nan\n","\n","            dongs.append(dong)\n","            gus.append(gu)\n","\n","        df[\"행정동\"] = dongs\n","        df[\"자치구\"] = gus\n","        return df\n","\n","    df = add_dong_gu_to_dataframe(df)\n","    return df\n","\n","### ----------------------------------------------------------------------------------\n","\n","### 교통량 데이터 추가하기\n","def traffic(df):\n","    # 도로 데이터\n","    gdf_links = gpd.read_file(###### 도로 데이터 경로 ######)\n","    gdf_links['LINK_ID'] = gdf_links['LINK_ID'].astype(int)\n","\n","    # 새로운 데이터 공간 데이터로 변환\n","    gdf_potholes = gpd.GeoDataFrame(\n","        df,\n","        geometry = gpd.points_from_xy(df['경도'], df['위도']),\n","        crs=\"EPSG:4326\")  # 위/경도 WGS84 좌표계로 설정\n","\n","    # 새로운 데이터 좌표계 통일\n","    if gdf_links.crs is not None:\n","        gdf_potholes = gdf_potholes.to_crs(gdf_links.crs)\n","\n","    # 새로운 데이터의 위치와 가까운 도로 번호(+도로정보) 매칭\n","    gdf_nearest = gpd.sjoin_nearest(\n","        gdf_potholes, gdf_links,\n","        how='left',\n","        distance_col='distance')  # 계산한 거리(m)\n","\n","    ### 교통량 데이터\n","    traffic_d = pd.read_excel(###### 교통량 데이터 경로 ######)\n","\n","    # 전처리\n","    traffic_d.columns = [\n","        f\"{upper}\" if 'Unnamed' in str(lower) else f\"{upper}_{lower}\"\n","        for upper, lower in traffic_d.columns]\n","    traffic_d.rename(columns={\n","        'ITS LINK ID': 'ITS_LINK_ID',\n","        '승용차-평일_전일': '승용차',\n","        '버스-평일_전일': '버스',\n","        '트럭-평일_전일': '트럭'}, inplace=True)\n","\n","    traffic_d['ITS_LINK_ID'] = traffic_d['ITS_LINK_ID'].astype(str).str.split(',')\n","    traffic_d = traffic_d.explode('ITS_LINK_ID')\n","    traffic_d['LINK_ID'] = traffic_d['ITS_LINK_ID'].str.strip().astype(int)\n","    traffic_df = traffic_d[['LINK_ID', '도로명', '차선수', '승용차', '버스', '트럭']].copy()\n","    traffic_df = (traffic_df.dropna(subset=['LINK_ID']).drop_duplicates('LINK_ID').reset_index(drop=True).astype({'LINK_ID': 'int'}))\n","\n","    # 교통량 join\n","    pothole_traffic = gdf_nearest.merge(traffic_df, on='LINK_ID', how='left')\n","    pothole_output = pothole_traffic[['날짜', '주소', '위도', '경도', '행정동', '자치구', 'LINK_ID', '도로명', '차선수', '승용차', '버스', '트럭']]\n","    pothole_output['총교통량'] = pothole_output['승용차'] + pothole_output['버스'] + pothole_output['트럭']\n","    pothole_output['중대형차량 교통량'] = (pothole_output['버스'] + pothole_output['트럭']) / pothole_output['총교통량']\n","\n","\n","    return pothole_output\n","\n","### ----------------------------------------------------------------------------------\n","\n","### 건물 평균 연령, 배수등급, 경사도 추가\n","def nature(new_pothole_traffic):\n","\n","    ### 건물별 평균 연령\n","    old = pd.read_csv(###### 건물별 연령 데이터 경로 ######)\n","    bup = pd.read_csv(###### 법정동 코드 데이터 경로 ######)\n","    bup['법정동명'] = bup['법정동명'].astype(str)\n","\n","    # 법정동 만들기\n","    new_pothole_traffic['법정동명'] = '서울특별시 ' + new_pothole_traffic['자치구'] + ' ' + new_pothole_traffic['행정동']\n","    new_pothole_traffic['법정동명'] = new_pothole_traffic['법정동명'].astype(str)\n","\n","    # join\n","    new_pothole_building = new_pothole_traffic.merge(bup[['법정동코드', '법정동명']], on = '법정동명', how = 'left')\n","    new_pothole_building = new_pothole_building.merge(old[['법정동코드', '평균_건물연령']], on = '법정동코드', how = 'left')\n","\n","    ### 배수등급\n","    # 공간 데이터로 변환\n","    gdf_pothole2 = gpd.GeoDataFrame(\n","        new_pothole_building,\n","        geometry=gpd.points_from_xy(new_pothole_building['경도'], new_pothole_building['위도']),\n","        crs=\"EPSG:4326\")\n","\n","    # 포트홀 좌표계 → EPSG:5174 로 변환 (shp에 맞추기)\n","    gdf_pothole2 = gdf_pothole2.to_crs(\"EPSG:5174\")\n","\n","    # 배수등급 로드\n","    soil_df = gpd.read_file(###### 배수등급 데이터 경로 ######)\n","\n","    # join\n","    new_pothole_soil = gpd.sjoin(gdf_pothole2, soil_df[['SOILDRA', 'geometry']], how='left', predicate='within')\n","\n","    ### 토양 경사도\n","    # 데이터 로드\n","    slope_df = gpd.read_file(###### 토양 경사도 데이터 경로 ######)\n","    new_pothole_soil.drop(['index_right'], axis=1, inplace=True)\n","\n","    # join\n","    new_pothole_slope = gpd.sjoin(new_pothole_soil, slope_df[['SOILSLOPE', 'geometry']], how='left', predicate='within')\n","\n","    # 열 이름 수정\n","    new_pothole_slope.rename(columns = {'SOILDRA' : '배수등급', 'SOILSLOPE' : '경사도'}, inplace = True)\n","    new_pothole_done = new_pothole_slope[['날짜', '주소', '위도', '경도', '자치구', '행정동', '도로명', '차선수', '승용차', '버스', '트럭', '총교통량', '중대형차량 교통량', '평균_건물연령', '배수등급' ,'경사도']]\n","\n","    return new_pothole_done\n","\n","### ----------------------------------------------------------------------------------\n","\n","def join_gu(new_pothole_done):\n","    ### 자치구별 데이터 로드\n","    people = pd.read_pickle(###### 자치구별 인구 수 데이터 경로 ######)\n","    people['자치구'] = people['자치구'].str.replace(\"\\u3000\",\"\",regex = False)\n","\n","    new_pothole_done.rename(columns = {'날짜' : '발생일'}, inplace = True)\n","    new_pothole_done['발생일'] = pd.to_datetime(new_pothole_done['발생일'])\n","\n","    ### 인구 수\n","    new_pothole = pd.merge(new_pothole_done, people, on = '자치구', how = 'left')\n","\n","    return new_pothole\n","\n","### ----------------------------------------------------------------------------------\n","\n","def prediction(new_pothole, transformer_path, scaler_path, model_path):\n","    ## x 할당\n","    new_x = new_pothole[['차선수', '승용차', '버스', '트럭', '총교통량', '중대형차량 교통량', '평균_건물연령', '인구 수', '배수등급', '경사도']]\n","\n","    # 저장된 변환기, 스케일러 불러오기\n","    transformer = joblib.load(transformer_path)\n","    scaler = joblib.load(scaler_path)\n","    # 새로운 데이터 변환\n","    cols = ['승용차', '버스', '트럭', '총교통량', '중대형차량 교통량', '평균_건물연령', '인구 수']\n","    arr = new_x[cols].values + 1e-6\n","    bc = transformer.transform(arr)\n","    bc_std = scaler.transform(bc)\n","    new_x[cols] = bc_std\n","\n","    ### 배수등급, 경사도 변수 처리\n","    # 경사도\n","    slope_encoding = {\n","        '0-2%': 0,\n","        '2-7%': 1,\n","        '7-15%': 2,\n","        '15-30%': 3,\n","        '30-60%': 4,\n","        '60-100%': 5}\n","    # 배수등급\n","    drain_encoding = {\n","        '매우양호': 5,\n","        '양호': 4,\n","        '약간양호': 3,\n","        '약간불량': 2,\n","        '불량': 1,\n","        '매우불량': 0}\n","    # 매핑\n","    new_x['경사도'] = new_x['경사도'].map(slope_encoding)\n","    new_x['배수등급'] = new_x['배수등급'].map(drain_encoding)\n","\n","    ### 모델 로드\n","    xgb_model = joblib.load(model_path)\n","    y_pred = xgb_model.predict(new_x)\n","    y_pred_prob = xgb_model.predict_proba(new_x)[:, 1]\n","\n","    return new_pothole, new_x, y_pred, y_pred_prob ## 원본 데이터, x를 살펴보기 위해 따로 받아옴 !"]},{"cell_type":"code","source":["def prediction_without_env(new_data, transformer_path, scaler_path, model_path):\n","    ### 마지막에 출력할 output\n","    output_df = new_data.copy()\n","    ### x 만들기\n","    geo = geo_coding(new_data)\n","    traffic_df = traffic(geo)\n","    nature_df = nature(traffic_df)\n","    new_potholes = join_gu(nature_df)\n","    ### 예측\n","    new_data_org, new_x, y_pred, y_pred_prob = prediction(new_potholes, transformer_path, scaler_path, model_path)\n","    ### output\n","    output_df['예측'] = y_pred\n","    output_df['예측 확률'] = y_pred_prob\n","    return new_data_org, new_x, output_df"],"metadata":{"id":"KB_4cCZzjwri"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### 새롭게 확인해볼 데이터 목록 (임의로 생성)\n","input = [\"서울특별시 강남구 대치동 507\",\n","         \"서울특별시 동대문구 제기동 137-418\",\n","         \"서울특별시 서초구 방배동 756-4\",\n","         \"서울특별시 용산구 동빙고동 90-1\",\n","         \"서울특별시 성북구 보문동5가 235\",\n","         ]\n","date = ['2024-07-28', '2023-06-23', '2021-10-29', '2024-01-05', '2022-04-29']\n","new_data = pd.DataFrame({'날짜' : date, '주소' : input})\n","\n","### Model, BoxCox Transformer, Scaler Path\n","model_path = ###### 모델 경로 ######\n","transformer_path = ###### BoxCox Transformer 경로 ######\n","scaler_path = ###### Standard Scaler 경로 ######\n","\n","### Prediction\n","new_data_org, new_x, output_df = prediction_without_env(new_data, transformer_path, scaler_path, model_path)\n","\n","# 리포트 예시 - 최종 데이터 프레임\n","output_df"],"metadata":{"id":"TogNhNTxjvXd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 3. 특정 샘플 변수 중요도 - SHAP"],"metadata":{"id":"KrCwkMkrfiUA"}},{"cell_type":"code","source":["###----- 모델 로드 -----###\n","model_path = model_path = ###### 모델 경로 ######\n","xgb_model = joblib.load(model_path)\n","\n","# 모델 만들 때 사용한 x\n","x_train_up = pd.read_csv(###### 모델 학습 시 사용한 train set 경로 ######)\n","\n","# 살펴볼 데이터 로드\n","new_places_x = pd.read_csv(###### 새롭게 입력한 데이터의 x 변환 결과 경로 #######)\n","new_places_x.drop(['Unnamed: 0'], axis = 1, inplace = True)\n","\n","###----- SHAP -----###\n","shap_explainer = shap.Explainer(xgb_model, x_train_up)\n","shap_values_ex = shap_explainer(new_places_x) # 각 SHAP value에 대한 정보를 담은 Explainer\n","\n","# 보고서 예시 - 특정 샘플(0번째 데이터) 설명\n","shap.plots.waterfall(shap_values_ex[0])"],"metadata":{"id":"CQpDbLo1fo61"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 4. 개선 방향 제시 - DiME"],"metadata":{"id":"iTqhLdXMfpN-"}},{"cell_type":"code","source":["###----- 역변환 함수 -----###\n","def inverse_scaling_boxcox(transformed_data, transformer_path, scaler_path):\n","\n","    # 역변환 대상 변수\n","    cols = ['승용차', '버스', '트럭', '총교통량', '중대형차량 교통량', '평균_건물연령', '인구 수']\n","    cols_idx = [transformed_data.columns.get_loc(col) for col in cols]\n","\n","    # scaler, transformer\n","    scaler = joblib.load(scaler_path)\n","    transformer = joblib.load(transformer_path)\n","\n","    # 변환된 5개 변수만 추출\n","    transformed = transformed_data.iloc[:, cols_idx]\n","\n","    # 역표준화\n","    un_scaled = scaler.inverse_transform(transformed)\n","\n","    # 역변환\n","    un_transformed = np.array([inv_boxcox(un_scaled[:, i], transformer.lambdas_[i]) for i in range(un_scaled.shape[1])]).T\n","\n","    # 전체 복원\n","    original = transformed_data.copy()\n","    for j, col in enumerate(cols):\n","        original[col] = un_transformed[:,j]\n","\n","    ### 배수등급, 경사도 변수 처리\n","    # 경사도\n","    slope_encoding = {'0-2%': 0, '2-7%': 1, '7-15%': 2, '15-30%': 3, '30-60%': 4, '60-100%': 5}\n","    # 배수등급\n","    drain_encoding = {'매우양호': 5, '양호': 4, '약간양호': 3, '약간불량': 2, '불량': 1, '매우불량': 0}\n","    # 인코딩 딕셔너리 뒤집기\n","    slope_decoding = {v: k for k, v in slope_encoding.items()}\n","    drain_decoding = {v: k for k, v in drain_encoding.items()}\n","\n","    # 역매핑\n","    original['경사도'] = original['경사도'].map(slope_decoding)\n","    original['배수등급'] = original['배수등급'].map(drain_decoding)\n","\n","    return original"],"metadata":{"id":"djahwjNUf8ug"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["###----- DiCE 활용, Counterfactual 생성 -----###\n","def dice(x_test, model_path, transformer_path, scaler_path): # x_test : 예측이 1로 나오는 예시 샘플 하나\n","    xgb_model = joblib.load(model_path)\n","\n","    # 혹시 모르니까 한 번 더 변환해주고\n","    x_test = x_test.astype('float64')\n","\n","    ### DiCE\n","    continuous = ['승용차', '버스', '트럭', '총교통량', '중대형차량 교통량', '평균_건물연령', '인구 수']\n","    d = dice_ml.Data(dataframe = x_test.assign(발생여부 = 0),  # dummy target\n","                     continuous_features = continuous,\n","                     outcome_name = \"발생여부\")\n","    m = dice_ml.Model(model = xgb_model, backend = \"sklearn\")\n","    exp = dice_ml.Dice(d, m)\n","\n","    ### counterfactual 생성\n","    # 값을 바꿀 변수들만 지정\n","    features_to_change = ['승용차', '버스', '트럭', '총교통량', '중대형차량 교통량', '평균_건물연령']\n","    query_instance = x_test\n","    query_instance = query_instance.astype('float64')\n","    cf = exp.generate_counterfactuals(query_instance, total_CFs=1, desired_class=\"opposite\",features_to_vary=features_to_change)\n","\n","    ### 데이터프레임 저장\n","    # 기존 데이터\n","    original_one = cf.cf_examples_list[0].test_instance_df\n","    # 바뀐 데이터\n","    changed_zero = cf.cf_examples_list[0].final_cfs_df\n","\n","    original_one = inverse_scaling_boxcox(original_one, transformer_path, scaler_path)\n","    changed_zero = inverse_scaling_boxcox(changed_zero, transformer_path, scaler_path)\n","\n","    return original_one, changed_zero"],"metadata":{"id":"GJj8lpb6khSn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Model, BoxCox Transformer, Scaler Path\n","model_path = ###### 모델 경로 ######\n","transformer_path = ###### BoxCox Transformer 경로 ######\n","scaler_path = ###### Standard Scaler 경로 ######\n","\n","### DiCE로 Counterfactual 생성\n","new_x = pd.read_csv(###### 새롭게 확인하고자 하는 데이터 ######)\n","new_x.drop(['Unnamed: 0'], axis = 1, inplace = True)\n","new_x_first = new_x.loc[[3]] # 세 번째 데이터 확인\n","new_x_first = new_x_first.astype('float64')\n","\n","original_one, changed_zero = dice(new_x_first, model_path, transformer_path, scaler_path)\n","# 리포트 예시 - original_one과 changed_zero 데이터프레임 출력\n","display(original_one)\n","display(changed_zero)"],"metadata":{"id":"55wkQ7WMkpvV"},"execution_count":null,"outputs":[]}]}
