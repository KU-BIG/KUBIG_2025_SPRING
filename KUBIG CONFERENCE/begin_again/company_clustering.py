# -*- coding: utf-8 -*-
"""표준산업분류.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cVULmlBuprtyopC32tsaz1z5QGutjmV3
"""

!pip install konlpy

!apt-get -qq install -y fonts-nanum

import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import matplotlib as mpl

# 나눔고딕 폰트 경로 직접 등록
font_path = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'
fm.fontManager.addfont(font_path)

# matplotlib에 폰트 적용
nanum_font = fm.FontProperties(fname=font_path).get_name()
mpl.rc('font', family=nanum_font)
plt.rcParams['axes.unicode_minus'] = False

from konlpy.tag import Okt
import re

okt = Okt()

def clean_text(text):
    text = re.sub(r'[^가-힣\s]', '', text)  # 한글/공백 외 제거
    words = okt.nouns(text)                # 명사만 추출
    words = [w for w in words if len(w) > 1]  # 불용어 제거 & 한 글자 제거
    return ' '.join(words)

"""### Pretrained BERT 기반 유사도 측정

#### 텍스트 정제 없이 그냥 군집화
"""

from sentence_transformers import SentenceTransformer
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import TfidfVectorizer
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import numpy as np

def print_result(df, embeddings, n_clusters, random_state=42):
    kmeans = KMeans(n_clusters=n_clusters, random_state=random_state)
    df['군집'] = kmeans.fit_predict(embeddings)

    # 군집별 중분류 개수 집계
    cluster_counts = df['군집'].value_counts().sort_index()
    # cluster_counts.columns = ["군집", "중분류 개수"]
    # print(cluster_counts)

    # 보기 좋게 출력
    for cluster_id, count in cluster_counts.items():
        print(f"군집 {cluster_id} : {count}개 중분류")

    print('\n')

    # 1. 군집별 텍스트 합치기
    cluster_texts = df.groupby('군집')['세세분류_통합'].apply(lambda x: ' '.join(x)).reset_index()

    # 2. TF-IDF 벡터화
    vectorizer = TfidfVectorizer(max_features=1000)
    tfidf_matrix = vectorizer.fit_transform(cluster_texts['세세분류_통합'])
    feature_names = vectorizer.get_feature_names_out()

    # 3. 군집별 상위 키워드 추출
    top_keywords_per_cluster = {}
    keywords_data = []

    for i, row in enumerate(tfidf_matrix.toarray()):
        top_indices = row.argsort()[::-1][:10]  # 상위 10개 단어
        top_keywords = [feature_names[idx] for idx in top_indices]
        keywords_string = ', '.join(top_keywords)
        top_keywords_per_cluster[f'군집 {cluster_texts.iloc[i]["군집"]}'] = top_keywords
        cluster_id = cluster_texts.iloc[i]['군집']
        keywords_data.append([cluster_id, keywords_string])

    # 4. 결과 출력
    # for cluster, keywords in top_keywords_per_cluster.items():
    #     print(f"{cluster} → {', '.join(keywords)}")

    keywords_df = pd.DataFrame(keywords_data, columns=['군집', '대표키워드'])
    # keywords_df = pd.merge(keywords_df, cluster_counts, on="군집")
    result_df = pd.merge(df, keywords_df, on="군집")

    return result_df

def merge_print_result(df1, df2, df_code, embeddings, n_clusters, random_state=42):
    code_table = print_result(df1, embeddings, n_clusters)
    cluster_result = pd.merge(code_table, df_code, on="중분류")

    # cluster_result.to_csv("/content/drive/MyDrive/업종 클러스터링/중분류_군집화.csv", index=False)

    result_table = pd.merge(df2, cluster_result, left_on="업종코드(중)", right_on="중분류_코드", how="left")
    result_table = result_table.groupby(["군집", "대표키워드"]).count().reset_index()[["군집","기업명", "대표키워드"]]
    result_table.columns = ["군집", "강소기업 수", "대표키워드"]
    return result_table

# 2. 엑셀 파일 불러오기
df = pd.read_excel("/content/drive/MyDrive/업종 클러스터링/표준산업분류표.xlsx", index_col=0)

df = df[['표준산업\n분류', '대분류.2', '대분류.3', '중분류.2', '중분류.3',
       '소분류.2', '소분류.3', '세분류.2', '세분류.3', '세세분류.1', '연계.1', '메인']]

df

# 3. 중분류별 세세분류 텍스트 통합
df_valid = df[['중분류.3', '세세분류.1']].dropna()
grouped = df_valid.groupby('중분류.3')['세세분류.1'].apply(lambda x: ' '.join(x)).reset_index()
grouped.columns = ['중분류', '세세분류_통합']

# 4. 한국어 문장 임베딩 모델 로드
model = SentenceTransformer("snunlp/KR-SBERT-V40K-klueNLI-augSTS")

# 5. 임베딩 수행
embeddings = model.encode(grouped['세세분류_통합'], show_progress_bar=True)

embeddings

# 코사인 유사도 히트맵

similarity_matrix = cosine_similarity(embeddings)
sim_df = pd.DataFrame(similarity_matrix, index=grouped['중분류'], columns=grouped['중분류'])

plt.figure(figsize=(12, 10))
sns.heatmap(sim_df, cmap='viridis')
plt.title("중분류 간 코사인 유사도 히트맵")
plt.xticks(rotation=90)
plt.yticks(rotation=0)
plt.tight_layout()
plt.show()

# 3. Elbow & Silhouette 분석
sse = []
silhouette_scores = []
k_range = range(2, 30)

for k in k_range:
    km = KMeans(n_clusters=k, random_state=42)
    km.fit(embeddings)
    sse.append(km.inertia_)
    silhouette_scores.append(silhouette_score(embeddings, km.labels_))

# 4. Elbow Plot
plt.figure(figsize=(10, 4))
plt.plot(k_range, sse, marker='o')
plt.title("Elbow Method: SSE vs # Clusters")
plt.xlabel("Number of Clusters")
plt.ylabel("SSE (Inertia)")
plt.grid(True)
plt.show()

# 5. Silhouette Score Plot
plt.figure(figsize=(10, 4))
plt.plot(k_range, silhouette_scores, marker='o', color='orange')
plt.title("Silhouette Score vs # Clusters")
plt.xlabel("Number of Clusters")
plt.ylabel("Silhouette Score")
plt.grid(True)
plt.show()

"""#### 05.13 추가 테스트"""

df_code = df[["중분류.2", "중분류.3"]]
df_code.drop_duplicates(inplace=True)
df_code.columns = ["중분류_코드", "중분류"]

result_df = pd.read_csv("/content/drive/MyDrive/업종 클러스터링/강소기업기준_과제_노인일자리_통합.csv", index_col=0)

# 29개 - Okt 적용 x

a = merge_print_result(grouped, result_df, df_code, embeddings, 5)
a

# 29개 - Okt 적용 x

a = merge_print_result(grouped, result_df, df_code, embeddings, 6)
a

# 29개 - Okt 적용 x

a = merge_print_result(grouped, result_df, df_code, embeddings, 7)
a

# 29개 - Okt 적용 x

a = merge_print_result(grouped, result_df, df_code, embeddings, 9)
a

# 29개 - Okt 적용 x

a = merge_print_result(grouped, result_df, df_code, embeddings, 10)
a

# 29개 - Okt 적용 x

a = merge_print_result(grouped, result_df, df_code, embeddings, 11)
a

# 29개 - Okt 적용 x

a = merge_print_result(grouped, result_df, df_code, embeddings, 12)
a

# 29개 - Okt 적용 x

a = merge_print_result(grouped, result_df, df_code, embeddings, 13)
a

# 29개 - Okt 적용 x

a = merge_print_result(grouped, result_df, df_code, embeddings, 14)
a

# 29개 - Okt 적용 x

a = merge_print_result(grouped, result_df, df_code, embeddings, 15)
a

# 29개 - Okt 적용 x

a = merge_print_result(grouped, result_df, df_code, embeddings, 16)
a

# 29개 - Okt 적용 x

a = merge_print_result(grouped, result_df, df_code, embeddings, 17)
a

# 29개 - Okt 적용 x

a = merge_print_result(grouped, result_df, df_code, embeddings, 18)
a

# 29개 - Okt 적용 x

a = merge_print_result(grouped, result_df, df_code, embeddings, 19)

a.to_excel("/content/drive/MyDrive/업종 클러스터링/k19_핵심키워드.xlsx")

# 29개 - Okt 적용 x

a = merge_print_result(grouped, result_df, df_code, embeddings, 20)
a

"""#### Okt -> 명사만 추출한 뒤 임베딩"""

# 1. 중분류별 세세분류 통합
df_2 = df[['중분류.3', '세세분류.1']].dropna()
grouped_2 = df_2.groupby('중분류.3')['세세분류.1'].apply(lambda x: ' '.join(x)).reset_index()
grouped_2.columns = ['중분류', '세세분류_통합']

# 텍스트 전처리
grouped_2['세세분류_통합'] = grouped_2['세세분류_통합'].apply(clean_text)

# 5. 임베딩 수행
embeddings2 = model.encode(grouped_2['세세분류_통합'], show_progress_bar=True)

# 3. Elbow & Silhouette 분석
sse_2 = []
silhouette_scores_2 = []
k_range = range(2, 51)

for k in k_range:
    km = KMeans(n_clusters=k, random_state=42)
    km.fit(embeddings2)
    sse_2.append(km.inertia_)
    silhouette_scores_2.append(silhouette_score(embeddings2, km.labels_))

# 4. Elbow Plot
plt.figure(figsize=(10, 4))
plt.plot(k_range, sse_2, marker='o')
plt.title("Elbow Method: SSE_2 vs # Clusters")
plt.xlabel("Number of Clusters")
plt.ylabel("SSE_2 (Inertia)")
plt.grid(True)
plt.show()

# 5. Silhouette Score Plot
plt.figure(figsize=(10, 4))
plt.plot(k_range, silhouette_scores_2, marker='o', color='orange')
plt.title("Silhouette Score vs # Clusters")
plt.xlabel("Number of Clusters")
plt.ylabel("Silhouette Score")
plt.grid(True)
plt.show()

"""##### 클러스터 수 늘리기"""

df_code = df[["중분류.2", "중분류.3"]]
df_code.drop_duplicates(inplace=True)
df_code.columns = ["중분류_코드", "중분류"]

result_df = pd.read_csv("/content/drive/MyDrive/업종 클러스터링/강소기업기준_과제_노인일자리_통합.csv", index_col=0)

result_df = pd.read_csv("/content/drive/MyDrive/업종 클러스터링/강소기업기준_과제_노인일자리_통합.csv", index_col=0)

# 29개 - Okt 적용 x

a = merge_print_result(grouped, result_df, df_code, embeddings, 29)
a

# 21개 - Okt 적용 x

a = merge_print_result(grouped, result_df, df_code, embeddings, 20)
a

# 21개 - Okt 적용 o

a = merge_print_result(grouped_2, result_df, df_code, embeddings2, 20)
a

kmeans = KMeans(n_clusters=20, random_state=42)
grouped['군집'] = kmeans.fit_predict(embeddings)

cluster_result = pd.merge(grouped, df_code, on="중분류")
cluster_result.to_csv("/content/drive/MyDrive/업종 클러스터링/k20_중분류_군집화.csv", index=False)
a.to_csv("/content/drive/MyDrive/업종 클러스터링/k20_핵심키워드.csv", index=False)

cluster_result

